{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b82eb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie principali\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch & torchvision\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Similarità\n",
    "from sklearn.metrics.pairwise import cosine_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468c50e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3ee13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se CUDA disponibile, usa la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carica ResNet50 pre-addestrata e in modalità eval\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1  # o DEFAULT per i pesi più aggiornati\n",
    "model = models.resnet50(weights=weights)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Preprocessing standard per ResNet\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "# Carica features da file .npz\n",
    "data = np.load(\"resnetfc.npz\", allow_pickle=True)\n",
    "feature_matrix = data[\"features\"]\n",
    "filenames = data[\"filenames\"]\n",
    "labels = data[\"labels\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ad571",
   "metadata": {},
   "source": [
    "Funzione Estrazione Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "33c9c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fc_features_from_image(image_path, model, preprocess, device):\n",
    "    \"\"\"\n",
    "    Estrae le feature del layer fully connected (fc) di ResNet50 da un'immagine.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORE] Immagine non valida {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    fc_output = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "\n",
    "    hook = model.fc.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    if fc_output:\n",
    "        return fc_output[0].squeeze(0).cpu().numpy()\n",
    "    else:\n",
    "        print(f\"[ERRORE] Nessun output FC per {image_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa9a99",
   "metadata": {},
   "source": [
    "Elaborazione Batch e Salvataggio Feature in .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d43f4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    \"\"\"\n",
    "    Estrae le feature FC da immagini in più cartelle e salva in un file .npz.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_filenames = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"[ATTENZIONE] Cartella non trovata: {folder_path}\")\n",
    "            continue\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "                else:\n",
    "                    print(f\"[ERRORE] Feature non estratte da {img_path}\")\n",
    "\n",
    "    # Salva in file .npz\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    \n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")\n",
    "    print(f\"[FINE] Totale immagini processate: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a7462",
   "metadata": {},
   "source": [
    " Retrieval: Immagini più Simili (distanza coseno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cc7d97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_cosine(img_path, k):\n",
    "    \"\"\"\n",
    "    Trova le k immagini più simili rispetto a una query, usando la distanza coseno.\n",
    "    \"\"\"\n",
    "    query_feature = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Impossibile estrarre feature dalla query.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    distances = cosine_distances(feature_matrix, query_feature).flatten()\n",
    "\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "    top_k_scores = distances[top_k_idx]\n",
    "\n",
    "    print(f\"\\nTop {k} immagini più simili a: {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {filenames[idx]} | Classe: {labels[idx]} | Distanza: {top_k_scores[rank]:.4f}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        match_img = cv2.imread(os.path.join(\"Part1\", labels[idx], filenames[idx]))\n",
    "        axs[i+1].imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[i+1].set_title(f\"Rank {i+1}\\nD={top_k_scores[i]:.4f}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri cartelle e output\n",
    "base_folder = \"Part1\"\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "output_file = \"resnetfc.npz\"\n",
    "\n",
    "# Estrazione e salvataggio\n",
    "process_and_save_features(base_folder, subfolders, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test su immagine di query\n",
    "query_img = \"Part1/brain_glioma/brain_glioma_0001.jpg\"\n",
    "find_k_similar_cosine(query_img, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e32f2e",
   "metadata": {},
   "source": [
    "codice non pre-modifiche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ba4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_resnet_fc_features(img_path):\n",
    "    # Carica l'immagine e assicura la modalità RGB\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # Pre-processamento standard per ResNet: ridimensiona, ritaglia, trasforma in tensor e normalizza\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img_tensor = preprocess(img).unsqueeze(0)  # Aggiungi la dimensione del batch\n",
    "    \n",
    "    # Carica la ResNet50 pre-addestrata e mettila in modalità eval\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    resnet.eval()\n",
    "    \n",
    "    # Lista per salvare l'output del layer fc\n",
    "    fc_output = []\n",
    "\n",
    "    # Definisci un hook che memorizza l'output del layer fc\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "    \n",
    "    # Registra il forward hook sul layer fully connected\n",
    "    hook = resnet.fc.register_forward_hook(hook_fn)\n",
    "    \n",
    "    # Passa l'immagine attraverso il modello\n",
    "    with torch.no_grad():\n",
    "        resnet(img_tensor)\n",
    "    \n",
    "    # Rimuovi l'hook (è buona norma pulirlo dopo l'uso)\n",
    "    hook.remove()\n",
    "    \n",
    "    # Il risultato è salvato in fc_output[0] con shape [1, 1000]. Rimuovi la dimensione del batch:\n",
    "    features = fc_output[0].squeeze(0)\n",
    "    \n",
    "    # Stampa e visualizza il vettore delle features\n",
    "    print(\"Vettore delle features (1000 elementi):\")\n",
    "    print(features.numpy())\n",
    "    \n",
    "    # Visualizzazione opzionale: ad esempio, un bar plot dei primi 20 valori\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(20), features.numpy()[:20])\n",
    "    plt.xlabel(\"Indice feature\")\n",
    "    plt.ylabel(\"Valore\")\n",
    "    plt.title(\"Prime 20 features del layer fc\")\n",
    "    plt.show()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Esempio di esecuzione\n",
    "img_path = \"Part1/brain_glioma/brain_glioma_0002.jpg\"  # Sostituisci con il percorso corretto della tua immagine\n",
    "features = extract_resnet_fc_features(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f17dd",
   "metadata": {},
   "source": [
    "Task: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f356f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "def extract_fc_features_from_image(image_path, model, preprocess, device):\n",
    "    \"\"\"\n",
    "    Apre l'immagine, la pre-processa e la passa attraverso la rete.\n",
    "    Utilizza un hook per catturare l'output del layer fully connected (fc) della ResNet.\n",
    "    Restituisce un vettore numpy di dimensione 1000.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'apertura dell'immagine {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    fc_output = []\n",
    "\n",
    "    # Definizione del hook per catturare l'output del layer fc\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "\n",
    "    hook = model.fc.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    # fc_output[0] ha forma [1, 1000], rimuoviamo la dimensione batch e riportiamo su CPU\n",
    "    features = fc_output[0].squeeze(0).cpu().numpy()\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Imposta il percorso della cartella base e le sottocartelle\n",
    "    base_dir = \"Part1\"\n",
    "    subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "    image_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "\n",
    "    image_paths = []\n",
    "    # Cerca le immagini all'interno delle sottocartelle specificate\n",
    "    for sub in subfolders:\n",
    "        dir_path = os.path.join(base_dir, sub)\n",
    "        if os.path.isdir(dir_path):\n",
    "            for root, _, files in os.walk(dir_path):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(image_extensions):\n",
    "                        image_paths.append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"La cartella {dir_path} non esiste.\")\n",
    "\n",
    "    if not image_paths:\n",
    "        print(\"Non sono state trovate immagini nelle cartelle specificate.\")\n",
    "        return\n",
    "\n",
    "    # Configura il dispositivo da utilizzare (GPU se disponibile, altrimenti CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Definisci la trasformazione di pre-processing standard per ResNet\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Carica il modello ResNet50 pre-addestrato ed impostalo in modalità evaluation\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "\n",
    "    \"\"\"\"\"\n",
    "    # Prepara i dati che verranno salvati sul file CSV\n",
    "    csv_rows = []\n",
    "    # Crea l'header: la prima colonna è il percorso dell'immagine, le altre sono le feature\n",
    "    header = [\"image_path\"] + [f\"fc_feature_{i}\" for i in range(1000)]\n",
    "    csv_rows.append(header)\n",
    "\n",
    "    # Estrai le features per ogni immagine e conserva il risultato in una riga di CSV\n",
    "    for img_path in image_paths:\n",
    "        features = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "        if features is not None:\n",
    "            row = [img_path] + features.tolist()\n",
    "            csv_rows.append(row)\n",
    "        else:\n",
    "            print(f\"Errore nell'estrazione delle features da {img_path}\")\n",
    "\n",
    "    # Salva i risultati in un file CSV\n",
    "    csv_file = \"resnetfc.csv\"\n",
    "    try:\n",
    "        with open(csv_file, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(csv_rows)\n",
    "        print(f\"Salvataggio completato in {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il salvataggio del file CSV: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\"\n",
    "\n",
    "# === Funzione per elaborare immagini in più cartelle ===\n",
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "     # Carica il modello ResNet50 pre-addestrato ed impostalo in modalità evaluation\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_filenames = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "    # Converti in array\n",
    "    features_array = np.array(all_features)\n",
    "    filenames_array = np.array(all_filenames)\n",
    "    labels_array = np.array(all_labels)\n",
    "\n",
    "    # Salva in .npz\n",
    "    np.savez(output_file, features=features_array, filenames=filenames_array, labels=labels_array)\n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")\n",
    "    print(f\"[FINE] Totale immagini processate: {len(all_features)}\")\n",
    "\n",
    "\n",
    "# === Esecuzione ===\n",
    "base_folder = \"Part1\"\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "output_file = \"resnetfc0.npz\"\n",
    "\n",
    "process_and_save_features(base_folder, subfolders, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f532d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import cv2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc95f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "def extract_fc_features_from_image(image_path, model, preprocess, device):\n",
    "    \"\"\"\n",
    "    Apre l'immagine, la pre-processa e la passa attraverso la rete.\n",
    "    Utilizza un hook per catturare l'output del layer fully connected (fc) della ResNet.\n",
    "    Restituisce un vettore numpy di dimensione 1000.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORE] Immagine non valida {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    fc_output = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "\n",
    "    hook = model.fc.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    if fc_output:\n",
    "        return fc_output[0].squeeze(0).cpu().numpy()\n",
    "    else:\n",
    "        print(f\"[ERRORE] Nessun output FC per {image_path}\")\n",
    "        return None\n",
    "\n",
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    # Configura il dispositivo\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Definisci la trasformazione\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Carica il modello\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_filenames = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"[ATTENZIONE] Cartella non trovata: {folder_path}\")\n",
    "            continue\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "                else:\n",
    "                    print(f\"[ERRORE] Feature non estratte da {img_path}\")\n",
    "\n",
    "    # Converti in array\n",
    "    features_array = np.array(all_features)\n",
    "    filenames_array = np.array(all_filenames)\n",
    "    labels_array = np.array(all_labels)\n",
    "\n",
    "    # Salva in .npz\n",
    "    np.savez(output_file, features=features_array, filenames=filenames_array, labels=labels_array)\n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")\n",
    "    print(f\"[FINE] Totale immagini processate: {len(all_features)}\")\n",
    "\n",
    "# === Esecuzione ===\n",
    "if __name__ == \"__main__\":\n",
    "    base_folder = \"Part1\"\n",
    "    subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "    output_file = \"resnetfc.npz\"\n",
    "\n",
    "    process_and_save_features(base_folder, subfolders, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b030250",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# Carica dati da file .npz (con feature ResNetFC)\n",
    "data = np.load(\"resnetfc.npz\", allow_pickle=True)\n",
    "feature_matrix = data[\"features\"]\n",
    "filenames = data[\"filenames\"]\n",
    "labels = data[\"labels\"]\n",
    "\n",
    "# Definisci la trasformazione\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# === Funzione per trovare k immagini più simili (coseno) ===\n",
    "def find_k_similar_cosine(img_path, k):\n",
    "    query_feature = extract_fc_features_from_image(img_path, model, preprocess, device)  # Deve restituire un vettore 1D\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Impossibile estrarre feature dalla query.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "\n",
    "    # Calcola la distanza del coseno (1 - similarità coseno)\n",
    "    distances = cosine_distances(feature_matrix, query_feature).flatten()\n",
    "\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "    top_k_scores = distances[top_k_idx]\n",
    "\n",
    "    print(f\"\\nTop {k} immagini più simili (distanza coseno) a: {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {filenames[idx]} | Classe: {labels[idx]} | Distanza: {top_k_scores[rank]:.4f}\")\n",
    "\n",
    "    # Visualizza risultati\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        match_img = cv2.imread(os.path.join(\"Part1\", labels[idx], filenames[idx]))\n",
    "        axs[i+1].imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[i+1].set_title(f\"Rank {i+1}\\nD={top_k_scores[i]:.4f}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Test ===\n",
    "query_img = \"Part1/brain_glioma/brain_glioma_0001.jpg\"\n",
    "find_k_similar_cosine(query_img, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
