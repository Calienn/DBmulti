{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b82eb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie principali\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from collections import defaultdict, Counter\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468c50e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a3ee13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se CUDA disponibile, usa la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carica ResNet50 pre-addestrata e in modalità eval\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1  # o DEFAULT per i pesi più aggiornati\n",
    "model = models.resnet50(weights=weights)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Preprocessing standard per ResNet\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "\n",
    "#funzione di creazione dei file\n",
    "def load_features(npz_path):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    return data['features'], data['labels'], data.get('filenames', [f\"img_{i}\" for i in range(len(data['features']))])\n",
    "\n",
    "\n",
    "feat_matrix_part1, lbls_part1, flname_part1 = load_features(\n",
    "    \"resnetfc_part1.npz\")\n",
    "feat_matrix_part2, lbls_part2, flname_part2 = load_features(\n",
    "    \"resnetfc_part2.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ad571",
   "metadata": {},
   "source": [
    "Funzione Estrazione Feature - Task 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "33c9c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fc_features_from_image(image_path, model, preprocess, device):\n",
    "    \"\"\"\n",
    "    Estrae le feature del layer fully connected (fc) di ResNet50 da un'immagine.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORE] Immagine non valida {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    fc_output = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "\n",
    "    hook = model.fc.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    if fc_output:\n",
    "        return fc_output[0].squeeze(0).cpu().numpy()\n",
    "    else:\n",
    "        print(f\"[ERRORE] Nessun output FC per {image_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa9a99",
   "metadata": {},
   "source": [
    "Elaborazione Batch e Salvataggio Feature in .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d43f4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    \"\"\"\n",
    "    Estrae le feature FC da immagini in più cartelle e salva in un file .npz.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_filenames = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"[ATTENZIONE] Cartella non trovata: {folder_path}\")\n",
    "            continue\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "                else:\n",
    "                    print(f\"[ERRORE] Feature non estratte da {img_path}\")\n",
    "\n",
    "    # Salva in file .npz\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    \n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")\n",
    "    print(f\"[FINE] Totale immagini processate: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a7462",
   "metadata": {},
   "source": [
    " Retrieval: Immagini più Simili (distanza coseno) - Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cc7d97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_cosine(img_path, k):\n",
    "    \"\"\"\n",
    "    Trova le k immagini più simili rispetto a una query, usando la distanza coseno.\n",
    "    \"\"\"\n",
    "    query_feature = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Impossibile estrarre feature dalla query.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    distances = cosine_distances(feat_matrix_part1, query_feature).flatten()\n",
    "\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "    top_k_scores = distances[top_k_idx]\n",
    "\n",
    "    print(f\"\\nTop {k} immagini più simili a: {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {flname_part1[idx]} | Classe: {lbls_part1[idx]} | Distanza: {top_k_scores[rank]:.4f}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        match_img = cv2.imread(os.path.join(\"Part1\", lbls_part1[idx], flname_part1[idx]))\n",
    "        axs[i+1].imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[i+1].set_title(f\"Rank {i+1}\\nD={top_k_scores[i]:.4f}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "b855f245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Elaboro cartella: brain_glioma\n",
      "[INFO] Elaboro cartella: brain_menin\n",
      "[INFO] Elaboro cartella: brain_tumor\n",
      "[SALVATO] Features salvate in resnetfc_part1\n",
      "[FINE] Totale immagini processate: 3006\n",
      "[INFO] Elaboro cartella: brain_glioma\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Estrazione e salvataggio\u001b[39;00m\n\u001b[1;32m      5\u001b[0m process_and_save_features(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPart1\u001b[39m\u001b[38;5;124m\"\u001b[39m, subfolders, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnetfc_part1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mprocess_and_save_features\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPart2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubfolders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnetfc_part2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[103], line 19\u001b[0m, in \u001b[0;36mprocess_and_save_features\u001b[0;34m(base_folder, subfolders, output_file)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mlower()\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.jpeg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.bmp\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m)):\n\u001b[1;32m     18\u001b[0m     img_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(folder_path, filename)\n\u001b[0;32m---> 19\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_fc_features_from_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     21\u001b[0m         all_features\u001b[38;5;241m.\u001b[39mappend(features)\n",
      "Cell \u001b[0;32mIn[102], line 19\u001b[0m, in \u001b[0;36mextract_fc_features_from_image\u001b[0;34m(image_path, model, preprocess, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m hook \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mregister_forward_hook(hook_fn)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m hook\u001b[38;5;241m.\u001b[39mremove()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fc_output:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1760\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1761\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1764\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torchvision/models/resnet.py:280\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    278\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n\u001b[1;32m    279\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mflatten(x, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1857\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1854\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1858\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1859\u001b[0m     \u001b[38;5;66;03m# run always called hooks if they have not already been run\u001b[39;00m\n\u001b[1;32m   1860\u001b[0m     \u001b[38;5;66;03m# For now only forward hooks have the always_call option but perhaps\u001b[39;00m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# this functionality should be added to full backward hooks as well.\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m _global_forward_hooks\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/module.py:1805\u001b[0m, in \u001b[0;36mModule._call_impl.<locals>.inner\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1802\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m BackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1803\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1805\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1807\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1808\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1809\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1810\u001b[0m     ):\n\u001b[1;32m   1811\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parametri cartelle e output\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "\n",
    "# Estrazione e salvataggio\n",
    "process_and_save_features(\"Part1\", subfolders, \"resnetfc_part1\")\n",
    "process_and_save_features(\"Part2\", subfolders, \"resnetfc_part2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "78a9092d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 1000 while Y.shape[1] == 2048",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Test su immagine di query\u001b[39;00m\n\u001b[1;32m      2\u001b[0m query_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPart1/brain_glioma/brain_glioma_0017.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mfind_k_similar_cosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[96], line 11\u001b[0m, in \u001b[0;36mfind_k_similar_cosine\u001b[0;34m(img_path, k)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     10\u001b[0m query_feature \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(query_feature)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m distances \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_distances\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeat_matrix_part1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_feature\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     13\u001b[0m top_k_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(distances)[:k]\n\u001b[1;32m     14\u001b[0m top_k_scores \u001b[38;5;241m=\u001b[39m distances[top_k_idx]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1130\u001b[0m, in \u001b[0;36mcosine_distances\u001b[0;34m(X, Y)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine distance between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1096\u001b[0m \n\u001b[1;32m   1097\u001b[0m \u001b[38;5;124;03mCosine distance is defined as 1.0 minus the cosine similarity.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;124;03m       [0.42..., 0.18...]])\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1129\u001b[0m \u001b[38;5;66;03m# 1.0 - cosine_similarity(X, Y) without copy\u001b[39;00m\n\u001b[0;32m-> 1130\u001b[0m S \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m S \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1132\u001b[0m S \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:214\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecomputed metric requires shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(n_queries, n_indexed). Got (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m indexed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ensure_2d \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# Only check the number of features if 2d arrays are enforced. Otherwise,\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# validation is left to the user for custom metrics.\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimension for X and Y matrices: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m while Y.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, Y\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 1000 while Y.shape[1] == 2048"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test su immagine di query\n",
    "query_img = \"Part1/brain_glioma/brain_glioma_0017.jpg\"\n",
    "find_k_similar_cosine(query_img, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a47de",
   "metadata": {},
   "source": [
    "Task 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f7fc4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task4_predict_labels_resnetfc(query_img_path, k, extractor_fn, features, labels, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Predict top-k labels for query image using ResNet FC features.\n",
    "    extractor_fn: funzione che prende image_path e restituisce feature numpy array\n",
    "    features: matrice numpy (N, d)\n",
    "    labels: array di stringhe (N,)\n",
    "    metric: \"euclidean\" o \"cosine\"\n",
    "    \"\"\"\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "    print(f\"\\n======== PREDIZIONE PER: {os.path.basename(query_img_path)} ========\")\n",
    "\n",
    "    def compute_metric(query_feat, target_feats, metric):\n",
    "        query_feat = query_feat.reshape(1, -1)\n",
    "        if metric == \"euclidean\":\n",
    "            # distanza euclidea tra query_feat e tutti target_feats\n",
    "            return np.linalg.norm(target_feats - query_feat, axis=1)\n",
    "        elif metric == \"cosine\":\n",
    "            # similarità coseno tra query_feat e tutti target_feats\n",
    "            # sim = (A·B) / (|A||B|), distanza = 1 - sim\n",
    "            dot_prod = np.dot(target_feats, query_feat.T).flatten()\n",
    "            norm_feats = np.linalg.norm(target_feats, axis=1)\n",
    "            norm_query = np.linalg.norm(query_feat)\n",
    "            cosine_sim = dot_prod / (norm_feats * norm_query + 1e-10)\n",
    "            cosine_dist = 1 - cosine_sim  # distanza coseno\n",
    "            return cosine_dist\n",
    "        else:\n",
    "            raise ValueError(\"Metric must be 'euclidean' or 'cosine'\")\n",
    "\n",
    "    def predict_top_k_labels_distance_mean(query_img_path, k, features, labels, metric):\n",
    "        query_feat = extractor_fn(query_img_path)\n",
    "        if query_feat is None:\n",
    "            print(\"[ERRORE] Feature non estratte.\")\n",
    "            return\n",
    "        unique_labels = np.unique(labels)\n",
    "        scores = []\n",
    "        for label in unique_labels:\n",
    "            class_feats = features[labels == label]\n",
    "            dists = compute_metric(query_feat, class_feats, metric)\n",
    "            scores.append(dists.mean())\n",
    "        if metric == \"euclidean\":\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        else:  # cosine distanza: più piccola è meglio\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        print(f\"\\n[STRATEGIA: distanza media - metrica: {metric}]\")\n",
    "        for idx in top_k:\n",
    "            print(f\"Classe: {unique_labels[idx]} | Score medio: {scores[idx]:.4f}\")\n",
    "\n",
    "    def predict_top_k_labels_prototype(query_img_path, k, features, labels, metric):\n",
    "        query_feat = extractor_fn(query_img_path)\n",
    "        if query_feat is None:\n",
    "            print(\"[ERRORE] Feature non estratte.\")\n",
    "            return\n",
    "        unique_labels = np.unique(labels)\n",
    "        prototypes = []\n",
    "        for label in unique_labels:\n",
    "            class_feats = features[labels == label]\n",
    "            prototypes.append(class_feats.mean(axis=0))\n",
    "        prototypes = np.vstack(prototypes)\n",
    "        scores = compute_metric(query_feat, prototypes, metric)\n",
    "        if metric == \"euclidean\":\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        else:\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        print(f\"\\n[STRATEGIA: prototipo di classe - metrica: {metric}]\")\n",
    "        for idx in top_k:\n",
    "            print(f\"Classe: {unique_labels[idx]} | Score: {scores[idx]:.4f}\")\n",
    "\n",
    "    predict_top_k_labels_distance_mean(query_img_path, k, features, labels, metric)\n",
    "    predict_top_k_labels_prototype(query_img_path, k, features, labels, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_menin/brain_menin_1202.jpg\"\n",
    "task4_predict_labels_resnetfc(\n",
    "    query_img, k=2,\n",
    "    extractor_fn=lambda img: extract_fc_features_from_image(img, model, preprocess, device),\n",
    "    features=feat_matrix_part1,\n",
    "    labels=lbls_part1,\n",
    "    metric=\"euclidean\"\n",
    ")\n",
    "\n",
    "task4_predict_labels_resnetfc(\n",
    "    query_img, k=2,\n",
    "    extractor_fn=lambda img: extract_fc_features_from_image(img, model, preprocess, device),\n",
    "    features=feat_matrix_part1,\n",
    "    labels=lbls_part1,\n",
    "    metric=\"cosine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696ac9c",
   "metadata": {},
   "source": [
    "Task 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "83a11ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task5_latent_semantics_resnetfc(feature_model_path, technique, k):\n",
    "    data = np.load(feature_model_path, allow_pickle=True)\n",
    "    feature_matrix = data['features']\n",
    "    filenames = data['filenames']\n",
    "    labels = data['labels']\n",
    "    technique = technique.lower()\n",
    "\n",
    "    if technique == \"svd\":\n",
    "        model = TruncatedSVD(n_components=k, random_state=42)\n",
    "        X_transformed = model.fit_transform(feature_matrix)\n",
    "        components = model.components_\n",
    "        method = \"svd\"\n",
    "\n",
    "    elif technique == \"lda\":\n",
    "        unique_labels = np.unique(labels)\n",
    "        max_k = len(unique_labels) - 1\n",
    "        if k > max_k:\n",
    "            print(f\"[ATTENZIONE] LDA supporta al massimo {max_k} componenti con {len(unique_labels)} classi.\")\n",
    "            k = max_k\n",
    "        model = LDA(n_components=k)\n",
    "        X_transformed = model.fit_transform(feature_matrix, labels)\n",
    "        components = model.scalings_.T[:k]\n",
    "        method = \"lda\"\n",
    "\n",
    "    elif technique == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "        model.fit(feature_matrix)\n",
    "        components = model.cluster_centers_\n",
    "        X_transformed = model.transform(feature_matrix)\n",
    "        method = \"kmeans\"\n",
    "    else:\n",
    "        print(\"[ERRORE] Tecnica non supportata. Usa: 'svd', 'lda', 'kmeans'\")\n",
    "        return\n",
    "\n",
    "    if technique in [\"svd\", \"lda\"]:\n",
    "        plot_latent_space_2d(X_transformed, labels, technique, k)\n",
    "    elif technique == \"kmeans\":\n",
    "        plot_kmeans_clusters_2d(feature_matrix, labels, k)\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(feature_model_path))[0]\n",
    "    out_file = f\"latent_semantics_{method}_{base_name}_k{k}.txt\"\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for i in range(k):\n",
    "            f.write(f\"\\n--- Latent Semantic {i+1} ---\\n\")\n",
    "            if technique in [\"svd\", \"lda\"]:\n",
    "                weights = feature_matrix @ components[i].T\n",
    "            else:\n",
    "                weights = -X_transformed[:, i]  # distanza inversa\n",
    "            sorted_idx = np.argsort(-np.abs(weights))\n",
    "            for idx in sorted_idx:\n",
    "                f.write(f\"{filenames[idx]} | Peso: {weights[idx]:.4f} | Classe: {labels[idx]}\\n\")\n",
    "\n",
    "    print(f\"[SALVATO] Latent semantics salvati in: {out_file}\")\n",
    "\n",
    "\n",
    "def plot_latent_space_2d(X_transformed, labels, technique, k):\n",
    "    if X_transformed.shape[1] < 2:\n",
    "        print(\"[INFO] Meno di 2 componenti: impossibile visualizzare in 2D.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_transformed[:, 0], y=X_transformed[:, 1], hue=labels, palette=\"Set2\", s=80)\n",
    "    plt.title(f\"{technique.upper()} - Proiezione sulle prime 2 componenti latenti (k={k})\")\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_kmeans_clusters_2d(feature_matrix, labels, n_clusters):\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(feature_matrix)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=cluster_labels, palette='tab10', s=80, style=labels)\n",
    "    plt.title(f\"KMeans Clustering (k={n_clusters}) con proiezione SVD 2D\")\n",
    "    plt.xlabel(\"Componente Latente 1 (da SVD)\")\n",
    "    plt.ylabel(\"Componente Latente 2 (da SVD)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "task5_latent_semantics_resnetfc(\"resnetfc_part1.npz\", technique=\"svd\", k=5)\n",
    "task5_latent_semantics_resnetfc(\"resnetfc_part1.npz\", technique=\"lda\", k=2)\n",
    "task5_latent_semantics_resnetfc(\"resnetfc_part1.npz\", technique=\"kmeans\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872f36c",
   "metadata": {},
   "source": [
    "task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4073e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_intrinsic_dimensionality(feature_matrix, threshold, plot=True):\n",
    "    max_components = min(feature_matrix.shape)\n",
    "    pca = PCA(n_components=max_components)\n",
    "    pca.fit(feature_matrix)\n",
    "\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    cumulative = np.cumsum(explained)\n",
    "    intrinsic_dim = np.argmax(cumulative >= threshold) + 1\n",
    "\n",
    "    #print(f\"[INFO] Spiegazione varianza per ogni componente PCA:\\n{explained}\")\n",
    "    #print(f\"[INFO] Varianza cumulativa:\\n{cumulative}\")\n",
    "    #print(f\"[INFO] Soglia impostata: {threshold}\")\n",
    "    #print(f\"[INFO] Dimensione intrinseca stimata: {intrinsic_dim}\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(cumulative, marker='o', label=\"Varianza cumulativa\")\n",
    "        plt.axhline(y=threshold, color='r', linestyle='--', label=f\"Soglia {threshold*100:.0f}%\")\n",
    "        plt.axvline(x=intrinsic_dim, color='g', linestyle='--', label=f\"k suggerito: {intrinsic_dim}\")\n",
    "        plt.xlabel(\"Numero componenti\")\n",
    "        plt.ylabel(\"Varianza cumulativa\")\n",
    "        plt.title(\"Scelta ottimale di k (PCA/SVD)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"[INFO] k ottimale suggerito (soglia {threshold*100:.0f}%): {intrinsic_dim}\")\n",
    "    return intrinsic_dim, cumulative\n",
    "\n",
    "def suggest_k(feature_matrix, threshold_list=[0.90, 0.95, 0.99]):\n",
    "    print(f\"[INFO] Feature matrix shape: {feature_matrix.shape}\")\n",
    "    k_values = {}\n",
    "    for t in threshold_list:\n",
    "        k, _ = estimate_intrinsic_dimensionality(feature_matrix, threshold=t, plot=False)\n",
    "        k_values[t] = k\n",
    "        print(f\"Soglia {int(t*100)}% : k = {k}\")\n",
    "    return k_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9585c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dimensionality_per_label(feature_matrix, labels, threshold):\n",
    "    label_dim_map = {}\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"[INFO] Etichette uniche trovate: {len(unique_labels)}\")\n",
    "\n",
    "    for label in unique_labels:\n",
    "        indices = np.where(labels == label)[0]\n",
    "        label_features = feature_matrix[indices]\n",
    "\n",
    "        if len(indices) < 2:\n",
    "            print(f\"[AVVISO] Label '{label}' ha meno di 2 campioni — ignorata.\")\n",
    "            continue\n",
    "\n",
    "        k, _ = estimate_intrinsic_dimensionality(label_features, threshold=threshold, plot=False)\n",
    "        label_dim_map[label] = k\n",
    "        print(f\" Label '{label}' : k = {k}\")\n",
    "\n",
    "    return label_dim_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428759c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola k per varie soglie\n",
    "print(\"\\Stima automatica di k in base alla varianza spiegata:\\n\")\n",
    "k_suggeriti = suggest_k(feat_matrix_part1)\n",
    "# Plot dettagliato per la soglia 95%\n",
    "estimate_intrinsic_dimensionality(feat_matrix_part1, threshold=0.95, plot=True)\n",
    "\n",
    "\n",
    "print(\"\\n Task 6b – Dimensionalità per etichetta:\\n\")\n",
    "label_dimensionalities = estimate_dimensionality_per_label(feat_matrix_part1, lbls_part1, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c608a",
   "metadata": {},
   "source": [
    "Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "63c39581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latent_semantics_per_class(X, y, k=10):\n",
    "    class_models = {}\n",
    "    class_means = {}\n",
    "\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        X_class = X[y == label]  # Prende solo le istanze della classe corrente\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_class)  # Normalizza i dati della classe\n",
    "\n",
    "        svd = TruncatedSVD(n_components=k)\n",
    "        latent = svd.fit_transform(X_scaled)  # Riduzione dimensionale con SVD\n",
    "\n",
    "        # Salva modello SVD e scaler per la classe\n",
    "        class_models[label] = {\n",
    "            'svd': svd,\n",
    "            'scaler': scaler,\n",
    "            'latent_vectors': latent\n",
    "        }\n",
    "        # Calcola la media dei vettori latenti della classe\n",
    "        class_means[label] = np.mean(latent, axis=0)\n",
    "    return class_models, class_means\n",
    "\n",
    "def predict_label(X_test, class_models, class_means):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        best_label = None\n",
    "        min_dist = float('inf')\n",
    "        for label, model in class_models.items():\n",
    "            x_scaled = model['scaler'].transform(x.reshape(1, -1))  # Normalizza x\n",
    "            x_latent = model['svd'].transform(x_scaled)  # Trasforma in spazio latente\n",
    "            dist = np.linalg.norm(x_latent - class_means[label])  # Distanza dal centroide\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_label = label\n",
    "        y_pred.append(best_label)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    labels = np.unique(y_true)\n",
    "    print(\"Per-class metrics:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        print(\n",
    "            f\"Class {label}: P={precision[i]:.2f}, R={recall[i]:.2f}, F1={f1[i]:.2f}\")\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "def evaluate_predictions(true_labels, predicted_labels):\n",
    "    print(\"[VALUTAZIONE] Report di classificazione:\")\n",
    "    print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c23056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento sui dati di Part1\n",
    "class_models, class_means = compute_latent_semantics_per_class(\n",
    "    feat_matrix_part1, lbls_part1, k=10)\n",
    "\n",
    "# Predizione su Part2\n",
    "predicted_labels = predict_label(feat_matrix_part2, class_models, class_means)\n",
    "\n",
    "# Valutazione\n",
    "evaluate(lbls_part2, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0606d712",
   "metadata": {},
   "source": [
    "Task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f971ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(npz_path):\n",
    "    \"\"\"\n",
    "    Carica features, labels e filenames da un file .npz.\n",
    "    Ritorna:\n",
    "      - features: array NumPy di shape (N, D)\n",
    "      - labels:   array di shape (N,)\n",
    "      - filenames: array di shape (N,)\n",
    "    \"\"\"\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    features = data['features']\n",
    "    labels = data['labels']\n",
    "    filenames = data.get('filenames', np.array([f\"img_{i}\" for i in range(len(features))]))\n",
    "    return features, labels, filenames\n",
    "\n",
    "\n",
    "def extract_color_moments(img_path):\n",
    "    \"\"\"\n",
    "    Estrae i Color Moments su griglia 10×10 (900‐dim) da un'immagine.\n",
    "    Restituisce una lista di 900 float, oppure None se l'immagine non viene letta.\n",
    "    \"\"\"\n",
    "    from scipy.stats import skew\n",
    "\n",
    "    img_bgr = cv2.imread(img_path)\n",
    "    if img_bgr is None:\n",
    "        return None\n",
    "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    img_resized = cv2.resize(img_rgb, (300, 100))\n",
    "\n",
    "    h_cell = 100 // 10  # 10\n",
    "    w_cell = 300 // 10  # 30\n",
    "    feature = []\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            cell = img_resized[i*h_cell:(i+1)*h_cell, j*w_cell:(j+1)*w_cell, :]\n",
    "            for c in range(3):\n",
    "                canal = cell[:, :, c].flatten().astype(np.float64)\n",
    "                m = float(np.mean(canal))\n",
    "                s = float(np.std(canal))\n",
    "                sk = float(skew(canal))\n",
    "                feature.extend([m, s, sk])\n",
    "    return feature  # lunghezza = 10×10×3×3 = 900\n",
    "\n",
    "\n",
    "def lista_percorso_immagini(cartella_root):\n",
    "    \"\"\"\n",
    "    Ritorna la lista di tutti i percorsi di file immagine (.jpg, .jpeg, .png)\n",
    "    presenti ricorsivamente sotto cartella_root.\n",
    "    \"\"\"\n",
    "    img_paths = []\n",
    "    for root, dirs, files in os.walk(cartella_root):\n",
    "        for f in files:\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_paths.append(os.path.join(root, f))\n",
    "    return img_paths\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 2) Funzione per PCA + DBSCAN\n",
    "# -----------------------------------------------\n",
    "\n",
    "def apply_dbscan_with_pca(features, eps=2.0, min_samples=3, n_components=50):\n",
    "    \"\"\"\n",
    "    Riduce 'features' a 'n_components' dimensioni via PCA, poi applica DBSCAN.\n",
    "    Restituisce l'array di cluster-labels (interi) di lunghezza = numero di righe in 'features'.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] PCA → riduco da {features.shape[1]} a {n_components} componenti\")\n",
    "    pca = PCA(n_components=n_components)\n",
    "    reduced_features = pca.fit_transform(features)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    reduced_scaled = scaler.fit_transform(reduced_features)\n",
    "\n",
    "    db = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "    labels = db.fit_predict(reduced_scaled)\n",
    "    return labels\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 3) Funzione per selezionare i c cluster più popolosi\n",
    "# -----------------------------------------------\n",
    "\n",
    "def top_c_clusters(cluster_labels, c):\n",
    "    \"\"\"\n",
    "    cluster_labels: array di interi di lunghezza N.\n",
    "    c: numero di cluster \"più voluminosi\" da restituire.\n",
    "    Restituisce la lista dei c valori di cluster (escludendo -1), \n",
    "    ordinati per frequenza decrescente. Se ci sono meno di c cluster, restituisce tutti.\n",
    "    \"\"\"\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    label_counts.pop(-1, None)  # rimuovo il rumore (-1), se presente\n",
    "\n",
    "    if not label_counts:\n",
    "        print(\"[WARN] DBSCAN non ha trovato alcun cluster valido (solo rumore).\")\n",
    "        return []\n",
    "\n",
    "    most_common = label_counts.most_common(c)  # e.g. [(lbl1, cnt1), (lbl2, cnt2), ...]\n",
    "    top = [int(lbl) for lbl, _ in most_common]\n",
    "\n",
    "    if len(top) < c:\n",
    "        print(f\"[WARN] DBSCAN ha trovato solo {len(top)} cluster validi (meno di {c}).\")\n",
    "    return top\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 4) Funzione per disegnare i cluster in 2D con MDS\n",
    "# -----------------------------------------------\n",
    "\n",
    "def plot_mds_clusters(features, cluster_labels, top_clusters, metric='euclidean'):\n",
    "    \"\"\"\n",
    "    features: array (N, d) delle feature originali (non PCA), normalizzazione interna.\n",
    "    cluster_labels: array (N,) con i risultati DBSCAN.\n",
    "    top_clusters: lista di interi corrispondenti ai cluster \"significativi\".\n",
    "    metric: tipo di distanza per l’MDS (default 'euclidean').\n",
    "    Plotta un scatter 2D dove i punti di top_clusters hanno colori diversi,\n",
    "    tutti gli altri (rumore o cluster secondari) appaiono in grigio chiaro.\n",
    "    \"\"\"\n",
    "    # 1) Normalizzo / scalizzo le feature originali\n",
    "    scaler = StandardScaler()\n",
    "    features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "    # 2) Applico MDS (2D) su features_scaled\n",
    "    mds = MDS(n_components=2, random_state=42, dissimilarity=metric)\n",
    "    Y = mds.fit_transform(features_scaled)\n",
    "\n",
    "    # 3) Scatterno i punti\n",
    "    import matplotlib\n",
    "    cmap = matplotlib.colormaps['tab10']\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    for i in range(len(Y)):\n",
    "        lbl = cluster_labels[i]\n",
    "        if lbl in top_clusters:\n",
    "            color_idx = top_clusters.index(lbl)\n",
    "            plt.scatter(Y[i, 0], Y[i, 1], color=cmap(color_idx), s=30, edgecolor='k', linewidth=0.2)\n",
    "        else:\n",
    "            # rumore (-1) o cluster non top\n",
    "            plt.scatter(Y[i, 0], Y[i, 1], color='lightgray', s=8)\n",
    "\n",
    "    plt.title(f\"MDS 2D – Top {len(top_clusters)} cluster\")\n",
    "    plt.xlabel(\"MDS dimension 1\")\n",
    "    plt.ylabel(\"MDS dimension 2\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------------------------------\n",
    "# 5) Funzione per visualizzare miniature per ciascun cluster\n",
    "# -----------------------------------------------\n",
    "\n",
    "def show_cluster_thumbnails(images, cluster_labels, top_clusters, thumb_size=(64, 64)):\n",
    "    \"\"\"\n",
    "    images: lista (o array) di percorsi file (lunghezza N), \n",
    "            ossia images[i] corrisponde a features[i].\n",
    "    cluster_labels: array (N,) di interi per ogni immagine.\n",
    "    top_clusters: lista di interi che vogliamo visualizzare.\n",
    "    thumb_size: dimensione (w, h) di ogni miniatura.\n",
    "    Per ciascun cluster in top_clusters stampa a video una griglia di miniature.\n",
    "    \"\"\"\n",
    "    for cluster_id in top_clusters:\n",
    "        # Indici delle immagini appartenenti a questo cluster\n",
    "        idxs = [i for i, cl in enumerate(cluster_labels) if cl == cluster_id]\n",
    "        print(f\"[INFO] Cluster {cluster_id}: {len(idxs)} immagini trovate\")\n",
    "\n",
    "        max_display = min(len(idxs), 16)\n",
    "        if max_display == 0:\n",
    "            continue\n",
    "\n",
    "        n = int(np.ceil(np.sqrt(max_display)))  # dimensione griglia n×n\n",
    "        plt.figure(figsize=(n * 1.5, n * 1.5))\n",
    "\n",
    "        for j, i_img in enumerate(idxs[:max_display]):\n",
    "            try:\n",
    "                img = Image.open(images[i_img]).convert('RGB')\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Impossibile aprire {images[i_img]}: {e}\")\n",
    "                continue\n",
    "\n",
    "            img_thumb = img.resize(thumb_size, Image.LANCZOS)\n",
    "            ax = plt.subplot(n, n, j + 1)\n",
    "            plt.imshow(img_thumb)\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.suptitle(f\"Cluster {cluster_id} – {len(idxs)} immagini (mostrate: {max_display})\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# ================================\n",
    "# 6) BLOCCHETTO PRINCIPALE PER TASK 8\n",
    "# ================================\n",
    "\n",
    "# 6.1) Parametri DBSCAN + PCA + numero di cluster da visualizzare\n",
    "eps = 5.0            # DBSCAN eps (distanza massima per considerare punti vicini)\n",
    "min_samples = 5      # DBSCAN min_samples (numero minimo di punti per formare un cluster)\n",
    "n_components = 50    # quante componenti PCA mantenere prima di DBSCAN\n",
    "c = 5                # quanti cluster più voluminosi voglio visualizzare per ciascuna label\n",
    "\n",
    "# 6.2) Directory di output (facoltativa, per salvare figure o miniature)\n",
    "output_base = \"./results_task8\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# 6.3) Carico features di Part1 e Part2\n",
    "feat_matrix_part1, lbls_part1, flname_part1 = load_features(\"color_moments_part1.npz\")\n",
    "feat_matrix_part2, lbls_part2, flname_part2 = load_features(\"color_moments_part2.npz\")\n",
    "\n",
    "# 6.4) Costruisco lista di tutti i percorsi completi delle immagini di Part1\n",
    "base_folder = \"Part1\"  # modifica se il percorso è diverso (es. \"/mnt/data/Part1\")\n",
    "images_full = [\n",
    "    os.path.join(base_folder, lbl, fname)\n",
    "    for fname, lbl in zip(flname_part1, lbls_part1)\n",
    "]\n",
    "\n",
    "# 6.5) Pre‐elaborazione delle feature di Part1: centering + L2 normalization\n",
    "mean_vec = np.mean(feat_matrix_part1, axis=0)\n",
    "feat_centered = feat_matrix_part1 - mean_vec\n",
    "feat_normed = normalize(feat_centered, norm='l2', axis=1)  # (N1, D)\n",
    "\n",
    "# 6.6) Prendo tutte le label uniche di Part1 (es. [\"brain_glioma\", \"brain_menin\", ...])\n",
    "unique_labels = np.unique(lbls_part1)\n",
    "\n",
    "# 6.7) Per ciascuna label, filtro le righe corrispondenti e applico PCA+DBSCAN\n",
    "for lbl in unique_labels:\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(f\"[INFO] Elaboro label: {lbl}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "    # 6.7.1) Indici di Part1 corrispondenti a questa label\n",
    "    mask_lbl = (lbls_part1 == lbl)\n",
    "    features_label = feat_matrix_part1[mask_lbl]   # shape = (n_i, D)\n",
    "    images_label   = np.array(images_full)[mask_lbl]  # tutti i percorsi di file per questa label\n",
    "\n",
    "    # 6.7.2) Se non ci sono abbastanza immagini, salto\n",
    "    if features_label.shape[0] < min_samples:\n",
    "        print(f\"[WARN] Solo {features_label.shape[0]} immagini per label '{lbl}' < min_samples; salto.\")\n",
    "        continue\n",
    "\n",
    "    # 6.7.3) Applico PCA + DBSCAN sui vettori originali (senza normalizzazione)\n",
    "    # Nota: qui uso direttamente features_label (900‐dim Raw). Se vuoi usare feat_normed,\n",
    "    # devi indicizzare nello stesso ordine; in ogni caso per DBSCAN va bene anche raw + scaling interno.\n",
    "    cluster_labels = apply_dbscan_with_pca(\n",
    "        features_label,\n",
    "        eps=eps,\n",
    "        min_samples=min_samples,\n",
    "        n_components=n_components\n",
    "    )\n",
    "    unique_clusters = np.unique(cluster_labels)\n",
    "    print(f\"[INFO] Cluster-labels trovati: {unique_clusters}\")\n",
    "\n",
    "    # 6.7.4) Individuo i c cluster più voluminosi (escludendo -1)\n",
    "    top_clusters = top_c_clusters(cluster_labels, c)\n",
    "    print(f\"[INFO] Top {c} cluster (per dimensione): {top_clusters}\")\n",
    "\n",
    "    # 6.7.5) MDS 2D dei punti di questa label con i cluster evidenziati\n",
    "    print(f\"[INFO] Disegno MDS 2D per i cluster di '{lbl}' …\")\n",
    "    plot_mds_clusters(\n",
    "        features_label,\n",
    "        cluster_labels,\n",
    "        top_clusters,\n",
    "        metric='euclidean'\n",
    "    )\n",
    "    # Se vuoi salvare il grafico anziché visualizzarlo, sostituisci plt.show() con:\n",
    "    # plt.savefig(os.path.join(output_base, f\"{lbl}_MDS_clusters.png\"))\n",
    "    # plt.close()\n",
    "\n",
    "    # 6.7.6) Mostro le miniature dei top_clusters\n",
    "    print(f\"[INFO] Genero miniature per ciascun cluster di '{lbl}' …\")\n",
    "    show_cluster_thumbnails(\n",
    "        images_label,            # lista di percorsi\n",
    "        cluster_labels,          # array di lunghezza n_i\n",
    "        top_clusters,            # i cluster “significativi” selezionati\n",
    "        thumb_size=(64, 64)\n",
    "    )\n",
    "    # Se vuoi salvare le miniature anziché mostrare con plt.show(), puoi modificare\n",
    "    # show_cluster_thumbnails per usare plt.savefig() in un path dedicato.\n",
    "\n",
    "print(\"\\n[FINITO] Task 8 completato per tutte le label di Part1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def0437",
   "metadata": {},
   "source": [
    "task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bdcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imposta il valore di m per l'm-NN\n",
    "m = 5  # Modifica questo valore in base alle tue necessità\n",
    "\n",
    "# Addestramento m-NN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=m)\n",
    "knn_model.fit(feat_matrix_part1, lbls_part1)\n",
    "\n",
    "# Addestramento Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(feat_matrix_part1, lbls_part1)\n",
    "\n",
    "# Predizioni su Part2\n",
    "pred_knn = knn_model.predict(feat_matrix_part2)\n",
    "pred_dt = dt_model.predict(feat_matrix_part2)\n",
    "\n",
    "# Valutazione m-NN\n",
    "print(\"Risultati m-NN:\")\n",
    "print(classification_report(lbls_part2, pred_knn))\n",
    "print(\"Accuratezza complessiva m-NN:\", accuracy_score(lbls_part2, pred_knn))\n",
    "\n",
    "# Valutazione Decision Tree\n",
    "print(\"Risultati Decision Tree:\")\n",
    "print(classification_report(lbls_part2, pred_dt))\n",
    "print(\"Accuratezza complessiva Decision Tree:\", accuracy_score(lbls_part2, pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e18743",
   "metadata": {},
   "source": [
    "Task10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ce167b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe LSH con quantizzazione\n",
    "\n",
    "class LSH_EuclideanQuantized:\n",
    "    \"\"\"\n",
    "    LSH per distanza Euclidea (p-stable) con bucket width r.\n",
    "    Ogni hash h_j(v) = floor((a_j · v + b_j) / r).\n",
    "\n",
    "    Parametri:\n",
    "      - num_layers   = L = numero di tavole hash\n",
    "      - num_hashes   = h = numero di functions concatenati in ciascuna tavola\n",
    "      - dim          = D = dimensione dei vettori di input\n",
    "      - r            = bucket width (parte intera di quantizzazione)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers: int, num_hashes: int, dim: int, r: float):\n",
    "        self.L = num_layers\n",
    "        self.h = num_hashes\n",
    "        self.d = dim\n",
    "        self.r = r\n",
    "\n",
    "        # Prepara L tavole hash: ciascuna è un dict (chiave tuple di h interi -> lista di indici)\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.L)]\n",
    "\n",
    "        # Per ogni layer l=0..L-1, e per ogni j=0..h-1, genero:\n",
    "        #   - a_lj  vettore gaussiano di dimensione D\n",
    "        #   - b_lj  offset (uniforme in [0, r) )\n",
    "        self.a_vectors = [\n",
    "            [np.random.randn(self.d) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "        self.b_offsets = [\n",
    "            [np.random.uniform(0, self.r) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "\n",
    "        # Memorizzerò i vettori originali di Part1 in questo array, shape=(N, D)\n",
    "        self.data_vectors = None\n",
    "\n",
    "    def _compute_hash_tuple(self, vec: np.ndarray, layer_idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Calcola l'hash (h interi) per il layer layer_idx su un vettore vec:\n",
    "          h_j = floor((a_vectors[layer_idx][j] · vec + b_offsets[layer_idx][j]) / r)\n",
    "        Ritorna una tupla di h interi.\n",
    "        \"\"\"\n",
    "        keys = []\n",
    "        a_vs = self.a_vectors[layer_idx]\n",
    "        b_os = self.b_offsets[layer_idx]\n",
    "        for j in range(self.h):\n",
    "            a_j = a_vs[j]         # vettore dimensione D\n",
    "            b_j = b_os[j]         # float in [0, r)\n",
    "            proj = float(np.dot(a_j, vec) + b_j)\n",
    "            h_val = int(np.floor(proj / self.r))\n",
    "            keys.append(h_val)\n",
    "        return tuple(keys)\n",
    "\n",
    "    def index(self, vectors: np.ndarray):\n",
    "        \"\"\"\n",
    "        Costruisci l'indice LSH su un insieme di vettori di Part1:\n",
    "          vectors: numpy array shape = (N, D)\n",
    "        Al termine di questa chiamata:\n",
    "          - self.data_vectors = vectors\n",
    "          - self.hash_tables[l][hash_tuple] conterrà la lista di indici i per cui\n",
    "            hash_tuple = _compute_hash_tuple(vectors[i], l).\n",
    "        \"\"\"\n",
    "        self.data_vectors = vectors\n",
    "        N, D = vectors.shape\n",
    "        assert D == self.d, f\"Errore: dimensione vettore ({D}) ≠ atteso ({self.d}).\"\n",
    "\n",
    "        # Inserisco ogni vettore in ciascuna tavola hash\n",
    "        for idx in range(N):\n",
    "            v = vectors[idx]\n",
    "            for l in range(self.L):\n",
    "                key = self._compute_hash_tuple(v, l)\n",
    "                self.hash_tables[l][key].append(idx)\n",
    "\n",
    "    def query(self, q_vec: np.ndarray, top_t: int = 5):\n",
    "        \"\"\"\n",
    "        Esegui una query LSH per cercare i top_t vettori più vicini a q_vec.\n",
    "        Restituisce:\n",
    "          - top_results: lista di tuple (indice, distanza) ord. per dist. crescente\n",
    "          - unique_count: numero di indici distinti considerati (cardinalità dei candidati)\n",
    "          - total_checked: somma della lunghezza di tutti i bucket esaminati\n",
    "        \"\"\"\n",
    "        assert q_vec.shape[0] == self.d, \"Errore: dimensione query ≠ D.\"\n",
    "        candidati = set()\n",
    "        total_checked = 0\n",
    "\n",
    "        # Per ciascun layer, ottengo la chiave polidimensionale e i suoi bucket\n",
    "        for l in range(self.L):\n",
    "            h_tuple = self._compute_hash_tuple(q_vec, l)\n",
    "            bucket = self.hash_tables[l].get(h_tuple, [])\n",
    "            total_checked += len(bucket)\n",
    "            candidati.update(bucket)\n",
    "\n",
    "        # Ora calcolo la distanza euclidea esatta tra q_vec e ciascun candidato\n",
    "        risultati = []\n",
    "        for idx in candidati:\n",
    "            v_i = self.data_vectors[idx]\n",
    "            dist = np.linalg.norm(v_i - q_vec)\n",
    "            risultati.append((idx, dist))\n",
    "\n",
    "        # Ordino e prendo i primi top_t\n",
    "        risultati.sort(key=lambda x: x[1])\n",
    "        top_results = risultati[:top_t]\n",
    "        return top_results, len(candidati), total_checked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "99704571",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_vec.shape = (1000,)\n",
      "[INFO] LSH quantizzato costruito: D=1000, L=10, h=12, r=0.2\n"
     ]
    }
   ],
   "source": [
    "# costruzione LSH_EuclideanQuantized su Part1\n",
    "\n",
    "# 1) (Opzionale ma consigliato) centra e normalizza i vettori di Part1\n",
    "#    Questo passaggio riduce l'effetto di scale diverse e spesso migliora la qualità LSH\n",
    "mean_vec = np.mean(feat_matrix_part1, axis=0)\n",
    "print(\"mean_vec.shape =\", mean_vec.shape)\n",
    "feat_centered = feat_matrix_part1 - mean_vec\n",
    "feat_normed = normalize(feat_centered, norm='l2', axis=1)\n",
    "\n",
    "# 2) Parametri LSH\n",
    "D = feat_normed.shape[1]      # di solito 900\n",
    "L = 10                         # numero di tavole hash (scegli in base a esperimenti)\n",
    "h = 12                        # numero di funzioni concatenati in ciascuna tavola\n",
    "r = 0.2                       # parametro di larghezza (esempio: 0.5); puoi sperimentare\n",
    "\n",
    "# 3) Creo l'oggetto e indicizzo\n",
    "lsh_quant = LSH_EuclideanQuantized(num_layers=L, num_hashes=h, dim=D, r=r)\n",
    "lsh_quant.index(feat_normed)\n",
    "\n",
    "print(f\"[INFO] LSH quantizzato costruito: D={D}, L={L}, h={h}, r={r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a2c91f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_lsh_quant(base_folder: str, img_path: str, k: int):\n",
    "    \"\"\"\n",
    "    Trova le k immagini più simili a img_path (di Part2) usando lsh_quant costruito su Part1.\n",
    "    \"\"\"\n",
    "    # 1) Estrai feature raw (900-dim)\n",
    "    raw_q = np.array(extract_fc_features_from_image(img_path, model, preprocess, device), dtype=np.float32)\n",
    "\n",
    "    # 2) Center + normalize (stesso mean_vec usato su Part1)\n",
    "    print(\"raw_q.shape =\", raw_q.shape)        # ad esempio (1024,)\n",
    "    print(\"mean_vec.shape =\", mean_vec.shape)  # ad esempio (900,) o (2048,) o altro\n",
    "    q_centered = raw_q - mean_vec\n",
    "    q_normed = q_centered / np.linalg.norm(q_centered)\n",
    "\n",
    "    # 3) Chiamata LSH\n",
    "    top_results, unique_count, total_checked = lsh_quant.query(q_normed, top_t=k)\n",
    "\n",
    "    # 4) Stampo i risultati testuali\n",
    "    print(f\"\\n[LSH-Quant] Top {k} simili a: {img_path}\")\n",
    "    for rank, (idx, dist) in enumerate(top_results, start=1):\n",
    "        label = lbls_part1[idx]\n",
    "        fname = flname_part1[idx]\n",
    "        print(f\"  {rank}. {fname} | Classe: {label} | Distanza Euclidea: {dist:.2f}\")\n",
    "    print(f\"[LSH-Quant] Immagini uniche considerate: {unique_count}\")\n",
    "    print(f\"[LSH-Quant] Immagini totali controllate: {total_checked}\")\n",
    "\n",
    "    # 5) Visualizzazione (query + k risultati)\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(4*(k+1), 4))\n",
    "    img_q = cv2.imread(img_path)\n",
    "    img_q = cv2.cvtColor(img_q, cv2.COLOR_BGR2RGB)\n",
    "    axs[0].imshow(img_q)\n",
    "    axs[0].set_title(\"Query (LSH-Quant)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, (idx, dist) in enumerate(top_results, start=1):\n",
    "        lab = lbls_part1[idx]\n",
    "        fname = flname_part1[idx]\n",
    "        full_path = os.path.join(base_folder, lab, fname)\n",
    "        img_match = cv2.imread(full_path)\n",
    "        img_match = cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(img_match)\n",
    "        axs[i].set_title(f\"Rank {i}\\nd={dist:.2f}\")\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4d442ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_q.shape = (2048,)\n",
      "mean_vec.shape = (1000,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2048,) (1000,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m                         \u001b[38;5;66;03m# numero di immagini simili da visualizzare\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Eseguo la ricerca LSH\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mfind_k_similar_lsh_quant\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPart1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[100], line 11\u001b[0m, in \u001b[0;36mfind_k_similar_lsh_quant\u001b[0;34m(base_folder, img_path, k)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_q.shape =\u001b[39m\u001b[38;5;124m\"\u001b[39m, raw_q\u001b[38;5;241m.\u001b[39mshape)        \u001b[38;5;66;03m# ad esempio (1024,)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_vec.shape =\u001b[39m\u001b[38;5;124m\"\u001b[39m, mean_vec\u001b[38;5;241m.\u001b[39mshape)  \u001b[38;5;66;03m# ad esempio (900,) o (2048,) o altro\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m q_centered \u001b[38;5;241m=\u001b[39m \u001b[43mraw_q\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmean_vec\u001b[49m\n\u001b[1;32m     12\u001b[0m q_normed \u001b[38;5;241m=\u001b[39m q_centered \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(q_centered)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 3) Chiamata LSH\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2048,) (1000,) "
     ]
    }
   ],
   "source": [
    "# Esempio di utilizzo su un'immagine di Part2 ---\n",
    "query_path = \"Part2/brain_glioma/brain_glioma_1409.jpg\"\n",
    "\n",
    "k = 3                         # numero di immagini simili da visualizzare\n",
    "\n",
    "# Eseguo la ricerca LSH\n",
    "find_k_similar_lsh_quant(\"Part1\", query_path, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd29dc",
   "metadata": {},
   "source": [
    "Index LSH costruito: 5 tabelle, 1 hash per tabella.\n",
    "\n",
    "----- Risultati LSH (Task 10) -----\n",
    "Query: brain_glioma_1409.jpg\n",
    "Num. candidati totali considerati (con duplicati): 784\n",
    "Num. candidati unici considerati: 703\n",
    "Indici dei top 5 vicini trovati: [355, 461, 958, 56, 920]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
