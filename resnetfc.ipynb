{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82eb29c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289ba4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_resnet_fc_features(img_path):\n",
    "    # Carica l'immagine e assicura la modalità RGB\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    \n",
    "    # Pre-processamento standard per ResNet: ridimensiona, ritaglia, trasforma in tensor e normalizza\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img_tensor = preprocess(img).unsqueeze(0)  # Aggiungi la dimensione del batch\n",
    "    \n",
    "    # Carica la ResNet50 pre-addestrata e mettila in modalità eval\n",
    "    resnet = models.resnet50(pretrained=True)\n",
    "    resnet.eval()\n",
    "    \n",
    "    # Lista per salvare l'output del layer fc\n",
    "    fc_output = []\n",
    "\n",
    "    # Definisci un hook che memorizza l'output del layer fc\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "    \n",
    "    # Registra il forward hook sul layer fully connected\n",
    "    hook = resnet.fc.register_forward_hook(hook_fn)\n",
    "    \n",
    "    # Passa l'immagine attraverso il modello\n",
    "    with torch.no_grad():\n",
    "        resnet(img_tensor)\n",
    "    \n",
    "    # Rimuovi l'hook (è buona norma pulirlo dopo l'uso)\n",
    "    hook.remove()\n",
    "    \n",
    "    # Il risultato è salvato in fc_output[0] con shape [1, 1000]. Rimuovi la dimensione del batch:\n",
    "    features = fc_output[0].squeeze(0)\n",
    "    \n",
    "    # Stampa e visualizza il vettore delle features\n",
    "    print(\"Vettore delle features (1000 elementi):\")\n",
    "    print(features.numpy())\n",
    "    \n",
    "    # Visualizzazione opzionale: ad esempio, un bar plot dei primi 20 valori\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(range(20), features.numpy()[:20])\n",
    "    plt.xlabel(\"Indice feature\")\n",
    "    plt.ylabel(\"Valore\")\n",
    "    plt.title(\"Prime 20 features del layer fc\")\n",
    "    plt.show()\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Esempio di esecuzione\n",
    "img_path = \"Part1/brain_glioma/brain_glioma_0002.jpg\"  # Sostituisci con il percorso corretto della tua immagine\n",
    "features = extract_resnet_fc_features(img_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f17dd",
   "metadata": {},
   "source": [
    "Task: 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f356f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from PIL import Image\n",
    "\n",
    "def extract_fc_features_from_image(image_path, model, preprocess, device):\n",
    "    \"\"\"\n",
    "    Apre l'immagine, la pre-processa e la passa attraverso la rete.\n",
    "    Utilizza un hook per catturare l'output del layer fully connected (fc) della ResNet.\n",
    "    Restituisce un vettore numpy di dimensione 1000.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore nell'apertura dell'immagine {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    \n",
    "    fc_output = []\n",
    "\n",
    "    # Definizione del hook per catturare l'output del layer fc\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "\n",
    "    hook = model.fc.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    # fc_output[0] ha forma [1, 1000], rimuoviamo la dimensione batch e riportiamo su CPU\n",
    "    features = fc_output[0].squeeze(0).cpu().numpy()\n",
    "    return features\n",
    "\n",
    "def main():\n",
    "    # Imposta il percorso della cartella base e le sottocartelle\n",
    "    base_dir = \"Part1\"\n",
    "    subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "    image_extensions = (\".jpg\", \".jpeg\", \".png\", \".bmp\")\n",
    "\n",
    "    image_paths = []\n",
    "    # Cerca le immagini all'interno delle sottocartelle specificate\n",
    "    for sub in subfolders:\n",
    "        dir_path = os.path.join(base_dir, sub)\n",
    "        if os.path.isdir(dir_path):\n",
    "            for root, _, files in os.walk(dir_path):\n",
    "                for file in files:\n",
    "                    if file.lower().endswith(image_extensions):\n",
    "                        image_paths.append(os.path.join(root, file))\n",
    "        else:\n",
    "            print(f\"La cartella {dir_path} non esiste.\")\n",
    "\n",
    "    if not image_paths:\n",
    "        print(\"Non sono state trovate immagini nelle cartelle specificate.\")\n",
    "        return\n",
    "\n",
    "    # Configura il dispositivo da utilizzare (GPU se disponibile, altrimenti CPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Definisci la trasformazione di pre-processing standard per ResNet\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Carica il modello ResNet50 pre-addestrato ed impostalo in modalità evaluation\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    # Prepara i dati che verranno salvati sul file CSV\n",
    "    csv_rows = []\n",
    "    # Crea l'header: la prima colonna è il percorso dell'immagine, le altre sono le feature\n",
    "    header = [\"image_path\"] + [f\"fc_feature_{i}\" for i in range(1000)]\n",
    "    csv_rows.append(header)\n",
    "\n",
    "    # Estrai le features per ogni immagine e conserva il risultato in una riga di CSV\n",
    "    for img_path in image_paths:\n",
    "        features = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "        if features is not None:\n",
    "            row = [img_path] + features.tolist()\n",
    "            csv_rows.append(row)\n",
    "        else:\n",
    "            print(f\"Errore nell'estrazione delle features da {img_path}\")\n",
    "\n",
    "    # Salva i risultati in un file CSV\n",
    "    csv_file = \"resnetfc.csv\"\n",
    "    try:\n",
    "        with open(csv_file, \"w\", newline=\"\") as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(csv_rows)\n",
    "        print(f\"Salvataggio completato in {csv_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Errore durante il salvataggio del file CSV: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
