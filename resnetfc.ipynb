{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82eb29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerie principali\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PyTorch & torchvision\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "# OpenCV\n",
    "import cv2\n",
    "\n",
    "# Similarità\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e468c50e",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee13a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se CUDA disponibile, usa la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carica ResNet50 pre-addestrata e in modalità eval\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1  # o DEFAULT per i pesi più aggiornati\n",
    "model = models.resnet50(weights=weights)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Preprocessing standard per ResNet\n",
    "preprocess = weights.transforms()\n",
    "\n",
    "\n",
    "#funzione di creazione dei file\n",
    "def load_features(npz_path):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    return data['features'], data['labels'], data.get('filenames', [f\"img_{i}\" for i in range(len(data['features']))])\n",
    "\n",
    "\n",
    "feat_matrix_part1, lbls_part1, flname_part1 = load_features(\n",
    "    \"resnetfc_part1.npz\")\n",
    "feat_matrix_part2, lbls_part2, flname_part2 = load_features(\n",
    "    \"resnetfc_part2.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7ad571",
   "metadata": {},
   "source": [
    "Funzione Estrazione Feature - Task 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fc_features_from_image(image_path, model, preprocess, device):\n",
    "    \"\"\"\n",
    "    Estrae le feature del layer fully connected (fc) di ResNet50 da un'immagine.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert(\"RGB\")\n",
    "    except Exception as e:\n",
    "        print(f\"[ERRORE] Immagine non valida {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "    img_tensor = preprocess(img).unsqueeze(0).to(device)\n",
    "    fc_output = []\n",
    "\n",
    "    def hook_fn(module, input, output):\n",
    "        fc_output.append(output)\n",
    "\n",
    "    hook = model.fc.register_forward_hook(hook_fn)\n",
    "    with torch.no_grad():\n",
    "        model(img_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    if fc_output:\n",
    "        return fc_output[0].squeeze(0).cpu().numpy()\n",
    "    else:\n",
    "        print(f\"[ERRORE] Nessun output FC per {image_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaa9a99",
   "metadata": {},
   "source": [
    "Elaborazione Batch e Salvataggio Feature in .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43f4f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    \"\"\"\n",
    "    Estrae le feature FC da immagini in più cartelle e salva in un file .npz.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_filenames = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"[ATTENZIONE] Cartella non trovata: {folder_path}\")\n",
    "            continue\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "                else:\n",
    "                    print(f\"[ERRORE] Feature non estratte da {img_path}\")\n",
    "\n",
    "    # Salva in file .npz\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    \n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")\n",
    "    print(f\"[FINE] Totale immagini processate: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685a7462",
   "metadata": {},
   "source": [
    " Retrieval: Immagini più Simili (distanza coseno) - Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7d97c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_cosine(img_path, k):\n",
    "    \"\"\"\n",
    "    Trova le k immagini più simili rispetto a una query, usando la distanza coseno.\n",
    "    \"\"\"\n",
    "    query_feature = extract_fc_features_from_image(img_path, model, preprocess, device)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Impossibile estrarre feature dalla query.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    distances = cosine_distances(feat_matrix_part1, query_feature).flatten()\n",
    "\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "    top_k_scores = distances[top_k_idx]\n",
    "\n",
    "    print(f\"\\nTop {k} immagini più simili a: {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {flname_part1[idx]} | Classe: {lbls_part1[idx]} | Distanza: {top_k_scores[rank]:.4f}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        match_img = cv2.imread(os.path.join(\"Part1\", lbls_part1[idx], flname_part1[idx]))\n",
    "        axs[i+1].imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[i+1].set_title(f\"Rank {i+1}\\nD={top_k_scores[i]:.4f}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855f245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri cartelle e output\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "\n",
    "# Estrazione e salvataggio\n",
    "process_and_save_features(\"Part1\", subfolders, \"resnetfc_part1\")\n",
    "process_and_save_features(\"Part2\", subfolders, \"resnetfc_part2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a9092d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test su immagine di query\n",
    "query_img = \"Part1/brain_glioma/brain_glioma_0017.jpg\"\n",
    "find_k_similar_cosine(query_img, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969a47de",
   "metadata": {},
   "source": [
    "Task 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def task4_predict_labels_resnetfc(query_img_path, k, extractor_fn, features, labels, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Predict top-k labels for query image using ResNet FC features.\n",
    "    extractor_fn: funzione che prende image_path e restituisce feature numpy array\n",
    "    features: matrice numpy (N, d)\n",
    "    labels: array di stringhe (N,)\n",
    "    metric: \"euclidean\" o \"cosine\"\n",
    "    \"\"\"\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "    print(f\"\\n======== PREDIZIONE PER: {os.path.basename(query_img_path)} ========\")\n",
    "\n",
    "    def compute_metric(query_feat, target_feats, metric):\n",
    "        query_feat = query_feat.reshape(1, -1)\n",
    "        if metric == \"euclidean\":\n",
    "            # distanza euclidea tra query_feat e tutti target_feats\n",
    "            return np.linalg.norm(target_feats - query_feat, axis=1)\n",
    "        elif metric == \"cosine\":\n",
    "            # similarità coseno tra query_feat e tutti target_feats\n",
    "            # sim = (A·B) / (|A||B|), distanza = 1 - sim\n",
    "            dot_prod = np.dot(target_feats, query_feat.T).flatten()\n",
    "            norm_feats = np.linalg.norm(target_feats, axis=1)\n",
    "            norm_query = np.linalg.norm(query_feat)\n",
    "            cosine_sim = dot_prod / (norm_feats * norm_query + 1e-10)\n",
    "            cosine_dist = 1 - cosine_sim  # distanza coseno\n",
    "            return cosine_dist\n",
    "        else:\n",
    "            raise ValueError(\"Metric must be 'euclidean' or 'cosine'\")\n",
    "\n",
    "    def predict_top_k_labels_distance_mean(query_img_path, k, features, labels, metric):\n",
    "        query_feat = extractor_fn(query_img_path)\n",
    "        if query_feat is None:\n",
    "            print(\"[ERRORE] Feature non estratte.\")\n",
    "            return\n",
    "        unique_labels = np.unique(labels)\n",
    "        scores = []\n",
    "        for label in unique_labels:\n",
    "            class_feats = features[labels == label]\n",
    "            dists = compute_metric(query_feat, class_feats, metric)\n",
    "            scores.append(dists.mean())\n",
    "        if metric == \"euclidean\":\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        else:  # cosine distanza: più piccola è meglio\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        print(f\"\\n[STRATEGIA: distanza media - metrica: {metric}]\")\n",
    "        for idx in top_k:\n",
    "            print(f\"Classe: {unique_labels[idx]} | Score medio: {scores[idx]:.4f}\")\n",
    "\n",
    "    def predict_top_k_labels_prototype(query_img_path, k, features, labels, metric):\n",
    "        query_feat = extractor_fn(query_img_path)\n",
    "        if query_feat is None:\n",
    "            print(\"[ERRORE] Feature non estratte.\")\n",
    "            return\n",
    "        unique_labels = np.unique(labels)\n",
    "        prototypes = []\n",
    "        for label in unique_labels:\n",
    "            class_feats = features[labels == label]\n",
    "            prototypes.append(class_feats.mean(axis=0))\n",
    "        prototypes = np.vstack(prototypes)\n",
    "        scores = compute_metric(query_feat, prototypes, metric)\n",
    "        if metric == \"euclidean\":\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        else:\n",
    "            top_k = np.argsort(scores)[:k]\n",
    "        print(f\"\\n[STRATEGIA: prototipo di classe - metrica: {metric}]\")\n",
    "        for idx in top_k:\n",
    "            print(f\"Classe: {unique_labels[idx]} | Score: {scores[idx]:.4f}\")\n",
    "\n",
    "    predict_top_k_labels_distance_mean(query_img_path, k, features, labels, metric)\n",
    "    predict_top_k_labels_prototype(query_img_path, k, features, labels, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984b9fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_menin/brain_menin_1202.jpg\"\n",
    "task4_predict_labels_resnetfc(\n",
    "    query_img, k=2,\n",
    "    extractor_fn=lambda img: extract_fc_features_from_image(img, model, preprocess, device),\n",
    "    features=feat_matrix_part1,\n",
    "    labels=lbls_part1,\n",
    "    metric=\"euclidean\"\n",
    ")\n",
    "\n",
    "task4_predict_labels_resnetfc(\n",
    "    query_img, k=2,\n",
    "    extractor_fn=lambda img: extract_fc_features_from_image(img, model, preprocess, device),\n",
    "    features=feat_matrix_part1,\n",
    "    labels=lbls_part1,\n",
    "    metric=\"cosine\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1696ac9c",
   "metadata": {},
   "source": [
    "Task 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a11ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def task5_latent_semantics_resnetfc(feature_model_path, technique, k):\n",
    "    data = np.load(feature_model_path, allow_pickle=True)\n",
    "    feature_matrix = data['features']\n",
    "    filenames = data['filenames']\n",
    "    labels = data['labels']\n",
    "    technique = technique.lower()\n",
    "\n",
    "    if technique == \"svd\":\n",
    "        model = TruncatedSVD(n_components=k, random_state=42)\n",
    "        X_transformed = model.fit_transform(feature_matrix)\n",
    "        components = model.components_\n",
    "        method = \"svd\"\n",
    "\n",
    "    elif technique == \"lda\":\n",
    "        unique_labels = np.unique(labels)\n",
    "        max_k = len(unique_labels) - 1\n",
    "        if k > max_k:\n",
    "            print(f\"[ATTENZIONE] LDA supporta al massimo {max_k} componenti con {len(unique_labels)} classi.\")\n",
    "            k = max_k\n",
    "        model = LDA(n_components=k)\n",
    "        X_transformed = model.fit_transform(feature_matrix, labels)\n",
    "        components = model.scalings_.T[:k]\n",
    "        method = \"lda\"\n",
    "\n",
    "    elif technique == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "        model.fit(feature_matrix)\n",
    "        components = model.cluster_centers_\n",
    "        X_transformed = model.transform(feature_matrix)\n",
    "        method = \"kmeans\"\n",
    "    else:\n",
    "        print(\"[ERRORE] Tecnica non supportata. Usa: 'svd', 'lda', 'kmeans'\")\n",
    "        return\n",
    "\n",
    "    if technique in [\"svd\", \"lda\"]:\n",
    "        plot_latent_space_2d(X_transformed, labels, technique, k)\n",
    "    elif technique == \"kmeans\":\n",
    "        plot_kmeans_clusters_2d(feature_matrix, labels, k)\n",
    "\n",
    "    base_name = os.path.splitext(os.path.basename(feature_model_path))[0]\n",
    "    out_file = f\"latent_semantics_{method}_{base_name}_k{k}.txt\"\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for i in range(k):\n",
    "            f.write(f\"\\n--- Latent Semantic {i+1} ---\\n\")\n",
    "            if technique in [\"svd\", \"lda\"]:\n",
    "                weights = feature_matrix @ components[i].T\n",
    "            else:\n",
    "                weights = -X_transformed[:, i]  # distanza inversa\n",
    "            sorted_idx = np.argsort(-np.abs(weights))\n",
    "            for idx in sorted_idx:\n",
    "                f.write(f\"{filenames[idx]} | Peso: {weights[idx]:.4f} | Classe: {labels[idx]}\\n\")\n",
    "\n",
    "    print(f\"[SALVATO] Latent semantics salvati in: {out_file}\")\n",
    "\n",
    "\n",
    "def plot_latent_space_2d(X_transformed, labels, technique, k):\n",
    "    if X_transformed.shape[1] < 2:\n",
    "        print(\"[INFO] Meno di 2 componenti: impossibile visualizzare in 2D.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_transformed[:, 0], y=X_transformed[:, 1], hue=labels, palette=\"Set2\", s=80)\n",
    "    plt.title(f\"{technique.upper()} - Proiezione sulle prime 2 componenti latenti (k={k})\")\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_kmeans_clusters_2d(feature_matrix, labels, n_clusters):\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(feature_matrix)\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=cluster_labels, palette='tab10', s=80, style=labels)\n",
    "    plt.title(f\"KMeans Clustering (k={n_clusters}) con proiezione SVD 2D\")\n",
    "    plt.xlabel(\"Componente Latente 1 (da SVD)\")\n",
    "    plt.ylabel(\"Componente Latente 2 (da SVD)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659b9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "task5_latent_semantics_resnetfc(\"resnetfc_part1.npz\", technique=\"svd\", k=5)\n",
    "task5_latent_semantics_resnetfc(\"resnetfc_part1.npz\", technique=\"lda\", k=2)\n",
    "task5_latent_semantics_resnetfc(\"resnetfc_part1.npz\", technique=\"kmeans\", k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872f36c",
   "metadata": {},
   "source": [
    "task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4073e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_intrinsic_dimensionality(feature_matrix, threshold, plot=True):\n",
    "    max_components = min(feature_matrix.shape)\n",
    "    pca = PCA(n_components=max_components)\n",
    "    pca.fit(feature_matrix)\n",
    "\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    cumulative = np.cumsum(explained)\n",
    "    intrinsic_dim = np.argmax(cumulative >= threshold) + 1\n",
    "\n",
    "    #print(f\"[INFO] Spiegazione varianza per ogni componente PCA:\\n{explained}\")\n",
    "    #print(f\"[INFO] Varianza cumulativa:\\n{cumulative}\")\n",
    "    #print(f\"[INFO] Soglia impostata: {threshold}\")\n",
    "    #print(f\"[INFO] Dimensione intrinseca stimata: {intrinsic_dim}\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(cumulative, marker='o', label=\"Varianza cumulativa\")\n",
    "        plt.axhline(y=threshold, color='r', linestyle='--', label=f\"Soglia {threshold*100:.0f}%\")\n",
    "        plt.axvline(x=intrinsic_dim, color='g', linestyle='--', label=f\"k suggerito: {intrinsic_dim}\")\n",
    "        plt.xlabel(\"Numero componenti\")\n",
    "        plt.ylabel(\"Varianza cumulativa\")\n",
    "        plt.title(\"Scelta ottimale di k (PCA/SVD)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"[INFO] k ottimale suggerito (soglia {threshold*100:.0f}%): {intrinsic_dim}\")\n",
    "    return intrinsic_dim, cumulative\n",
    "\n",
    "def suggest_k(feature_matrix, threshold_list=[0.90, 0.95, 0.99]):\n",
    "    print(f\"[INFO] Feature matrix shape: {feature_matrix.shape}\")\n",
    "    k_values = {}\n",
    "    for t in threshold_list:\n",
    "        k, _ = estimate_intrinsic_dimensionality(feature_matrix, threshold=t, plot=False)\n",
    "        k_values[t] = k\n",
    "        print(f\"Soglia {int(t*100)}% : k = {k}\")\n",
    "    return k_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9585c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dimensionality_per_label(feature_matrix, labels, threshold):\n",
    "    label_dim_map = {}\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"[INFO] Etichette uniche trovate: {len(unique_labels)}\")\n",
    "\n",
    "    for label in unique_labels:\n",
    "        indices = np.where(labels == label)[0]\n",
    "        label_features = feature_matrix[indices]\n",
    "\n",
    "        if len(indices) < 2:\n",
    "            print(f\"[AVVISO] Label '{label}' ha meno di 2 campioni — ignorata.\")\n",
    "            continue\n",
    "\n",
    "        k, _ = estimate_intrinsic_dimensionality(label_features, threshold=threshold, plot=False)\n",
    "        label_dim_map[label] = k\n",
    "        print(f\" Label '{label}' : k = {k}\")\n",
    "\n",
    "    return label_dim_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428759c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola k per varie soglie\n",
    "print(\"\\Stima automatica di k in base alla varianza spiegata:\\n\")\n",
    "k_suggeriti = suggest_k(feat_matrix_part1)\n",
    "# Plot dettagliato per la soglia 95%\n",
    "estimate_intrinsic_dimensionality(feat_matrix_part1, threshold=0.95, plot=True)\n",
    "\n",
    "\n",
    "print(\"\\n Task 6b – Dimensionalità per etichetta:\\n\")\n",
    "label_dimensionalities = estimate_dimensionality_per_label(feat_matrix_part1, lbls_part1, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999c608a",
   "metadata": {},
   "source": [
    "Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c39581",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_latent_semantics_per_class(X, y, k=10):\n",
    "    class_models = {}\n",
    "    class_means = {}\n",
    "\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        X_class = X[y == label]  # Istanze della classe corrente\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_class)\n",
    "\n",
    "        svd = TruncatedSVD(n_components=k, random_state=42)\n",
    "        latent = svd.fit_transform(X_scaled)\n",
    "\n",
    "        # Salva scaler, SVD e i vettori latenti per la classe\n",
    "        class_models[label] = {\n",
    "            'scaler': scaler,\n",
    "            'svd': svd,\n",
    "            'latent_vectors': latent\n",
    "        }\n",
    "        # Calcola centroide nello spazio latente\n",
    "        class_means[label] = np.mean(latent, axis=0)\n",
    "    return class_models, class_means\n",
    "\n",
    "\n",
    "def predict_label(X_test, class_models, class_means):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        best_label = None\n",
    "        min_dist = float('inf')\n",
    "        for label, model in class_models.items():\n",
    "            x_scaled = model['scaler'].transform(x.reshape(1, -1))\n",
    "            x_latent = model['svd'].transform(x_scaled)\n",
    "            dist = np.linalg.norm(x_latent - class_means[label])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_label = label\n",
    "        y_pred.append(best_label)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    labels = np.unique(y_true)\n",
    "    print(\"Per-class metrics:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        print(f\"Class {label}: P={precision[i]:.2f}, R={recall[i]:.2f}, F1={f1[i]:.2f}\")\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}\\n\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "\"\"\" # ESEMPIO DI UTILIZZO:\n",
    "def run_task7_resnetfc(part1_path, part2_path, k=10):\n",
    "    X_train, y_train = part1['features'], part1['labels']\n",
    "    X_test, y_test = part2['features'], part2['labels']\n",
    "\n",
    "    # Addestramento\n",
    "    print(\"[INFO] Calcolo dei latent semantics per ciascuna classe...\")\n",
    "    class_models, class_means = compute_latent_semantics_per_class(X_train, y_train, k)\n",
    "\n",
    "    # Predizione\n",
    "    print(\"[INFO] Classificazione delle immagini di Part 2...\")\n",
    "    y_pred = predict_label(X_test, class_models, class_means)\n",
    "\n",
    "    # Valutazione\n",
    "    print(\"[INFO] Valutazione del sistema:\")\n",
    "    evaluate(y_test, y_pred)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c23056",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_task7_resnetfc(\"resnetfc_part1.npz\", \"resnetfc_part2.npz\", k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5def0437",
   "metadata": {},
   "source": [
    "task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40bdcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imposta il valore di m per l'm-NN\n",
    "m = 5  # Modifica questo valore in base alle tue necessità\n",
    "\n",
    "# Addestramento m-NN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=m)\n",
    "knn_model.fit(feat_matrix_part1, lbls_part1)\n",
    "\n",
    "# Addestramento Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(feat_matrix_part1, lbls_part1)\n",
    "\n",
    "# Predizioni su Part2\n",
    "pred_knn = knn_model.predict(feat_matrix_part2)\n",
    "pred_dt = dt_model.predict(feat_matrix_part2)\n",
    "\n",
    "# Valutazione m-NN\n",
    "print(\"Risultati m-NN:\")\n",
    "print(classification_report(lbls_part2, pred_knn))\n",
    "print(\"Accuratezza complessiva m-NN:\", accuracy_score(lbls_part2, pred_knn))\n",
    "\n",
    "# Valutazione Decision Tree\n",
    "print(\"Risultati Decision Tree:\")\n",
    "print(classification_report(lbls_part2, pred_dt))\n",
    "print(\"Accuratezza complessiva Decision Tree:\", accuracy_score(lbls_part2, pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e18743",
   "metadata": {},
   "source": [
    "Task10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce167b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe LSH con quantizzazione\n",
    "\n",
    "class LSH_EuclideanQuantized:\n",
    "    \"\"\"\n",
    "    LSH per distanza Euclidea (p-stable) con bucket width r.\n",
    "    Ogni hash h_j(v) = floor((a_j · v + b_j) / r).\n",
    "\n",
    "    Parametri:\n",
    "      - num_layers   = L = numero di tavole hash\n",
    "      - num_hashes   = h = numero di functions concatenati in ciascuna tavola\n",
    "      - dim          = D = dimensione dei vettori di input\n",
    "      - r            = bucket width (parte intera di quantizzazione)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers: int, num_hashes: int, dim: int, r: float):\n",
    "        self.L = num_layers\n",
    "        self.h = num_hashes\n",
    "        self.d = dim\n",
    "        self.r = r\n",
    "\n",
    "        # Prepara L tavole hash: ciascuna è un dict (chiave tuple di h interi -> lista di indici)\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.L)]\n",
    "\n",
    "        # Per ogni layer l=0..L-1, e per ogni j=0..h-1, genero:\n",
    "        #   - a_lj  vettore gaussiano di dimensione D\n",
    "        #   - b_lj  offset (uniforme in [0, r) )\n",
    "        self.a_vectors = [\n",
    "            [np.random.randn(self.d) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "        self.b_offsets = [\n",
    "            [np.random.uniform(0, self.r) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "\n",
    "        # Memorizzerò i vettori originali di Part1 in questo array, shape=(N, D)\n",
    "        self.data_vectors = None\n",
    "\n",
    "    def _compute_hash_tuple(self, vec: np.ndarray, layer_idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Calcola l'hash (h interi) per il layer layer_idx su un vettore vec:\n",
    "          h_j = floor((a_vectors[layer_idx][j] · vec + b_offsets[layer_idx][j]) / r)\n",
    "        Ritorna una tupla di h interi.\n",
    "        \"\"\"\n",
    "        keys = []\n",
    "        a_vs = self.a_vectors[layer_idx]\n",
    "        b_os = self.b_offsets[layer_idx]\n",
    "        for j in range(self.h):\n",
    "            a_j = a_vs[j]         # vettore dimensione D\n",
    "            b_j = b_os[j]         # float in [0, r)\n",
    "            proj = float(np.dot(a_j, vec) + b_j)\n",
    "            h_val = int(np.floor(proj / self.r))\n",
    "            keys.append(h_val)\n",
    "        return tuple(keys)\n",
    "\n",
    "    def index(self, vectors: np.ndarray):\n",
    "        \"\"\"\n",
    "        Costruisci l'indice LSH su un insieme di vettori di Part1:\n",
    "          vectors: numpy array shape = (N, D)\n",
    "        Al termine di questa chiamata:\n",
    "          - self.data_vectors = vectors\n",
    "          - self.hash_tables[l][hash_tuple] conterrà la lista di indici i per cui\n",
    "            hash_tuple = _compute_hash_tuple(vectors[i], l).\n",
    "        \"\"\"\n",
    "        self.data_vectors = vectors\n",
    "        N, D = vectors.shape\n",
    "        assert D == self.d, f\"Errore: dimensione vettore ({D}) ≠ atteso ({self.d}).\"\n",
    "\n",
    "        # Inserisco ogni vettore in ciascuna tavola hash\n",
    "        for idx in range(N):\n",
    "            v = vectors[idx]\n",
    "            for l in range(self.L):\n",
    "                key = self._compute_hash_tuple(v, l)\n",
    "                self.hash_tables[l][key].append(idx)\n",
    "\n",
    "    def query(self, q_vec: np.ndarray, top_t: int = 5):\n",
    "        \"\"\"\n",
    "        Esegui una query LSH per cercare i top_t vettori più vicini a q_vec.\n",
    "        Restituisce:\n",
    "          - top_results: lista di tuple (indice, distanza) ord. per dist. crescente\n",
    "          - unique_count: numero di indici distinti considerati (cardinalità dei candidati)\n",
    "          - total_checked: somma della lunghezza di tutti i bucket esaminati\n",
    "        \"\"\"\n",
    "        assert q_vec.shape[0] == self.d, \"Errore: dimensione query ≠ D.\"\n",
    "        candidati = set()\n",
    "        total_checked = 0\n",
    "\n",
    "        # Per ciascun layer, ottengo la chiave polidimensionale e i suoi bucket\n",
    "        for l in range(self.L):\n",
    "            h_tuple = self._compute_hash_tuple(q_vec, l)\n",
    "            bucket = self.hash_tables[l].get(h_tuple, [])\n",
    "            total_checked += len(bucket)\n",
    "            candidati.update(bucket)\n",
    "\n",
    "        # Ora calcolo la distanza euclidea esatta tra q_vec e ciascun candidato\n",
    "        risultati = []\n",
    "        for idx in candidati:\n",
    "            v_i = self.data_vectors[idx]\n",
    "            dist = np.linalg.norm(v_i - q_vec)\n",
    "            risultati.append((idx, dist))\n",
    "\n",
    "        # Ordino e prendo i primi top_t\n",
    "        risultati.sort(key=lambda x: x[1])\n",
    "        top_results = risultati[:top_t]\n",
    "        return top_results, len(candidati), total_checked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99704571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# costruzione LSH_EuclideanQuantized su Part1\n",
    "\n",
    "# 1) (Opzionale ma consigliato) centra e normalizza i vettori di Part1\n",
    "#    Questo passaggio riduce l'effetto di scale diverse e spesso migliora la qualità LSH\n",
    "mean_vec = np.mean(feat_matrix_part1, axis=0)\n",
    "feat_centered = feat_matrix_part1 - mean_vec\n",
    "feat_normed = normalize(feat_centered, norm='l2', axis=1)\n",
    "\n",
    "# 2) Parametri LSH\n",
    "D = feat_normed.shape[1]      # di solito 900\n",
    "L = 10                         # numero di tavole hash (scegli in base a esperimenti)\n",
    "h = 12                        # numero di funzioni concatenati in ciascuna tavola\n",
    "r = 0.2                       # parametro di larghezza (esempio: 0.5); puoi sperimentare\n",
    "\n",
    "# 3) Creo l'oggetto e indicizzo\n",
    "lsh_quant = LSH_EuclideanQuantized(num_layers=L, num_hashes=h, dim=D, r=r)\n",
    "lsh_quant.index(feat_normed)\n",
    "\n",
    "print(f\"[INFO] LSH quantizzato costruito: D={D}, L={L}, h={h}, r={r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0bdee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per cercare top_k con LSH quantizzato\n",
    "\n",
    "def find_k_similar_lsh_quant(base_folder: str, img_path: str, k: int):\n",
    "    \"\"\"\n",
    "    Cerca le k immagini di Part1 più simili a img_path (di Part2) usando LSH_EuclideanQuantized.\n",
    "    Stampa:\n",
    "      - i primi k risultati (file name, label, distanza)\n",
    "      - il numero di immagini uniche considerate\n",
    "      - il numero totale di controlli (somma delle lunghezze dei bucket)\n",
    "    E poi visualizza (query + k risultati) con matplotlib.\n",
    "    \"\"\"\n",
    "    # 1) Estrazione feature raw (900-dim) con la funzione esistente\n",
    "    raw_q = np.array(extract_fc_features_from_image(img_path, model, preprocess, device), dtype=np.float32)\n",
    "\n",
    "    # 2) Center + normalize (stesso mean_vec e L2 norm usati su Part1)\n",
    "    q_centered = raw_q - mean_vec\n",
    "    q_normed = q_centered / np.linalg.norm(q_centered)\n",
    "\n",
    "    # 3) Chiamata a LSH\n",
    "    top_results, unique_count, total_checked = lsh_quant.query(q_normed, top_t=k)\n",
    "\n",
    "    # 4) Stampa output testuale\n",
    "    print(f\"\\n[LSH-Quant] Top {k} simili a: {img_path}\")\n",
    "    for rank, (idx, dist) in enumerate(top_results, start=1):\n",
    "        label = lbls_part1[idx]\n",
    "        fname = flname_part1[idx]\n",
    "        print(f\"  {rank}. {fname} | Classe: {label} | Distanza Euclidea: {dist:.2f}\")\n",
    "    print(f\"[LSH-Quant] Immagini uniche considerate: {unique_count}\")\n",
    "    print(f\"[LSH-Quant] Immagini totali controllate: {total_checked}\")\n",
    "\n",
    "    # 5) Visualizzazione (query + primi k risultati)\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(4*(k+1), 4))\n",
    "    img_q = cv2.imread(img_path)\n",
    "    img_q = cv2.cvtColor(img_q, cv2.COLOR_BGR2RGB)\n",
    "    axs[0].imshow(img_q)\n",
    "    axs[0].set_title(\"Query (LSH-Quant)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, (idx, dist) in enumerate(top_results, start=1):\n",
    "        lab = lbls_part1[idx]\n",
    "        fname = flname_part1[idx]\n",
    "        full_path = os.path.join(base_folder, lab, fname)\n",
    "        img_match = cv2.imread(full_path)\n",
    "        img_match = cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(img_match)\n",
    "        axs[i].set_title(f\"Rank {i}\\nd={dist:.2f}\")\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d442ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio di utilizzo su un'immagine di Part2 ---\n",
    "query_path = \"Part2/brain_glioma/brain_glioma_1409.jpg\"\n",
    "\n",
    "k = 5                         # numero di immagini simili da visualizzare\n",
    "\n",
    "# Eseguo la ricerca LSH\n",
    "find_k_similar_lsh_quant(\"Part1\", query_path, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acd29dc",
   "metadata": {},
   "source": [
    "Index LSH costruito: 5 tabelle, 1 hash per tabella.\n",
    "\n",
    "----- Risultati LSH (Task 10) -----\n",
    "Query: brain_glioma_1409.jpg\n",
    "Num. candidati totali considerati (con duplicati): 784\n",
    "Num. candidati unici considerati: 703\n",
    "Indici dei top 5 vicini trovati: [355, 461, 958, 56, 920]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
