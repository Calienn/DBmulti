{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b047aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Built-in ===\n",
    "import os\n",
    "\n",
    "# === Third-party ===\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics.pairwise import euclidean_distances, cosine_distances\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "# === PyTorch ===\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c56c11",
   "metadata": {},
   "source": [
    "Classe per Estrazione delle Feature - Task 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetAvgPool1024Extractor:\n",
    "    def __init__(self):\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.model.eval()\n",
    "        self.feature = None\n",
    "        self.model.avgpool.register_forward_hook(self._hook_avgpool)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def _hook_avgpool(self, module, input, output):\n",
    "        self.feature = output.squeeze().detach().numpy()\n",
    "\n",
    "    def extract_feature(self, image_path):\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = self.transform(img).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(input_tensor)\n",
    "\n",
    "        feat_2048 = self.feature\n",
    "        return 0.5 * (feat_2048[::2] + feat_2048[1::2])  # Ridotto a 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a74ba",
   "metadata": {},
   "source": [
    "Estrazione,Salvataggio e Caricamneto delle Feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4708e174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    extractor = ResNetAvgPool1024Extractor()\n",
    "    all_features, all_filenames, all_labels = [], [], []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extractor.extract_feature(img_path)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    \n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")\n",
    "    print(f\"[FINE] Totale immagini processate: {len(all_features)}\")\n",
    "\n",
    "\n",
    "def load_features(file_path):\n",
    "    data = np.load(file_path, allow_pickle=True)\n",
    "    return data[\"features\"], data[\"filenames\"], data[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac58be",
   "metadata": {},
   "source": [
    "Visualizzazione dei Risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad30579",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matches(query_path, indices, labels, filenames, distances, metric_label):\n",
    "    k = len(indices)\n",
    "    fig, axs = plt.subplots(1, k + 1, figsize=(15, 5))\n",
    "\n",
    "    # Immagine query\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(query_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # Immagini simili\n",
    "    for i, idx in enumerate(indices):\n",
    "        img_path = os.path.join(\"Part1\", labels[idx], filenames[idx])\n",
    "        match_img = cv2.imread(img_path)\n",
    "        axs[i + 1].imshow(cv2.cvtColor(match_img, cv2.COLOR_BGR2RGB))\n",
    "        axs[i + 1].set_title(f\"Rank {i+1}\\n{metric_label}={distances[idx]:.2f}\")\n",
    "        axs[i + 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434585c5",
   "metadata": {},
   "source": [
    "Ricerca Immagini Simili - Euclidea / Coseno  -- Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a67af25",
   "metadata": {},
   "source": [
    "In questa funzione chiamiamo una solo distanza "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1e2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar(img_path, k, extractor, features, filenames, labels):\n",
    "    query_feature = extractor.extract_feature(img_path)\n",
    "    if query_feature is None:\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    dist_euc = euclidean_distances(features, query_feature).flatten()\n",
    "    dist_cos = cosine_distances(features, query_feature).flatten()\n",
    "\n",
    "    top_k_idx_euc = np.argsort(dist_euc)[:k]\n",
    "    top_k_idx_cos = np.argsort(dist_cos)[:k]\n",
    "\n",
    "    print(f\"\\nTop {k} simili a {img_path}:\")\n",
    "    print(\"=== Euclide ===\")\n",
    "    for rank, idx in enumerate(top_k_idx_euc):\n",
    "        print(f\"{rank+1}. {filenames[idx]} | Classe: {labels[idx]} | Euclid: {dist_euc[idx]:.4f}\")\n",
    "\n",
    "    print(\"=== Coseno ===\")\n",
    "    for rank, idx in enumerate(top_k_idx_cos):\n",
    "        print(f\"{rank+1}. {filenames[idx]} | Classe: {labels[idx]} | Cosine: {dist_cos[idx]:.4f}\")\n",
    "\n",
    "    # Visualizza entrambi\n",
    "    plot_matches(img_path, top_k_idx_euc, labels, filenames, dist_euc, \"Euclid\")\n",
    "    plot_matches(img_path, top_k_idx_cos, labels, filenames, dist_cos, \"Cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d957217",
   "metadata": {},
   "source": [
    "Ricerca Immagini Simili - Mahalanobis -- Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220b43bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_mahalanobis(img_path, k, extractor, features, filenames, labels):\n",
    "    query_feature = extractor.extract_feature(img_path)\n",
    "    if query_feature is None:\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature)\n",
    "    cov = np.cov(features.T)\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"[ERRORE] Covarianza non invertibile. Uso pseudoinversa.\")\n",
    "        cov_inv = np.linalg.pinv(cov)\n",
    "\n",
    "    distances = np.array([mahalanobis(query_feature, f, cov_inv) for f in features])\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "\n",
    "    print(f\"\\nTop {k} simili (Mahalanobis) a {img_path}:\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {filenames[idx]} | Classe: {labels[idx]} | Distanza: {distances[idx]:.2f}\")\n",
    "\n",
    "    plot_matches(img_path, top_k_idx, labels, filenames, distances, \"M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16dbba47",
   "metadata": {},
   "source": [
    "Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Parametri ===\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "\n",
    "\n",
    "\n",
    "# === Estrai e salva features (solo una volta) ===\n",
    "process_and_save_features(\"Part1\", subfolders, \"resnet1024_pt1.npz\")\n",
    "process_and_save_features(\"Part2\", subfolders, \"resnet1024_pt2.npz\")\n",
    "\n",
    "# === Carica features ===\n",
    "features_pt1, filenames_pt1, labels_pt1 = load_features(\"resnet1024_pt1.npz\")\n",
    "features_pt2, filenames_pt2, labels_pt2 = load_features(\"resnet1024_pt2.npz\")\n",
    "\n",
    "# === Inizializza extractor ===\n",
    "extractor = ResNetAvgPool1024Extractor()\n",
    "\n",
    "# === Query ===\n",
    "query_img = \"Part1/brain_glioma/brain_glioma_0005.jpg\"\n",
    "find_k_similar(query_img, k=5, extractor=extractor, features=features_pt1, filenames=filenames_pt1, labels=labels_pt1)\n",
    "find_k_similar_mahalanobis(query_img, k=5, extractor=extractor, features=features_pt1, filenames=filenames_pt1, labels=labels_pt1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0339aa08",
   "metadata": {},
   "source": [
    "Task 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbc5ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "\n",
    "def compute_metric(query_feat, target_feats, metric=\"euclidean\"):\n",
    "    query_feat = query_feat.reshape(1, -1)\n",
    "    if metric == \"euclidean\":\n",
    "        return euclidean_distances(target_feats, query_feat).flatten()\n",
    "    elif metric == \"cosine\":\n",
    "        return cosine_similarity(query_feat, target_feats).flatten()\n",
    "    else:\n",
    "        raise ValueError(\"Metric must be 'euclidean' or 'cosine'\")\n",
    "\n",
    "def predict_top_k_labels_distance_mean_1024(query_img_path, k, extractor, features, labels, metric=\"euclidean\"):\n",
    "    query_feat = extractor.extract_feature(query_img_path)\n",
    "    if query_feat is None:\n",
    "        print(\"[ERRORE] Feature non estratte.\")\n",
    "        return\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    scores = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        class_feats = features[labels == label]\n",
    "        dists_or_sims = compute_metric(query_feat, class_feats, metric)\n",
    "        score = dists_or_sims.mean()\n",
    "        scores.append(score)\n",
    "\n",
    "    if metric == \"euclidean\":\n",
    "        top_k = np.argsort(scores)[:k]\n",
    "    else:\n",
    "        top_k = np.argsort(scores)[::-1][:k]\n",
    "\n",
    "    print(f\"\\n[STRATEGIA: distanza media - metrica: {metric}]\")\n",
    "    for idx in top_k:\n",
    "        print(f\"Classe: {unique_labels[idx]} | Score medio: {scores[idx]:.4f}\")\n",
    "\n",
    "def predict_top_k_labels_prototype_1024(query_img_path, k, extractor, features, labels, metric=\"euclidean\"):\n",
    "    query_feat = extractor.extract_feature(query_img_path)\n",
    "    if query_feat is None:\n",
    "        print(\"[ERRORE] Feature non estratte.\")\n",
    "        return\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    class_prototypes = []\n",
    "    for label in unique_labels:\n",
    "        class_feats = features[labels == label]\n",
    "        class_prototypes.append(class_feats.mean(axis=0))\n",
    "    class_prototypes = np.vstack(class_prototypes)\n",
    "\n",
    "    scores = compute_metric(query_feat, class_prototypes, metric)\n",
    "\n",
    "    if metric == \"euclidean\":\n",
    "        top_k = np.argsort(scores)[:k]\n",
    "    else:\n",
    "        top_k = np.argsort(scores)[::-1][:k]\n",
    "\n",
    "    print(f\"\\n[STRATEGIA: prototipo di classe - metrica: {metric}]\")\n",
    "    for idx in top_k:\n",
    "        print(f\"Classe: {unique_labels[idx]} | Score: {scores[idx]:.4f}\")\n",
    "\n",
    "def task4_predict_labels_1024(query_img_path, k, extractor, features, labels, metric=\"euclidean\"):\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "    print(f\"\\n======== PREDIZIONE PER: {os.path.basename(query_img_path)} ========\")\n",
    "    predict_top_k_labels_distance_mean_1024(query_img_path, k, extractor, features, labels, metric)\n",
    "    predict_top_k_labels_prototype_1024(query_img_path, k, extractor, features, labels, metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3167b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_menin/brain_menin_1202.jpg\"\n",
    "task4_predict_labels_1024(query_img, k=2, extractor=extractor, features=features_pt2, labels=labels_pt2, metric=\"euclidean\")\n",
    "task4_predict_labels_1024(query_img, k=2, extractor=extractor, features=features_pt2, labels=labels_pt2, metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e9b837",
   "metadata": {},
   "source": [
    "Task 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2220da50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def task5_latent_semantics_resnet1024(feature_model_path, technique, k):\n",
    "    \"\"\"\n",
    "    Estrae i top-k concetti latenti da uno spazio di feature ResNet AvgPool1024\n",
    "    usando SVD, LDA o KMeans. Salva i risultati su file e visualizza lo spazio latente.\n",
    "    \"\"\"\n",
    "    # === Carica feature ===\n",
    "    data = np.load(feature_model_path, allow_pickle=True)\n",
    "    feature_matrix = data[\"features\"]\n",
    "    filenames = data[\"filenames\"]\n",
    "    labels = data[\"labels\"]\n",
    "\n",
    "    technique = technique.lower()\n",
    "\n",
    "    if technique == \"svd\":\n",
    "        model = TruncatedSVD(n_components=k, random_state=42)\n",
    "        X_transformed = model.fit_transform(feature_matrix)\n",
    "        components = model.components_\n",
    "        method = \"svd\"\n",
    "\n",
    "    elif technique == \"lda\":\n",
    "        unique_labels = np.unique(labels)\n",
    "        max_k = len(unique_labels) - 1\n",
    "        if k > max_k:\n",
    "            print(f\"[ATTENZIONE] LDA supporta al massimo {max_k} componenti con {len(unique_labels)} classi.\")\n",
    "            k = max_k\n",
    "        model = LDA(n_components=k)\n",
    "        X_transformed = model.fit_transform(feature_matrix, labels)\n",
    "        components = model.scalings_.T[:k]\n",
    "        method = \"lda\"\n",
    "\n",
    "    elif technique == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "        model.fit(feature_matrix)\n",
    "        components = model.cluster_centers_\n",
    "        X_transformed = model.transform(feature_matrix)\n",
    "        method = \"kmeans\"\n",
    "    else:\n",
    "        print(\"[ERRORE] Tecnica non supportata. Usa: 'svd', 'lda', 'kmeans'\")\n",
    "        return\n",
    "\n",
    "    # === Visualizzazione 2D ===\n",
    "    if technique in [\"svd\", \"lda\"]:\n",
    "        plot_latent_space_2d(X_transformed, labels, technique, k)\n",
    "    elif technique == \"kmeans\":\n",
    "        plot_kmeans_clusters_2d(feature_matrix, labels, k)\n",
    "\n",
    "    # === Salvataggio output ===\n",
    "    base_name = os.path.splitext(os.path.basename(feature_model_path))[0]\n",
    "    out_file = f\"latent_semantics_{method}_{base_name}_k{k}.txt\"\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for i in range(k):\n",
    "            f.write(f\"\\n--- Latent Semantic {i+1} ---\\n\")\n",
    "            if technique in [\"svd\", \"lda\"]:\n",
    "                weights = feature_matrix @ components[i].T\n",
    "            else:\n",
    "                weights = -X_transformed[:, i]  # distanza inversa per KMeans\n",
    "\n",
    "            sorted_idx = np.argsort(-np.abs(weights))\n",
    "            for idx in sorted_idx:\n",
    "                f.write(f\"{filenames[idx]} | Peso: {weights[idx]:.4f} | Classe: {labels[idx]}\\n\")\n",
    "\n",
    "    print(f\"[SALVATO] Latent semantics salvati in: {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a13af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space_2d(X_transformed, labels, technique, k):\n",
    "    \"\"\"Visualizza la proiezione 2D dello spazio latente.\"\"\"\n",
    "    if X_transformed.shape[1] < 2:\n",
    "        print(\"[INFO] Meno di 2 componenti: impossibile visualizzare in 2D.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_transformed[:, 0], y=X_transformed[:, 1], hue=labels, palette=\"Set2\", s=80)\n",
    "    plt.title(f\"{technique.upper()} - Proiezione sulle prime 2 componenti latenti (k={k})\")\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_kmeans_clusters_2d(feature_matrix, labels, n_clusters):\n",
    "    \"\"\"Visualizza i cluster KMeans in 2D usando SVD per proiezione.\"\"\"\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(feature_matrix)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=cluster_labels, palette='tab10', s=80, style=labels)\n",
    "    plt.title(f\"KMeans Clustering (k={n_clusters}) con proiezione SVD 2D\")\n",
    "    plt.xlabel(\"Componente Latente 1 (da SVD)\")\n",
    "    plt.ylabel(\"Componente Latente 2 (da SVD)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ESEMPIO USO ===\n",
    "task5_latent_semantics_resnet1024(\"resnet1024.npz\", technique=\"svd\", k=5)\n",
    "task5_latent_semantics_resnet1024(\"resnet1024.npz\", technique=\"lda\", k=2)\n",
    "task5_latent_semantics_resnet1024(\"resnet1024.npz\", technique=\"kmeans\", k=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110781f7",
   "metadata": {},
   "source": [
    "Task 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc88464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def estimate_intrinsic_dimensionality(feature_matrix, threshold, plot=True):\n",
    "    max_components = min(feature_matrix.shape)\n",
    "    pca = PCA(n_components=max_components)\n",
    "    pca.fit(feature_matrix)\n",
    "\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    cumulative = np.cumsum(explained)\n",
    "    intrinsic_dim = np.argmax(cumulative >= threshold) + 1\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(cumulative, marker='o', label=\"Varianza cumulativa\")\n",
    "        plt.axhline(y=threshold, color='r', linestyle='--', label=f\"Soglia {threshold*100:.0f}%\")\n",
    "        plt.axvline(x=intrinsic_dim, color='g', linestyle='--', label=f\"k suggerito: {intrinsic_dim}\")\n",
    "        plt.xlabel(\"Numero componenti\")\n",
    "        plt.ylabel(\"Varianza cumulativa\")\n",
    "        plt.title(\"Scelta ottimale di k (PCA su ResNet1024)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"[INFO] k ottimale suggerito (soglia {threshold*100:.0f}%): {intrinsic_dim}\")\n",
    "    return intrinsic_dim, cumulative\n",
    "\n",
    "\n",
    "def suggest_k(feature_matrix, threshold_list=[0.90, 0.95, 0.99]):\n",
    "    print(f\"[INFO] Feature matrix shape: {feature_matrix.shape}\")\n",
    "    k_values = {}\n",
    "    for t in threshold_list:\n",
    "        k, _ = estimate_intrinsic_dimensionality(feature_matrix, threshold=t, plot=False)\n",
    "        k_values[t] = k\n",
    "        print(f\"Soglia {int(t*100)}% : k = {k}\")\n",
    "    return k_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feb210c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTask 6a – Dimensionalità intrinseca (globale):\\n\")\n",
    "k_suggeriti_resnet1024 = suggest_k(features_pt1)\n",
    "estimate_intrinsic_dimensionality(features_pt1, threshold=0.95, plot=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58027c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dimensionality_per_label(feature_matrix, labels, threshold):\n",
    "    label_dim_map = {}\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"[INFO] Etichette uniche trovate: {len(unique_labels)}\")\n",
    "\n",
    "    for label in unique_labels:\n",
    "        indices = np.where(np.array(labels) == label)[0]\n",
    "        label_features = feature_matrix[indices]\n",
    "\n",
    "        if len(indices) < 2:\n",
    "            print(f\"[AVVISO] Label '{label}' ha meno di 2 campioni — ignorata.\")\n",
    "            continue\n",
    "\n",
    "        k, _ = estimate_intrinsic_dimensionality(label_features, threshold=threshold, plot=False)\n",
    "        label_dim_map[label] = k\n",
    "        print(f\" • Label '{label}' : k = {k}\")\n",
    "    return label_dim_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2cc0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTask 6b – Dimensionalità intrinseca per etichetta (ResNet1024):\\n\")\n",
    "label_dimensionalities_resnet1024 = estimate_dimensionality_per_label(\n",
    "    features_pt1, labels_pt1, threshold=0.95\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a541d0",
   "metadata": {},
   "source": [
    "Task 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed5a202",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "def compute_latent_semantics_per_class_resnet(X, y, k=10):\n",
    "    class_models = {}\n",
    "    class_means = {}\n",
    "    labels = np.unique(y)\n",
    "\n",
    "    for label in labels:\n",
    "        X_class = X[np.array(y) == label]\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_class)\n",
    "\n",
    "        svd = TruncatedSVD(n_components=k, random_state=42)\n",
    "        latent = svd.fit_transform(X_scaled)\n",
    "\n",
    "        class_models[label] = {\n",
    "            'scaler': scaler,\n",
    "            'svd': svd,\n",
    "            'latent_vectors': latent\n",
    "        }\n",
    "        class_means[label] = np.mean(latent, axis=0)\n",
    "    return class_models, class_means\n",
    "\n",
    "def predict_labels_with_latent_semantics(X_test, class_models, class_means):\n",
    "    predictions = []\n",
    "    for x in X_test:\n",
    "        best_label = None\n",
    "        min_dist = float('inf')\n",
    "        for label, model in class_models.items():\n",
    "            x_scaled = model['scaler'].transform(x.reshape(1, -1))\n",
    "            x_latent = model['svd'].transform(x_scaled)\n",
    "            dist = np.linalg.norm(x_latent - class_means[label])\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_label = label\n",
    "        predictions.append(best_label)\n",
    "    return predictions\n",
    "\n",
    "def evaluate_predictions(y_true, y_pred):\n",
    "    print(\"[VALUTAZIONE] Metriche per classe:\")\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0\n",
    "    )\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    for label, p, r, f in zip(np.unique(y_true), precision, recall, f1):\n",
    "        print(f\"Classe {label}: Precisione={p:.2f}, Recall={r:.2f}, F1-Score={f:.2f}\")\n",
    "    print(f\"\\nAccuratezza globale: {accuracy:.2f}\\n\")\n",
    "    print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3d2251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== ESECUZIONE ======\n",
    "\n",
    "# Step 1: addestramento sulle immagini Part1\n",
    "class_models_resnet1024, class_means_resnet1024 = compute_latent_semantics_per_class_resnet(\n",
    "    features_pt1, labels_pt1, k=10\n",
    ")\n",
    "\n",
    "# Step 2: predizione sulle immagini Part2\n",
    "predicted_labels_resnet1024 = predict_labels_with_latent_semantics(\n",
    "    features_pt2, class_models_resnet1024, class_means_resnet1024\n",
    ")\n",
    "\n",
    "# Step 3: valutazione delle predizioni\n",
    "evaluate_predictions(labels_pt2, predicted_labels_resnet1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d70d46b",
   "metadata": {},
   "source": [
    "task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ddd68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imposta il valore di m per l'm-NN\n",
    "m = 5  # Modifica questo valore in base alle tue necessità\n",
    "\n",
    "# Addestramento m-NN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=m)\n",
    "knn_model.fit(features_pt1, labels_pt1)\n",
    "\n",
    "# Addestramento Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(features_pt1, labels_pt1)\n",
    "\n",
    "# Predizioni su Part2\n",
    "pred_knn = knn_model.predict(features_pt2)\n",
    "pred_dt = dt_model.predict(features_pt2)\n",
    "\n",
    "# Valutazione m-NN\n",
    "print(\"Risultati m-NN:\")\n",
    "print(classification_report(labels_pt2, pred_knn))\n",
    "print(\"Accuratezza complessiva m-NN:\", accuracy_score(labels_pt2, pred_knn))\n",
    "\n",
    "# Valutazione Decision Tree\n",
    "print(\"Risultati Decision Tree:\")\n",
    "print(classification_report(labels_pt2, pred_dt))\n",
    "print(\"Accuratezza complessiva Decision Tree:\", accuracy_score(labels_pt2, pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a09f87",
   "metadata": {},
   "source": [
    "Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7da9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe LSH con quantizzazione\n",
    "\n",
    "class LSH_EuclideanQuantized:\n",
    "    \"\"\"\n",
    "    LSH per distanza Euclidea (p-stable) con bucket width r.\n",
    "    Ogni hash h_j(v) = floor((a_j · v + b_j) / r).\n",
    "\n",
    "    Parametri:\n",
    "      - num_layers   = L = numero di tavole hash\n",
    "      - num_hashes   = h = numero di functions concatenati in ciascuna tavola\n",
    "      - dim          = D = dimensione dei vettori di input\n",
    "      - r            = bucket width (parte intera di quantizzazione)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers: int, num_hashes: int, dim: int, r: float):\n",
    "        self.L = num_layers\n",
    "        self.h = num_hashes\n",
    "        self.d = dim\n",
    "        self.r = r\n",
    "\n",
    "        # Prepara L tavole hash: ciascuna è un dict (chiave tuple di h interi -> lista di indici)\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.L)]\n",
    "\n",
    "        # Per ogni layer l=0..L-1, e per ogni j=0..h-1, genero:\n",
    "        #   - a_lj  vettore gaussiano di dimensione D\n",
    "        #   - b_lj  offset (uniforme in [0, r) )\n",
    "        self.a_vectors = [\n",
    "            [np.random.randn(self.d) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "        self.b_offsets = [\n",
    "            [np.random.uniform(0, self.r) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "\n",
    "        # Memorizzerò i vettori originali di Part1 in questo array, shape=(N, D)\n",
    "        self.data_vectors = None\n",
    "\n",
    "    def _compute_hash_tuple(self, vec: np.ndarray, layer_idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Calcola l'hash (h interi) per il layer layer_idx su un vettore vec:\n",
    "          h_j = floor((a_vectors[layer_idx][j] · vec + b_offsets[layer_idx][j]) / r)\n",
    "        Ritorna una tupla di h interi.\n",
    "        \"\"\"\n",
    "        keys = []\n",
    "        a_vs = self.a_vectors[layer_idx]\n",
    "        b_os = self.b_offsets[layer_idx]\n",
    "        for j in range(self.h):\n",
    "            a_j = a_vs[j]         # vettore dimensione D\n",
    "            b_j = b_os[j]         # float in [0, r)\n",
    "            proj = float(np.dot(a_j, vec) + b_j)\n",
    "            h_val = int(np.floor(proj / self.r))\n",
    "            keys.append(h_val)\n",
    "        return tuple(keys)\n",
    "\n",
    "    def index(self, vectors: np.ndarray):\n",
    "        \"\"\"\n",
    "        Costruisci l'indice LSH su un insieme di vettori di Part1:\n",
    "          vectors: numpy array shape = (N, D)\n",
    "        Al termine di questa chiamata:\n",
    "          - self.data_vectors = vectors\n",
    "          - self.hash_tables[l][hash_tuple] conterrà la lista di indici i per cui\n",
    "            hash_tuple = _compute_hash_tuple(vectors[i], l).\n",
    "        \"\"\"\n",
    "        self.data_vectors = vectors\n",
    "        N, D = vectors.shape\n",
    "        assert D == self.d, f\"Errore: dimensione vettore ({D}) ≠ atteso ({self.d}).\"\n",
    "\n",
    "        # Inserisco ogni vettore in ciascuna tavola hash\n",
    "        for idx in range(N):\n",
    "            v = vectors[idx]\n",
    "            for l in range(self.L):\n",
    "                key = self._compute_hash_tuple(v, l)\n",
    "                self.hash_tables[l][key].append(idx)\n",
    "\n",
    "    def query(self, q_vec: np.ndarray, top_t: int = 5):\n",
    "        \"\"\"\n",
    "        Esegui una query LSH per cercare i top_t vettori più vicini a q_vec.\n",
    "        Restituisce:\n",
    "          - top_results: lista di tuple (indice, distanza) ord. per dist. crescente\n",
    "          - unique_count: numero di indici distinti considerati (cardinalità dei candidati)\n",
    "          - total_checked: somma della lunghezza di tutti i bucket esaminati\n",
    "        \"\"\"\n",
    "        assert q_vec.shape[0] == self.d, \"Errore: dimensione query ≠ D.\"\n",
    "        candidati = set()\n",
    "        total_checked = 0\n",
    "\n",
    "        # Per ciascun layer, ottengo la chiave polidimensionale e i suoi bucket\n",
    "        for l in range(self.L):\n",
    "            h_tuple = self._compute_hash_tuple(q_vec, l)\n",
    "            bucket = self.hash_tables[l].get(h_tuple, [])\n",
    "            total_checked += len(bucket)\n",
    "            candidati.update(bucket)\n",
    "\n",
    "        # Ora calcolo la distanza euclidea esatta tra q_vec e ciascun candidato\n",
    "        risultati = []\n",
    "        for idx in candidati:\n",
    "            v_i = self.data_vectors[idx]\n",
    "            dist = np.linalg.norm(v_i - q_vec)\n",
    "            risultati.append((idx, dist))\n",
    "\n",
    "        # Ordino e prendo i primi top_t\n",
    "        risultati.sort(key=lambda x: x[1])\n",
    "        top_results = risultati[:top_t]\n",
    "        return top_results, len(candidati), total_checked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beeb7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# costruzione LSH_EuclideanQuantized su Part1\n",
    "\n",
    "# 1) (Opzionale ma consigliato) centra e normalizza i vettori di Part1\n",
    "#    Questo passaggio riduce l'effetto di scale diverse e spesso migliora la qualità LSH\n",
    "mean_vec = np.mean(features_pt1, axis=0)\n",
    "feat_centered = features_pt1 - mean_vec\n",
    "feat_normed = normalize(feat_centered, norm='l2', axis=1)\n",
    "\n",
    "# 2) Parametri LSH\n",
    "D = feat_normed.shape[1]      # di solito 900\n",
    "L = 10                         # numero di tavole hash (scegli in base a esperimenti)\n",
    "h = 5                      # numero di funzioni concatenati in ciascuna tavola\n",
    "r = 1                      # parametro di larghezza (esempio: 0.5); puoi sperimentare\n",
    "\n",
    "# 3) Creo l'oggetto e indicizzo\n",
    "lsh_quant = LSH_EuclideanQuantized(num_layers=L, num_hashes=h, dim=D, r=r)\n",
    "lsh_quant.index(feat_normed)\n",
    "\n",
    "print(f\"[INFO] LSH quantizzato costruito: D={D}, L={L}, h={h}, r={r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db417e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per cercare top_k con LSH quantizzato\n",
    "\n",
    "def find_k_similar_lsh_quant(base_folder: str, img_path: str, k: int, extractor, mean_vec, lsh_quant, labels_pt1, filenames_pt1):\n",
    "    \"\"\"\n",
    "    Cerca le k immagini di Part1 più simili a img_path (di Part2) usando LSH_EuclideanQuantized.\n",
    "    Stampa:\n",
    "      - i primi k risultati (file name, label, distanza)\n",
    "      - il numero di immagini uniche considerate\n",
    "      - il numero totale di controlli (somma delle lunghezze dei bucket)\n",
    "    E poi visualizza (query + k risultati) con matplotlib.\n",
    "    \"\"\"\n",
    "    # 1) Estrazione feature raw (900-dim) con la funzione esistente\n",
    "       # 1) Estrazione feature (1024-dim) con ResNetAvgPool1024Extractor\n",
    "    raw_q = np.array(extractor.extract_feature(img_path), dtype=np.float32)\n",
    "    if raw_q is None:\n",
    "        print(\"[ERRORE] Estrazione feature fallita per\", img_path)\n",
    "        return\n",
    "\n",
    "\n",
    "    # 2) Center + normalize (stesso mean_vec e L2 norm usati su Part1)\n",
    "    q_centered = raw_q - mean_vec\n",
    "    q_normed = q_centered / np.linalg.norm(q_centered)\n",
    "\n",
    "    # 3) Chiamata a LSH\n",
    "    top_results, unique_count, total_checked = lsh_quant.query(q_normed, top_t=k)\n",
    "\n",
    "    # 4) Stampa output testuale\n",
    "    print(f\"\\n[LSH-Quant] Top {k} simili a: {img_path}\")\n",
    "    for rank, (idx, dist) in enumerate(top_results, start=1):\n",
    "        label = labels_pt1[idx]\n",
    "        fname = filenames_pt1[idx]\n",
    "        print(f\"  {rank}. {fname} | Classe: {label} | Distanza Euclidea: {dist:.2f}\")\n",
    "    print(f\"[LSH-Quant] Immagini uniche considerate: {unique_count}\")\n",
    "    print(f\"[LSH-Quant] Immagini totali controllate: {total_checked}\")\n",
    "\n",
    "    # 5) Visualizzazione (query + primi k risultati)\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(4*(k+1), 4))\n",
    "    img_q = cv2.imread(img_path)\n",
    "    img_q = cv2.cvtColor(img_q, cv2.COLOR_BGR2RGB)\n",
    "    axs[0].imshow(img_q)\n",
    "    axs[0].set_title(\"Query (LSH-Quant)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, (idx, dist) in enumerate(top_results, start=1):\n",
    "        lab = labels_pt1[idx]\n",
    "        fname = filenames_pt1[idx]\n",
    "        full_path = os.path.join(base_folder, lab, fname)\n",
    "        img_match = cv2.imread(full_path)\n",
    "        img_match = cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(img_match)\n",
    "        axs[i].set_title(f\"Rank {i}\\nd={dist:.2f}\")\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd9a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio di utilizzo su un'immagine di Part2 ---\n",
    "query_path = \"Part2/brain_glioma/brain_glioma_1409.jpg\"\n",
    "\n",
    "k = 5                         # numero di immagini simili da visualizzare\n",
    "\n",
    "# Eseguo la ricerca LSH\n",
    "find_k_similar_lsh_quant(\"Part1\", query_path, 5, extractor, mean_vec, lsh_quant, labels_pt1, filenames_pt1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
