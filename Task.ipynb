{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poter importare correttamente cv2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.stats import skew\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# === Funzione: Crop automatico dell'area informativa (cervello) ===\n",
    "def crop_to_brain(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    x, y, w, h = cv2.boundingRect(coords)\n",
    "    cropped = img[y:y+h, x:x+w]\n",
    "    return cropped\n",
    "\n",
    "# === Funzione: Estrazione Color Moments su griglia 10x10 ===\n",
    "def extract_color_moments(img_path):\n",
    "    print(\"[CM10x10] Estrazione in corso...\")\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"[ERRORE] Immagine non trovata: {img_path}\")\n",
    "\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        print(\"[CM10x10] Immagine in scala di grigi – conversione in RGB finto\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    img = crop_to_brain(img)  # Crop dell'area utile\n",
    "    img = cv2.resize(img, (300, 100))\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    grid_h, grid_w = h // 10, w // 10\n",
    "    features = []\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            cell = img[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]\n",
    "            for channel in range(3):  # R, G, B\n",
    "                pixels = cell[:, :, channel].flatten()\n",
    "                if np.std(pixels) > 0:\n",
    "                    mean = np.mean(pixels)\n",
    "                    std = np.std(pixels)\n",
    "                    sk = skew(pixels)\n",
    "                    if np.isnan(sk):\n",
    "                        sk = 0\n",
    "                else:\n",
    "                    mean, std, sk = 0, 0, 0\n",
    "                features.extend([mean, std, sk])\n",
    "\n",
    "    features = np.array(features)\n",
    "    features = np.nan_to_num(features)\n",
    "\n",
    "    print(f\"[CM10x10] Feature vector (dim {features.shape[0]}): {features[:10]}\")\n",
    "    return features\n",
    "\n",
    "# === Percorso immagine ===\n",
    "img_path = \"Part1/brain_glioma/brain_glioma_0001.jpg\"\n",
    "features = extract_color_moments(img_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of Oriented Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage import exposure\n",
    "\n",
    "# === Funzione: Estrazione HOG ===\n",
    "def extract_hog_features(img_path):\n",
    "    print(\"[HOG] Estrazione in corso...\")\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"[ERRORE] Immagine non trovata: {img_path}\")\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (128, 128))  # dimensione fissa\n",
    "\n",
    "    features, hog_image = hog(resized,\n",
    "                              orientations=9,\n",
    "                              pixels_per_cell=(8, 8),\n",
    "                              cells_per_block=(2, 2),\n",
    "                              visualize=True,\n",
    "                              block_norm='L2-Hys')\n",
    "\n",
    "    print(f\"[HOG] Feature vector (dim {features.shape[0]}): {features[:900]}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    plt.figure(figsize=(10,4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(resized, cmap='gray')\n",
    "    plt.title(\"Input Grayscale\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(hog_image, cmap='gray')\n",
    "    plt.title(\"HOG Visualization\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return features\n",
    "\n",
    "# === Percorso immagine ===\n",
    "img_path = \"Part1/brain_glioma/brain_glioma_0001.jpg\"\n",
    "features = extract_hog_features(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_custom_hog(img_path):\n",
    "    print(\"[HOG-Custom] Estrazione in corso...\")\n",
    "\n",
    "    # Carica immagine e converti in scala di grigi\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        raise ValueError(f\"[ERRORE] Immagine non trovata: {img_path}\")\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Resize a 300x10\n",
    "    resized = cv2.resize(gray, (300, 10))\n",
    "\n",
    "    h, w = resized.shape\n",
    "    grid_h, grid_w = h // 10, w // 10  # Cella = 1x30 px\n",
    "    feature_vector = []\n",
    "\n",
    "    # Maschere per gradiente\n",
    "    dx_mask = np.array([[ -1, 0, 1 ]])\n",
    "    dy_mask = dx_mask.T\n",
    "\n",
    "    # Gradienti su immagine intera\n",
    "    dx = cv2.filter2D(resized.astype(np.float32), -1, dx_mask)\n",
    "    dy = cv2.filter2D(resized.astype(np.float32), -1, dy_mask)\n",
    "    magnitude = np.sqrt(dx**2 + dy**2)\n",
    "    angle = np.arctan2(dy, dx) * (180 / np.pi)\n",
    "    angle = (angle + 360) % 360  # Intervallo [0, 360)\n",
    "\n",
    "    # Estrazione HOG per ogni cella\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            cell_mag = magnitude[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]\n",
    "            cell_ang = angle[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]\n",
    "\n",
    "            hist = np.zeros(9)\n",
    "            for y in range(cell_mag.shape[0]):\n",
    "                for x in range(cell_mag.shape[1]):\n",
    "                    bin_idx = int(cell_ang[y, x] // 40) % 9\n",
    "                    hist[bin_idx] += cell_mag[y, x]\n",
    "            feature_vector.extend(hist)\n",
    "\n",
    "    feature_vector = np.array(feature_vector)\n",
    "    print(f\"[HOG-Custom] Feature vector (dim {len(feature_vector)}): {feature_vector[:10]}\")\n",
    "    return feature_vector\n",
    "\n",
    "# ESEMPIO USO:\n",
    "features = extract_custom_hog(\"Part2/brain_glioma/brain_glioma_1853.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1:  ResNet-AvgPool-1024: Resize image to 224 x 24; attach a hook to the output of the\n",
    "“avgpool” layer of the ResNet pre-trained architecture to obtain 2048 dimensional vector,\n",
    "reduce the number of dimensions of the vector to 1024 by averaging two consecutive entries\n",
    "in the vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "class ResNetAvgPool1024Extractor:\n",
    "    def __init__(self):\n",
    "        self.model = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        self.model.eval()\n",
    "        self.feature = None\n",
    "\n",
    "        # Hook sul layer avgpool\n",
    "        def hook_avgpool(module, input, output):\n",
    "            self.feature = output.squeeze().detach().numpy()\n",
    "\n",
    "        self.model.avgpool.register_forward_hook(hook_avgpool)\n",
    "\n",
    "        # Preprocessing: resize, tensor, normalize\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "    def extract_feature(self, image_path):\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        input_tensor = self.transform(img).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            _ = self.model(input_tensor)\n",
    "\n",
    "        # self.feature è 2048-dim; riduci a 1024-dim\n",
    "        avgpool_2048 = self.feature\n",
    "        avgpool_1024 = 0.5 * (avgpool_2048[::2] + avgpool_2048[1::2])\n",
    "        return avgpool_1024\n",
    "\n",
    "\n",
    "# === ESEMPIO USO ===\n",
    "if __name__ == \"__main__\":\n",
    "    image_path = \"Part1/brain_glioma/brain_glioma_0001.jpg\"  # Sostituisci con il tuo path\n",
    "    extractor = ResNetAvgPool1024Extractor()\n",
    "    features = extractor.extract_feature(image_path)\n",
    "\n",
    "    print(\"Feature vector (1024 dim):\")\n",
    "    print(features[:10], \"...\")  # stampa i primi 10 valori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HOG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import functional as F\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def visualize_image(image_path):\n",
    "    \"\"\"\n",
    "    Loads and displays an image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "    \"\"\"\n",
    "    image = read_image(image_path)  # Load the image using torchvision\n",
    "    plt.imshow(F.to_pil_image(image))\n",
    "    plt.title(\"Image\")\n",
    "    plt.show()\n",
    "\n",
    "def calculate_hog_features(image_path):\n",
    "    \"\"\"\n",
    "    Calculates Histogram of Oriented Gradients (HOG) features for a given image.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: 900-dimensional HOG feature descriptor.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Load and Preprocess Image\n",
    "    image = read_image(image_path)\n",
    "    pil_image = F.to_pil_image(image)  # Convert tensor to PIL Image\n",
    "    gray_image = F.to_grayscale(pil_image)  # Convert to grayscale\n",
    "    resized_image = F.resize(gray_image, [300, 10])  # Resize to 300x10\n",
    "    resized_image = F.to_tensor(resized_image) # Convert back to tensor\n",
    "\n",
    "    # 2. Calculate Gradients\n",
    "    #   Using [-1, 0, 1] and [-1, 0, 1].T masks for dI/dx and dI/dy\n",
    "    dx_filter = torch.tensor([[-1.0, 0.0, 1.0]])\n",
    "    dy_filter = torch.transpose(dx_filter, 0, 1)\n",
    "\n",
    "    # Add a channel dimension to resized_image for convolution\n",
    "    resized_image = resized_image.unsqueeze(0).float()\n",
    "    dx = torch.conv2d(resized_image, dx_filter.float().unsqueeze(0).unsqueeze(0), padding='same')\n",
    "    dy = torch.conv2d(resized_image, dy_filter.float().unsqueeze(0).unsqueeze(0), padding='same')\n",
    "\n",
    "    # Calculate magnitude and orientation\n",
    "    magnitude = torch.sqrt(dx**2 + dy**2)\n",
    "    orientation = torch.atan2(dy, dx) * (180 / np.pi)  # Convert radians to degrees\n",
    "\n",
    "    # 3. Compute Histograms\n",
    "    cell_size = (30, 1)  # Cell size for the 10x10 grid (300/10, 10/1)\n",
    "    num_bins = 9  # 9 bins for the histogram (40 degrees per bin)\n",
    "    histograms = []\n",
    "\n",
    "    for i in range(0, resized_image.shape[2], cell_size[0]):  # Iterate over rows (height)\n",
    "        for j in range(0, resized_image.shape[3], cell_size[1]):  # Iterate over columns (width)\n",
    "            cell_magnitude = magnitude[:, :, i:i + cell_size[0], j:j + cell_size[1]]\n",
    "            cell_orientation = orientation[:, :, i:i + cell_size[0], j:j + cell_size[1]]\n",
    "\n",
    "            histogram = torch.zeros(num_bins)\n",
    "            for bin in range(num_bins):\n",
    "                # Calculate bin edges\n",
    "                lower_bound = -90 + bin * 40\n",
    "                upper_bound = -90 + (bin + 1) * 40\n",
    "\n",
    "                # Count pixels within the bin\n",
    "                in_range = (cell_orientation >= lower_bound) & (cell_orientation < upper_bound)\n",
    "                histogram[bin] = cell_magnitude[in_range].sum()\n",
    "\n",
    "            histograms.append(histogram)\n",
    "\n",
    "    # 4.  Concatenate Histograms\n",
    "    hog_features = torch.cat(histograms).numpy()\n",
    "\n",
    "    return hog_features\n",
    "\n",
    "def print_hog_features(hog_features):\n",
    "    \"\"\"\n",
    "    Prints the HOG feature descriptor in a human-readable format.\n",
    "\n",
    "    Args:\n",
    "        hog_features (numpy.ndarray): The 900-dimensional HOG feature vector.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"HOG Feature Descriptor:\")\n",
    "    print(hog_features)\n",
    "    print(f\"Shape: {hog_features.shape}\")  # Ensure it's 900\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    image_file = \"Part1/brain_glioma/brain_glioma_0001.jpg\"  # Replace with the actual path to your image\n",
    "    visualize_image(image_file)\n",
    "    hog_features = calculate_hog_features(image_file)\n",
    "    print_hog_features(hog_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
