{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ac94653",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfd5fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from torchvision.models import ResNet50_Weights\n",
    "import torchvision.models as models\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a16e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se CUDA disponibile, usa la GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carica ResNet50 pre-addestrata e in modalità eval\n",
    "weights = ResNet50_Weights.IMAGENET1K_V1  # o DEFAULT per i pesi più aggiornati\n",
    "model = models.resnet50(weights=weights)\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# Preprocessing standard per ResNet\n",
    "preprocess = weights.transforms()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f881f44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per caricare l'immagine e fare la pre-elaborazione\n",
    "def preprocess_image(img_path):\n",
    "    img = Image.open(img_path).convert('RGB')\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b51f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funzione per estrarre la media su ciascuna mappa di attivazione\n",
    "def extract_and_process_image(img_path, model):\n",
    "    img_tensor = preprocess_image(img_path)\n",
    "    features = extract_resnet_features(img_tensor, model)\n",
    "    features_vector = features.detach().mean(dim=[1, 2]).cpu().numpy()\n",
    "    return features_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741cedb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(npz_path):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    return data['features'], data['labels'], data.get('filenames', [f\"img_{i}\" for i in range(len(data['features']))])\n",
    "\n",
    "\n",
    "feat_matrix_part1, lbls_part1, flname_part1 = load_features(\n",
    "    \"resnet_features_part1.npz\")\n",
    "feat_matrix_part2, lbls_part2, flname_part2 = load_features(\n",
    "    \"resnet_features_part2.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a80c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "Task 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebafc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Funzione per estrarre le caratteristiche dal livello \"layer3\" della ResNet\n",
    "def extract_resnet_features(img_tensor, model):\n",
    "    def hook_fn(module, input, output):\n",
    "        hook_fn.features = output\n",
    "\n",
    "    hook = model.layer3[0].register_forward_hook(hook_fn)\n",
    "    model(img_tensor)\n",
    "    hook.remove()\n",
    "\n",
    "    features = hook_fn.features.squeeze()\n",
    "    return features\n",
    "\n",
    "\n",
    "\n",
    "# Funzione per processare tutte le immagini in più sottocartelle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcc7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    \"\"\"\n",
    "    Estrae le feature FC da immagini in più cartelle e salva in un file .npz.\n",
    "    \"\"\"\n",
    "    all_features = []\n",
    "    all_filenames = []\n",
    "    all_labels = []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        if not os.path.isdir(folder_path):\n",
    "            print(f\"[ATTENZIONE] Cartella non trovata: {folder_path}\")\n",
    "            continue\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_and_process_image(img_path, model)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "                else:\n",
    "                    print(f\"[ERRORE] Feature non estratte da {img_path}\")\n",
    "\n",
    "    # Salva in file .npz\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    \n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")\n",
    "    print(f\"[FINE] Totale immagini processate: {len(all_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fbf7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri cartelle e output\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "\n",
    "\n",
    "# Estrazione e salvataggio\n",
    "process_and_save_features(\"Part1\", subfolders, \"resnet_features_part1\")\n",
    "process_and_save_features(\"Part2\", subfolders, \"resnet_features_part2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5a3725",
   "metadata": {},
   "source": [
    "Task 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40952091",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Funzione con scelta metrica ---\n",
    "\n",
    "def find_top_k_similar(query_img_path, k, features_npz_path, model, image_folder, metric):\n",
    "    \"\"\"\n",
    "    Trova e visualizza le k immagini più simili rispetto all'immagine di query.\n",
    "\n",
    "    Parametri:\n",
    "    - query_img_path: percorso immagine di query\n",
    "    - k: numero di immagini simili da mostrare\n",
    "    - features_npz_path: file .npz con features, filenames, labels\n",
    "    - model: modello ResNet già caricato\n",
    "    - image_folder: cartella base delle immagini (per ricostruire i path)\n",
    "    - metric: \"euclidean\" o \"cosine\" (default euclidean)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Estrai feature per immagine query\n",
    "    query_feature = extract_and_process_image(query_img_path, model).reshape(1, -1)\n",
    "\n",
    "    if metric == \"euclidean\":\n",
    "        # Distanza euclidea\n",
    "        dists = np.linalg.norm(feat_matrix_part1 - query_feature, axis=1)\n",
    "        # Più piccoli sono migliori (vicinanza)\n",
    "        top_k_indices = np.argsort(dists)[:k]\n",
    "\n",
    "    elif metric == \"cosine\":\n",
    "        # Similarità coseno\n",
    "        sim = cosine_similarity(query_feature, feat_matrix_part1)[0]  # shape: (num_features,)\n",
    "        # Più alti sono migliori (similarità)\n",
    "        top_k_indices = np.argsort(sim)[::-1][:k]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Metric must be 'euclidean' or 'cosine'\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    for i, idx in enumerate(top_k_indices):\n",
    "        img_path = os.path.join(image_folder, lbls_part1[idx], flname_part1[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        plt.subplot(1, k, i + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        if metric == \"euclidean\":\n",
    "            plt.title(f\"{flname_part1[idx]}\\nDist: {dists[idx]:.4f}\")\n",
    "        else:\n",
    "            plt.title(f\"{flname_part1[idx]}\\nSim: {sim[idx]:.4f}\")\n",
    "\n",
    "    plt.suptitle(f\"Top-{k} immagini più simili ({metric})\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f29e7a8",
   "metadata": {},
   "source": [
    "Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35317c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Parametri ===\n",
    "query_image_path = \"Part1/brain_tumor/brain_tumor_0001.jpg\"  # Sostituisci con il percorso corretto\n",
    "k = 5\n",
    "features_npz = \"resnet_features_part1.npz\"\n",
    "base_folder = \"Part1\"\n",
    "\n",
    "# === Chiamata con distanza euclidea ===\n",
    "# find_top_k_similar(query_image_path, k, features_npz, model, base_folder, metric=\"euclidean\")\n",
    "\n",
    "# === Chiamata con similarità coseno ===\n",
    "find_top_k_similar(query_image_path, k, features_npz, model, base_folder, metric=\"euclidean\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30b390b2",
   "metadata": {},
   "source": [
    "Task 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0271f255",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metric(query_feat, target_feats, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Calcola la distanza o similarità tra query_feat e un set di target_feats.\n",
    "    \"\"\"\n",
    "    query_feat = query_feat.reshape(1, -1)\n",
    "    if metric == \"euclidean\":\n",
    "        return np.linalg.norm(target_feats - query_feat, axis=1)\n",
    "    elif metric == \"cosine\":\n",
    "        return cosine_similarity(query_feat, target_feats)[0]\n",
    "    else:\n",
    "        raise ValueError(\"Metric must be 'euclidean' or 'cosine'\")\n",
    "\n",
    "def predict_top_k_labels_distance_mean(query_img_path, k, model, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Strategia 1: etichetta più vicina in media nel feature space.\n",
    "    \"\"\"\n",
    "    data = np.load(\"resnet_features_all.npz\")\n",
    "    features = data['features']\n",
    "    labels = data['labels']\n",
    "\n",
    "    query_feat = extract_and_process_image(query_img_path, model)\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    avg_scores = []\n",
    "\n",
    "    for label in unique_labels:\n",
    "        class_feats = features[labels == label]\n",
    "        scores = compute_metric(query_feat, class_feats, metric)\n",
    "        avg_scores.append(scores.mean())\n",
    "\n",
    "    # Ordinamento (euclidea: valori più piccoli = migliori; cosine: valori più grandi = migliori)\n",
    "    if metric == \"euclidean\":\n",
    "        sorted_indices = np.argsort(avg_scores)\n",
    "    else:  # cosine\n",
    "        sorted_indices = np.argsort(avg_scores)[::-1]\n",
    "\n",
    "    print(f\"--- Top-{k} etichette - Distanza media ({metric}) ---\")\n",
    "    for i in range(min(k, len(unique_labels))):\n",
    "        idx = sorted_indices[i]\n",
    "        print(f\"{unique_labels[idx]} \\t Score medio: {avg_scores[idx]:.4f}\")\n",
    "\n",
    "def predict_top_k_labels_prototype(query_img_path, k, model, metric=\"euclidean\"):\n",
    "    \"\"\"\n",
    "    Strategia 2: distanza/similarità rispetto al prototipo (media) della classe.\n",
    "    \"\"\"\n",
    "    data = np.load(\"resnet_features_all.npz\")\n",
    "    features = data['features']\n",
    "    labels = data['labels']\n",
    "\n",
    "    query_feat = extract_and_process_image(query_img_path, model)\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    prototypes = []\n",
    "    for label in unique_labels:\n",
    "        class_feats = features[labels == label]\n",
    "        prototypes.append(class_feats.mean(axis=0))\n",
    "    prototypes = np.vstack(prototypes)\n",
    "\n",
    "    scores = compute_metric(query_feat, prototypes, metric)\n",
    "\n",
    "    if metric == \"euclidean\":\n",
    "        sorted_indices = np.argsort(scores)\n",
    "    else:\n",
    "        sorted_indices = np.argsort(scores)[::-1]\n",
    "\n",
    "    print(f\"--- Top-{k} etichette - Prototipo classe ({metric}) ---\")\n",
    "    for i in range(min(k, len(unique_labels))):\n",
    "        idx = sorted_indices[i]\n",
    "        print(f\"{unique_labels[idx]} \\t Score: {scores[idx]:.4f}\")\n",
    "\n",
    "def task4_predict_labels(query_img_path, k, model, metric=\"euclidean\"):\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "    print(f\"Predizione top-{k} per immagine '{query_img_path}' usando metrica '{metric}'\")\n",
    "    predict_top_k_labels_distance_mean(query_img_path, k, model, metric)\n",
    "    print()\n",
    "    predict_top_k_labels_prototype(query_img_path, k, model, metric)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f2ea7e",
   "metadata": {},
   "source": [
    "Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913e179a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_glioma/brain_glioma_1112.jpg\"\n",
    "\n",
    "task4_predict_labels(query_img, k=2, model=model, metric=\"euclidean\")\n",
    "print()\n",
    "task4_predict_labels(query_img, k=2, model=model, metric=\"cosine\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1bb9c1",
   "metadata": {},
   "source": [
    "Task 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d48dded",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space_2d(X_transformed, labels, technique, k):\n",
    "    \"\"\"Visualizza la proiezione 2D dello spazio latente.\"\"\"\n",
    "    if X_transformed.shape[1] < 2:\n",
    "        print(\"[INFO] Meno di 2 componenti: impossibile visualizzare in 2D.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_transformed[:, 0], y=X_transformed[:, 1], hue=labels, palette=\"Set2\", s=80)\n",
    "    plt.title(f\"{technique.upper()} - Proiezione sulle prime 2 componenti latenti (k={k})\")\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_kmeans_clusters_2d(feature_matrix, labels, n_clusters):\n",
    "    \"\"\"Visualizza i cluster KMeans in 2D usando SVD per proiezione.\"\"\"\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(feature_matrix)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=cluster_labels, palette='tab10', s=80, style=labels)\n",
    "    plt.title(f\"KMeans Clustering (k={n_clusters}) con proiezione SVD 2D\")\n",
    "    plt.xlabel(\"Componente Latente 1 (da SVD)\")\n",
    "    plt.ylabel(\"Componente Latente 2 (da SVD)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d81d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def task5_latent_semantics_resnet(feature_model_path, technique, k):\n",
    "    \"\"\"\n",
    "    Estrae i top-k concetti latenti da uno spazio di feature ResNet usando SVD, LDA o KMeans.\n",
    "    Salva i risultati su file e visualizza lo spazio latente.\n",
    "\n",
    "    Parametri:\n",
    "    ------------\n",
    "    - feature_model_path: percorso file .npz (es. \"resnet_layer3.npz\")\n",
    "    - technique: \"svd\", \"lda\", \"kmeans\"\n",
    "    - k: numero componenti/cluster da estrarre\n",
    "    \"\"\"\n",
    "\n",
    "    technique = technique.lower()\n",
    "\n",
    "    if technique == \"svd\":\n",
    "        model = TruncatedSVD(n_components=k, random_state=42)\n",
    "        X_transformed = model.fit_transform(feat_matrix_part1)\n",
    "        components = model.components_\n",
    "        method = \"svd\"\n",
    "\n",
    "    elif technique == \"lda\":\n",
    "        unique_labels = np.unique(lbls_part1)\n",
    "        max_k = len(unique_labels) - 1\n",
    "        if k > max_k:\n",
    "            print(f\"[ATTENZIONE] LDA supporta al massimo {max_k} componenti con {len(unique_labels)} classi.\")\n",
    "            k = max_k\n",
    "        model = LDA(n_components=k)\n",
    "        X_transformed = model.fit_transform(feat_matrix_part1, lbls_part1)\n",
    "        components = model.scalings_.T[:k]\n",
    "        method = \"lda\"\n",
    "\n",
    "    elif technique == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "        model.fit(feat_matrix_part1)\n",
    "        components = model.cluster_centers_\n",
    "        X_transformed = model.transform(feat_matrix_part1)\n",
    "        method = \"kmeans\"\n",
    "    else:\n",
    "        print(\"[ERRORE] Tecnica non supportata. Usa: 'svd', 'lda', 'kmeans'\")\n",
    "        return\n",
    "\n",
    "    # === Visualizzazione ===\n",
    "    if technique in [\"svd\", \"lda\"]:\n",
    "        plot_latent_space_2d(X_transformed, lbls_part1, technique, k)\n",
    "    elif technique == \"kmeans\":\n",
    "        plot_kmeans_clusters_2d(feat_matrix_part1, lbls_part1, k)\n",
    "\n",
    "    # === Output file ===\n",
    "    base_name = os.path.splitext(os.path.basename(feature_model_path))[0]\n",
    "    out_file = f\"latent_semantics_{method}_{base_name}_k{k}.txt\"\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for i in range(k):\n",
    "            f.write(f\"\\n--- Latent Semantic {i+1} ---\\n\")\n",
    "            if technique in [\"svd\", \"lda\"]:\n",
    "                weights = feat_matrix_part1 @ components[i].T\n",
    "            else:\n",
    "                weights = -X_transformed[:, i]  # distanza inversa\n",
    "\n",
    "            sorted_idx = np.argsort(-np.abs(weights))\n",
    "            for idx in sorted_idx:\n",
    "                f.write(f\"{flname_part1[idx]} | Peso: {weights[idx]:.4f} | Classe: {lbls_part1[idx]}\\n\")\n",
    "\n",
    "    print(f\"[SALVATO] Latent semantics salvati in: {out_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c479a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supponendo tu abbia salvato il file .npz come \"resnet_layer3.npz\"\n",
    "task5_latent_semantics_resnet(\"resnet_features_all.npz\", technique=\"svd\", k=5)\n",
    "task5_latent_semantics_resnet(\"resnet_features_all.npz\", technique=\"lda\", k=2)\n",
    "task5_latent_semantics_resnet(\"resnet_features_all.npz\", technique=\"kmeans\", k=6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c273e38",
   "metadata": {},
   "source": [
    "Task 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f24274",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_intrinsic_dimensionality(feature_matrix, threshold, plot=True):\n",
    "    max_components = min(feature_matrix.shape)\n",
    "    pca = PCA(n_components=max_components)\n",
    "    pca.fit(feature_matrix)\n",
    "\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    cumulative = np.cumsum(explained)\n",
    "    intrinsic_dim = np.argmax(cumulative >= threshold) + 1\n",
    "\n",
    "    #print(f\"[INFO] Spiegazione varianza per ogni componente PCA:\\n{explained}\")\n",
    "    #print(f\"[INFO] Varianza cumulativa:\\n{cumulative}\")\n",
    "    #print(f\"[INFO] Soglia impostata: {threshold}\")\n",
    "    #print(f\"[INFO] Dimensione intrinseca stimata: {intrinsic_dim}\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(cumulative, marker='o', label=\"Varianza cumulativa\")\n",
    "        plt.axhline(y=threshold, color='r', linestyle='--', label=f\"Soglia {threshold*100:.0f}%\")\n",
    "        plt.axvline(x=intrinsic_dim, color='g', linestyle='--', label=f\"k suggerito: {intrinsic_dim}\")\n",
    "        plt.xlabel(\"Numero componenti\")\n",
    "        plt.ylabel(\"Varianza cumulativa\")\n",
    "        plt.title(\"Scelta ottimale di k (PCA/SVD)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"[INFO] k ottimale suggerito (soglia {threshold*100:.0f}%): {intrinsic_dim}\")\n",
    "    return intrinsic_dim, cumulative\n",
    "\n",
    "def suggest_k(feature_matrix, threshold_list=[0.90, 0.95, 0.99]):\n",
    "    print(f\"[INFO] Feature matrix shape: {feature_matrix.shape}\")\n",
    "    k_values = {}\n",
    "    for t in threshold_list:\n",
    "        k, _ = estimate_intrinsic_dimensionality(feature_matrix, threshold=t, plot=False)\n",
    "        k_values[t] = k\n",
    "        print(f\"Soglia {int(t*100)}% : k = {k}\")\n",
    "    return k_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ebcc42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dimensionality_per_label(feature_matrix, labels, threshold):\n",
    "    label_dim_map = {}\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"[INFO] Etichette uniche trovate: {len(unique_labels)}\")\n",
    "\n",
    "    for label in unique_labels:\n",
    "        indices = np.where(labels == label)[0]\n",
    "        label_features = feature_matrix[indices]\n",
    "\n",
    "        if len(indices) < 2:\n",
    "            print(f\"[AVVISO] Label '{label}' ha meno di 2 campioni — ignorata.\")\n",
    "            continue\n",
    "\n",
    "        k, _ = estimate_intrinsic_dimensionality(label_features, threshold=threshold, plot=False)\n",
    "        label_dim_map[label] = k\n",
    "        print(f\" Label '{label}' : k = {k}\")\n",
    "\n",
    "    return label_dim_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515b1674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola k per varie soglie\n",
    "print(\"\\Stima automatica di k in base alla varianza spiegata:\\n\")\n",
    "k_suggeriti = suggest_k(feat_matrix_part1)\n",
    "# Plot dettagliato per la soglia 95%\n",
    "estimate_intrinsic_dimensionality(feat_matrix_part1, threshold=0.95, plot=True)\n",
    "\n",
    "\n",
    "print(\"\\n Task 6b – Dimensionalità per etichetta:\\n\")\n",
    "label_dimensionalities = estimate_dimensionality_per_label(feat_matrix_part1, lbls_part1, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c87115",
   "metadata": {},
   "source": [
    "Task 7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8f2692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latent_semantics_per_class(X, y, k=10):\n",
    "    class_models = {}\n",
    "    class_means = {}\n",
    "\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        X_class = X[y == label]  # Prende solo le istanze della classe corrente\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_class)  # Normalizza i dati della classe\n",
    "\n",
    "        svd = TruncatedSVD(n_components=k)\n",
    "        latent = svd.fit_transform(X_scaled)  # Riduzione dimensionale con SVD\n",
    "\n",
    "        # Salva modello SVD e scaler per la classe\n",
    "        class_models[label] = {\n",
    "            'svd': svd,\n",
    "            'scaler': scaler,\n",
    "            'latent_vectors': latent\n",
    "        }\n",
    "        # Calcola la media dei vettori latenti della classe\n",
    "        class_means[label] = np.mean(latent, axis=0)\n",
    "    return class_models, class_means\n",
    "\n",
    "def predict_label(X_test, class_models, class_means):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        best_label = None\n",
    "        min_dist = float('inf')\n",
    "        for label, model in class_models.items():\n",
    "            x_scaled = model['scaler'].transform(x.reshape(1, -1))  # Normalizza x\n",
    "            x_latent = model['svd'].transform(x_scaled)  # Trasforma in spazio latente\n",
    "            dist = np.linalg.norm(x_latent - class_means[label])  # Distanza dal centroide\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_label = label\n",
    "        y_pred.append(best_label)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    labels = np.unique(y_true)\n",
    "    print(\"Per-class metrics:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        print(\n",
    "            f\"Class {label}: P={precision[i]:.2f}, R={recall[i]:.2f}, F1={f1[i]:.2f}\")\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "def evaluate_predictions(true_labels, predicted_labels):\n",
    "    print(\"[VALUTAZIONE] Report di classificazione:\")\n",
    "    print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dec790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento sui dati di Part1\n",
    "class_models, class_means = compute_latent_semantics_per_class(\n",
    "    feat_matrix_part1, lbls_part1, k=10)\n",
    "\n",
    "# Predizione su Part2\n",
    "predicted_labels = predict_label(feat_matrix_part2, class_models, class_means)\n",
    "\n",
    "# Valutazione\n",
    "evaluate(lbls_part2, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3d3b70",
   "metadata": {},
   "source": [
    "task 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3533e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.manifold import MDS\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def cluster_with_dbscan_per_class(X, y, filenames, eps, min_samples):\n",
    "    label_clusters = {}\n",
    "\n",
    "    for label in np.unique(y):\n",
    "        X_class = X[y == label]\n",
    "        fn_class = filenames[y == label]\n",
    "\n",
    "        # Standardizzazione\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_class)\n",
    "\n",
    "        # Clustering DBSCAN\n",
    "        db = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=-1).fit(X_scaled)\n",
    "        labels_db = db.labels_\n",
    "\n",
    "        print(f\"[INFO] Classe {label}: trovati {len(np.unique(labels_db)) - (1 if -1 in labels_db else 0)} cluster\")\n",
    "\n",
    "        # Salva risultati\n",
    "        label_clusters[label] = {\n",
    "            'features': X_scaled,\n",
    "            'cluster_labels': labels_db,\n",
    "            'filenames': fn_class\n",
    "        }\n",
    "\n",
    "        # Visualizzazione 2D\n",
    "        visualize_mds(X_scaled, labels_db, label)\n",
    "\n",
    "        # Visualizzazione thumbnails\n",
    "        show_cluster_thumbnails(fn_class, labels_db, label)\n",
    "\n",
    "    return label_clusters\n",
    "\n",
    "\n",
    "def visualize_mds(X, cluster_labels, label, max_points=500):\n",
    "    # Riduci campioni per grafico se troppi\n",
    "    if len(X) > max_points:\n",
    "        idx = np.random.choice(len(X), max_points, replace=False)\n",
    "        X = X[idx]\n",
    "        cluster_labels = cluster_labels[idx]\n",
    "\n",
    "    mds = MDS(n_components=2, random_state=42, dissimilarity='euclidean')\n",
    "    X_2d = mds.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=cluster_labels, cmap='tab10', s=50, alpha=0.7)\n",
    "    plt.title(f\"MDS 2D - Classe {label}\")\n",
    "    plt.xlabel(\"Dim 1\")\n",
    "    plt.ylabel(\"Dim 2\")\n",
    "    plt.colorbar(scatter, label=\"Cluster\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_cluster_thumbnails(filenames, cluster_labels, label, thumb_size=(64, 64), images_per_row=10):\n",
    "    clusters = np.unique(cluster_labels)\n",
    "    for clust in clusters:\n",
    "        if clust == -1:\n",
    "            continue  # Salta outlier\n",
    "        indices = np.where(cluster_labels == clust)[0]\n",
    "        n_images = len(indices)\n",
    "        if n_images == 0:\n",
    "            continue\n",
    "        print(f\"[CLUSTER] Classe {label} - Cluster {clust} - {n_images} immagini\")\n",
    "\n",
    "        n_rows = int(np.ceil(n_images / images_per_row))\n",
    "        fig, axs = plt.subplots(n_rows, images_per_row, figsize=(images_per_row, n_rows))\n",
    "        axs = axs.ravel()\n",
    "\n",
    "        for i, ax in enumerate(axs):\n",
    "            if i < n_images:\n",
    "                try:\n",
    "                    img = Image.open(filenames[indices[i]]).resize(thumb_size)\n",
    "                    ax.imshow(img)\n",
    "                    ax.axis('off')\n",
    "                except:\n",
    "                    ax.axis('off')\n",
    "            else:\n",
    "                ax.axis('off')\n",
    "\n",
    "        plt.suptitle(f\"Thumbnails - Classe {label} - Cluster {clust}\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd40070e",
   "metadata": {},
   "source": [
    "task 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f2d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Imposta il valore di m per l'm-NN\n",
    "m = 5  # Modifica questo valore in base alle tue necessità\n",
    "\n",
    "# Addestramento m-NN\n",
    "knn_model = KNeighborsClassifier(n_neighbors=m)\n",
    "knn_model.fit(feat_matrix_part1, lbls_part1)\n",
    "\n",
    "# Addestramento Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(feat_matrix_part1, lbls_part1)\n",
    "\n",
    "# Predizioni su Part2\n",
    "pred_knn = knn_model.predict(feat_matrix_part2)\n",
    "pred_dt = dt_model.predict(feat_matrix_part2)\n",
    "\n",
    "# Valutazione m-NN\n",
    "print(\"Risultati m-NN:\")\n",
    "print(classification_report(lbls_part2, pred_knn))\n",
    "print(\"Accuratezza complessiva m-NN:\", accuracy_score(lbls_part2, pred_knn))\n",
    "\n",
    "# Valutazione Decision Tree\n",
    "print(\"Risultati Decision Tree:\")\n",
    "print(classification_report(lbls_part2, pred_dt))\n",
    "print(\"Accuratezza complessiva Decision Tree:\", accuracy_score(lbls_part2, pred_dt))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57d34d7",
   "metadata": {},
   "source": [
    "Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d64c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe LSH con quantizzazione\n",
    "\n",
    "class LSH_EuclideanQuantized:\n",
    "    \"\"\"\n",
    "    LSH per distanza Euclidea (p-stable) con bucket width r.\n",
    "    Ogni hash h_j(v) = floor((a_j · v + b_j) / r).\n",
    "\n",
    "    Parametri:\n",
    "      - num_layers   = L = numero di tavole hash\n",
    "      - num_hashes   = h = numero di functions concatenati in ciascuna tavola\n",
    "      - dim          = D = dimensione dei vettori di input\n",
    "      - r            = bucket width (parte intera di quantizzazione)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers: int, num_hashes: int, dim: int, r: float):\n",
    "        self.L = num_layers\n",
    "        self.h = num_hashes\n",
    "        self.d = dim\n",
    "        self.r = r\n",
    "\n",
    "        # Prepara L tavole hash: ciascuna è un dict (chiave tuple di h interi -> lista di indici)\n",
    "        self.hash_tables = [defaultdict(list) for _ in range(self.L)]\n",
    "\n",
    "        # Per ogni layer l=0..L-1, e per ogni j=0..h-1, genero:\n",
    "        #   - a_lj  vettore gaussiano di dimensione D\n",
    "        #   - b_lj  offset (uniforme in [0, r) )\n",
    "        self.a_vectors = [\n",
    "            [np.random.randn(self.d) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "        self.b_offsets = [\n",
    "            [np.random.uniform(0, self.r) for _ in range(self.h)]\n",
    "            for _ in range(self.L)\n",
    "        ]\n",
    "\n",
    "        # Memorizzerò i vettori originali di Part1 in questo array, shape=(N, D)\n",
    "        self.data_vectors = None\n",
    "\n",
    "    def _compute_hash_tuple(self, vec: np.ndarray, layer_idx: int) -> tuple:\n",
    "        \"\"\"\n",
    "        Calcola l'hash (h interi) per il layer layer_idx su un vettore vec:\n",
    "          h_j = floor((a_vectors[layer_idx][j] · vec + b_offsets[layer_idx][j]) / r)\n",
    "        Ritorna una tupla di h interi.\n",
    "        \"\"\"\n",
    "        keys = []\n",
    "        a_vs = self.a_vectors[layer_idx]\n",
    "        b_os = self.b_offsets[layer_idx]\n",
    "        for j in range(self.h):\n",
    "            a_j = a_vs[j]         # vettore dimensione D\n",
    "            b_j = b_os[j]         # float in [0, r)\n",
    "            proj = float(np.dot(a_j, vec) + b_j)\n",
    "            h_val = int(np.floor(proj / self.r))\n",
    "            keys.append(h_val)\n",
    "        return tuple(keys)\n",
    "\n",
    "    def index(self, vectors: np.ndarray):\n",
    "        \"\"\"\n",
    "        Costruisci l'indice LSH su un insieme di vettori di Part1:\n",
    "          vectors: numpy array shape = (N, D)\n",
    "        Al termine di questa chiamata:\n",
    "          - self.data_vectors = vectors\n",
    "          - self.hash_tables[l][hash_tuple] conterrà la lista di indici i per cui\n",
    "            hash_tuple = _compute_hash_tuple(vectors[i], l).\n",
    "        \"\"\"\n",
    "        self.data_vectors = vectors\n",
    "        N, D = vectors.shape\n",
    "        assert D == self.d, f\"Errore: dimensione vettore ({D}) ≠ atteso ({self.d}).\"\n",
    "\n",
    "        # Inserisco ogni vettore in ciascuna tavola hash\n",
    "        for idx in range(N):\n",
    "            v = vectors[idx]\n",
    "            for l in range(self.L):\n",
    "                key = self._compute_hash_tuple(v, l)\n",
    "                self.hash_tables[l][key].append(idx)\n",
    "\n",
    "    def query(self, q_vec: np.ndarray, top_t: int = 5):\n",
    "        \"\"\"\n",
    "        Esegui una query LSH per cercare i top_t vettori più vicini a q_vec.\n",
    "        Restituisce:\n",
    "          - top_results: lista di tuple (indice, distanza) ord. per dist. crescente\n",
    "          - unique_count: numero di indici distinti considerati (cardinalità dei candidati)\n",
    "          - total_checked: somma della lunghezza di tutti i bucket esaminati\n",
    "        \"\"\"\n",
    "        assert q_vec.shape[0] == self.d, \"Errore: dimensione query ≠ D.\"\n",
    "        candidati = set()\n",
    "        total_checked = 0\n",
    "\n",
    "        # Per ciascun layer, ottengo la chiave polidimensionale e i suoi bucket\n",
    "        for l in range(self.L):\n",
    "            h_tuple = self._compute_hash_tuple(q_vec, l)\n",
    "            bucket = self.hash_tables[l].get(h_tuple, [])\n",
    "            total_checked += len(bucket)\n",
    "            candidati.update(bucket)\n",
    "\n",
    "        # Ora calcolo la distanza euclidea esatta tra q_vec e ciascun candidato\n",
    "        risultati = []\n",
    "        for idx in candidati:\n",
    "            v_i = self.data_vectors[idx]\n",
    "            dist = np.linalg.norm(v_i - q_vec)\n",
    "            risultati.append((idx, dist))\n",
    "\n",
    "        # Ordino e prendo i primi top_t\n",
    "        risultati.sort(key=lambda x: x[1])\n",
    "        top_results = risultati[:top_t]\n",
    "        return top_results, len(candidati), total_checked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd54c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# costruzione LSH_EuclideanQuantized su Part1\n",
    "\n",
    "# 1) (Opzionale ma consigliato) centra e normalizza i vettori di Part1\n",
    "#    Questo passaggio riduce l'effetto di scale diverse e spesso migliora la qualità LSH\n",
    "mean_vec = np.mean(feat_matrix_part1, axis=0)\n",
    "feat_centered = feat_matrix_part1 - mean_vec\n",
    "feat_normed = normalize(feat_centered, norm='l2', axis=1)\n",
    "\n",
    "# 2) Parametri LSH\n",
    "D = feat_normed.shape[1]      # di solito 900\n",
    "L = 10                         # numero di tavole hash (scegli in base a esperimenti)\n",
    "h = 7                      # numero di funzioni concatenati in ciascuna tavola\n",
    "r = 1                       # parametro di larghezza (esempio: 0.5); puoi sperimentare\n",
    "\n",
    "# 3) Creo l'oggetto e indicizzo\n",
    "lsh_quant = LSH_EuclideanQuantized(num_layers=L, num_hashes=h, dim=D, r=r)\n",
    "lsh_quant.index(feat_normed)\n",
    "\n",
    "print(f\"[INFO] LSH quantizzato costruito: D={D}, L={L}, h={h}, r={r}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19aa9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funzione per cercare top_k con LSH quantizzato\n",
    "\n",
    "def find_k_similar_lsh_quant(base_folder: str, img_path: str, k: int):\n",
    "    \"\"\"\n",
    "    Cerca le k immagini di Part1 più simili a img_path (di Part2) usando LSH_EuclideanQuantized.\n",
    "    Stampa:\n",
    "      - i primi k risultati (file name, label, distanza)\n",
    "      - il numero di immagini uniche considerate\n",
    "      - il numero totale di controlli (somma delle lunghezze dei bucket)\n",
    "    E poi visualizza (query + k risultati) con matplotlib.\n",
    "    \"\"\"\n",
    "    # 1) Estrazione feature raw (900-dim) con la funzione esistente\n",
    "    raw_q = np.array(extract_and_process_image(img_path,model), dtype=np.float32)\n",
    "\n",
    "    # 2) Center + normalize (stesso mean_vec e L2 norm usati su Part1)\n",
    "    q_centered = raw_q - mean_vec\n",
    "    q_normed = q_centered / np.linalg.norm(q_centered)\n",
    "\n",
    "    # 3) Chiamata a LSH\n",
    "    top_results, unique_count, total_checked = lsh_quant.query(q_normed, top_t=k)\n",
    "\n",
    "    # 4) Stampa output testuale\n",
    "    print(f\"\\n[LSH-Quant] Top {k} simili a: {img_path}\")\n",
    "    for rank, (idx, dist) in enumerate(top_results, start=1):\n",
    "        label = lbls_part1[idx]\n",
    "        fname = flname_part1[idx]\n",
    "        print(f\"  {rank}. {fname} | Classe: {label} | Distanza Euclidea: {dist:.2f}\")\n",
    "    print(f\"[LSH-Quant] Immagini uniche considerate: {unique_count}\")\n",
    "    print(f\"[LSH-Quant] Immagini totali controllate: {total_checked}\")\n",
    "\n",
    "    # 5) Visualizzazione (query + primi k risultati)\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(4*(k+1), 4))\n",
    "    img_q = cv2.imread(img_path)\n",
    "    img_q = cv2.cvtColor(img_q, cv2.COLOR_BGR2RGB)\n",
    "    axs[0].imshow(img_q)\n",
    "    axs[0].set_title(\"Query (LSH-Quant)\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, (idx, dist) in enumerate(top_results, start=1):\n",
    "        lab = lbls_part1[idx]\n",
    "        fname = flname_part1[idx]\n",
    "        full_path = os.path.join(base_folder, lab, fname)\n",
    "        img_match = cv2.imread(full_path)\n",
    "        img_match = cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB)\n",
    "        axs[i].imshow(img_match)\n",
    "        axs[i].set_title(f\"Rank {i}\\nd={dist:.2f}\")\n",
    "        axs[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65090a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Esempio di utilizzo su un'immagine di Part2 ---\n",
    "query_path = \"Part2/brain_glioma/brain_glioma_1409.jpg\"\n",
    "\n",
    "k = 5                         # numero di immagini simili da visualizzare\n",
    "\n",
    "# Eseguo la ricerca LSH\n",
    "find_k_similar_lsh_quant(\"Part1\", query_path, k)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
