{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3879fff0",
   "metadata": {},
   "source": [
    "Import necessari:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "99a7224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "from skimage.feature import hog\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import functional as F\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3286363c",
   "metadata": {},
   "source": [
    "Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "97c5311a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(npz_path):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    return data['features'], data['labels'], data.get('filenames', [f\"img_{i}\" for i in range(len(data['features']))])\n",
    "\n",
    "\n",
    "feat_matrix_part1, lbls_part1, flname_part1 = load_features(\n",
    "    \"hog_features_part1.npz\")\n",
    "feat_matrix_part2, lbls_part2, flname_part2 = load_features(\n",
    "    \"hog_features_part2.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7053a783",
   "metadata": {},
   "source": [
    "Seconda implementazione"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e16956",
   "metadata": {},
   "source": [
    "Task 2 : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a99d462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Funzione: Estrazione HOG ===\n",
    "def extract_hog_features_from_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRORE] Immagine non trovata o non valida: {img_path}\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (128, 128))  # dimensione standard\n",
    "\n",
    "    features, _ = hog(resized,\n",
    "                      orientations=9,\n",
    "                      pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2),\n",
    "                      visualize=True,\n",
    "                      block_norm='L2-Hys')\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0beff54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    \"\"\"Estrae le feature da immagini organizzate in sottocartelle e le salva in un file .npz.\"\"\"\n",
    "    all_features, all_filenames, all_labels = [], [], []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_hog_features_from_image(img_path)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a0503565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Elaboro cartella: brain_glioma\n",
      "[INFO] Elaboro cartella: brain_menin\n",
      "[INFO] Elaboro cartella: brain_tumor\n",
      "[SALVATO] Features salvate in hog_features_part1.npz\n",
      "[INFO] Elaboro cartella: brain_glioma\n",
      "[INFO] Elaboro cartella: brain_menin\n",
      "[INFO] Elaboro cartella: brain_tumor\n",
      "[SALVATO] Features salvate in hog_features_part2.npz\n"
     ]
    }
   ],
   "source": [
    "# Parametri\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "\n",
    "# Estrazione e salvataggio\n",
    "process_and_save_features(\"Part1\", subfolders, \"hog_features_part1.npz\")\n",
    "process_and_save_features(\"Part2\", subfolders, \"hog_features_part2.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e544b1f2",
   "metadata": {},
   "source": [
    "Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd2c0e",
   "metadata": {},
   "source": [
    "Distanza coseno:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12503d98",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Incompatible dimension for X and Y matrices: X.shape[1] == 900 while Y.shape[1] == 8100",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m query_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPart1/brain_glioma/brain_glioma_0001.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m11\u001b[39m\n\u001b[0;32m---> 74\u001b[0m \u001b[43mfind_similar_images_npz\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[87], line 57\u001b[0m, in \u001b[0;36mfind_similar_images_npz\u001b[0;34m(query_path, k, npz_path, base_folder)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Calcola la similarità coseno\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m similarities \u001b[38;5;241m=\u001b[39m \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Ordina per similarità decrescente\u001b[39;00m\n\u001b[1;32m     60\u001b[0m sorted_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(similarities)[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:1679\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[0;34m(X, Y, dense_output)\u001b[0m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \n\u001b[1;32m   1637\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1677\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[0;32m-> 1679\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1681\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/pairwise.py:214\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[0;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecomputed metric requires shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(n_queries, n_indexed). Got (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m indexed.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    210\u001b[0m         )\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m ensure_2d \u001b[38;5;129;01mand\u001b[39;00m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# Only check the number of features if 2d arrays are enforced. Otherwise,\u001b[39;00m\n\u001b[1;32m    213\u001b[0m     \u001b[38;5;66;03m# validation is left to the user for custom metrics.\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncompatible dimension for X and Y matrices: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    216\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m while Y.shape[1] == \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    217\u001b[0m     )\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m X, Y\n",
      "\u001b[0;31mValueError\u001b[0m: Incompatible dimension for X and Y matrices: X.shape[1] == 900 while Y.shape[1] == 8100"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Funzione: Estrai feature HOG dalla query ===\n",
    "def extract_hog_features(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRORE] Immagine non trovata o non valida: {img_path}\")\n",
    "        return None\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    resized = cv2.resize(gray, (128, 128))\n",
    "    features, _ = hog(resized,\n",
    "                      orientations=9,\n",
    "                      pixels_per_cell=(8, 8),\n",
    "                      cells_per_block=(2, 2),\n",
    "                      visualize=True,\n",
    "                      block_norm='L2-Hys')\n",
    "    return features\n",
    "\n",
    "# === Funzione: Visualizza immagini simili ===\n",
    "def show_similar_images(results, base_folder):\n",
    "    fig, axes = plt.subplots(1, len(results), figsize=(15, 5))\n",
    "    if len(results) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, (filename, score) in zip(axes, results):\n",
    "        img_path = None\n",
    "        # Cerca nei sottocartelle\n",
    "        for subdir in os.listdir(base_folder):\n",
    "            candidate_path = os.path.join(base_folder, subdir, filename)\n",
    "            if os.path.exists(candidate_path):\n",
    "                img_path = candidate_path\n",
    "                break\n",
    "        if img_path:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"{filename}\\nSim: {score:.2f}\")\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.set_title(f\"Non trovata: {filename}\")\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Funzione principale ===\n",
    "def find_similar_images_npz(query_path, k, npz_path=\"hog_features_all.npz\", base_folder=\"Part1\"):\n",
    "    # Carica i dati dal file .npz\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    X = data[\"features\"]\n",
    "    filenames = data[\"filenames\"]\n",
    "\n",
    "    # Estrai le feature dalla query\n",
    "    query_features = extract_hog_features_from_image(img_path)\n",
    "    if query_features is None:\n",
    "        print(\"[ERRORE] Impossibile estrarre feature dalla query.\")\n",
    "        return\n",
    "\n",
    "    # Calcola la similarità coseno\n",
    "    similarities = cosine_similarity([query_features], X)[0]\n",
    "\n",
    "    # Ordina per similarità decrescente\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    top_k = sorted_indices[:k]\n",
    "\n",
    "    results = [(filenames[i], similarities[i]) for i in top_k]\n",
    "\n",
    "    print(f\"[RISULTATI] Le {k} immagini più simili a '{os.path.basename(query_path)}':\")\n",
    "    for fname, score in results:\n",
    "        print(f\"- {fname} (similarità: {score:.4f})\")\n",
    "\n",
    "    show_similar_images(results, base_folder)\n",
    "\n",
    "# === ESEMPIO DI USO ===\n",
    "query_image = \"Part1/brain_glioma/brain_glioma_0001.jpg\"\n",
    "k = 11\n",
    "find_similar_images_npz(query_image, k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6958d312",
   "metadata": {},
   "source": [
    "Distanza euclidea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24306a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# === Funzione: Visualizza immagini simili ===\n",
    "def show_similar_images(results, base_folder):\n",
    "    fig, axes = plt.subplots(1, len(results), figsize=(15, 5))\n",
    "    if len(results) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, (filename, dist) in zip(axes, results):\n",
    "        img_path = None\n",
    "        for subdir in os.listdir(base_folder):\n",
    "            candidate_path = os.path.join(base_folder, subdir, filename)\n",
    "            if os.path.exists(candidate_path):\n",
    "                img_path = candidate_path\n",
    "                break\n",
    "        if img_path:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"{filename}\\nDist: {dist:.2f}\")\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.set_title(f\"Non trovata: {filename}\")\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Funzione principale ===\n",
    "def find_similar_images_npz(query_path, k, npz_path=\"hog_features_all.npz\", base_folder=\"Part1\"):\n",
    "    # Carica i dati dal file .npz\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    X = data['features']\n",
    "    filenames = data['filenames']\n",
    "\n",
    "    # Estrai feature della query\n",
    "    query_features = extract_hog_features(query_path)\n",
    "    if query_features is None:\n",
    "        print(\"[ERRORE] Impossibile estrarre feature dalla query.\")\n",
    "        return\n",
    "\n",
    "    # Calcola distanza euclidea\n",
    "    distances = euclidean_distances([query_features], X)[0]\n",
    "\n",
    "    # Ordina per distanza crescente\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    top_k = sorted_indices[:k]\n",
    "\n",
    "    results = [(filenames[i], distances[i]) for i in top_k]\n",
    "\n",
    "    print(f\"[RISULTATI] Le {k} immagini più simili a '{os.path.basename(query_path)}':\")\n",
    "    for fname, dist in results:\n",
    "        print(f\"- {fname} (distanza: {dist:.4f})\")\n",
    "\n",
    "    show_similar_images(results, base_folder)\n",
    "\n",
    "# === Esempio di utilizzo ===\n",
    "query_image = \"Part1/brain_glioma/brain_glioma_0001.jpg\"\n",
    "k = 11\n",
    "find_similar_images_npz(query_image, k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f16b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Distanza Chi-Squared ===\n",
    "def chi2_distance(a, b, eps=1e-10):\n",
    "    return 0.5 * np.sum(((a - b) ** 2) / (a + b + eps))\n",
    "\n",
    "# === Similarità Correlazione ===\n",
    "def correlation_similarity(a, B):\n",
    "    a_mean = a - np.mean(a)\n",
    "    B_mean = B - np.mean(B, axis=1, keepdims=True)\n",
    "    num = np.dot(B_mean, a_mean)\n",
    "    denom = np.linalg.norm(B_mean, axis=1) * np.linalg.norm(a_mean)\n",
    "    return num / (denom + 1e-10)\n",
    "\n",
    "# === Visualizza immagini ===\n",
    "def show_images(results, base_folder):\n",
    "    fig, axes = plt.subplots(1, len(results), figsize=(15, 5))\n",
    "    if len(results) == 1:\n",
    "        axes = [axes]\n",
    "    for ax, (filename, score) in zip(axes, results):\n",
    "        img_path = None\n",
    "        for subdir in os.listdir(base_folder):\n",
    "            candidate_path = os.path.join(base_folder, subdir, filename)\n",
    "            if os.path.exists(candidate_path):\n",
    "                img_path = candidate_path\n",
    "                break\n",
    "        if img_path:\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(f\"{filename}\\nScore: {score:.2f}\")\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.set_title(f\"Non trovata: {filename}\")\n",
    "            ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === Trova immagini simili ===\n",
    "def find_similar_images_npz(img_path, k, metric):\n",
    "\n",
    "    query_features = extract_hog_features_from_image(img_path)\n",
    "    if query_features is None:\n",
    "        print(\"[ERRORE] Impossibile estrarre feature dalla query.\")\n",
    "        return\n",
    "\n",
    "    # === Calcolo distanza/similarità ===\n",
    "    if metric == \"cosine\":\n",
    "        similarities = cosine_similarity([query_features], feat_matrix_part1)[0]\n",
    "        sorted_indices = np.argsort(similarities)[::-1]  # similarità -> decrescente\n",
    "        results = [(flname_part1[i], similarities[i]) for i in sorted_indices[:k]]\n",
    "    elif metric == \"euclidean\":\n",
    "        distances = euclidean_distances([query_features], feat_matrix_part1)[0]\n",
    "        sorted_indices = np.argsort(distances)  # distanza -> crescente\n",
    "        results = [(flname_part1[i], distances[i]) for i in sorted_indices[:k]]\n",
    "    elif metric == \"manhattan\":\n",
    "        distances = manhattan_distances([query_features], feat_matrix_part1)[0]\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        results = [(flname_part1[i], distances[i]) for i in sorted_indices[:k]]\n",
    "    elif metric == \"chi2\":\n",
    "        distances = np.array([chi2_distance(query_features, feat_matrix_part1) for x in feat_matrix_part1])\n",
    "        sorted_indices = np.argsort(distances)\n",
    "        results = [(flname_part1[i], distances[i]) for i in sorted_indices[:k]]\n",
    "    elif metric == \"correlation\":\n",
    "        similarities = correlation_similarity(query_features, feat_matrix_part1)\n",
    "        sorted_indices = np.argsort(similarities)[::-1]\n",
    "        results = [(flname_part1[i], similarities[i]) for i in sorted_indices[:k]]\n",
    "    else:\n",
    "        print(f\"[ERRORE] Metrica non supportata: {metric}\")\n",
    "        return\n",
    "\n",
    "    print(f\"[RISULTATI - {metric}] Le {k} immagini più simili a '{os.path.basename(img_path)}':\")\n",
    "    for fname, score in results:\n",
    "        print(f\"- {fname} (score: {score:.4f})\")\n",
    "\n",
    "    show_similar_images(results, base_folder)\n",
    "\n",
    "# === Esempio di uso ===\n",
    "query_image = \"Part1/brain_menin/brain_menin_0013.jpg\"\n",
    "k = 5\n",
    "find_similar_images_npz(query_image, k, metric=\"cosine\")  # Cambia qui per provare cosine, euclidean, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4adae54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar(base_folder, img_path, k):\n",
    "    \"\"\"Trova le k immagini più simili in base alla distanza euclidea.\"\"\"\n",
    "    query_feature = extract_hog_features_from_image(img_path)\n",
    "    if query_feature is None:\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    distances = euclidean_distances(feat_matrix_part1, query_feature).flatten()\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "\n",
    "    print(f\"\\nTop {k} immagini simili a: {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {flname_part1[idx]} | Classe: {lbls_part1[idx]} | Distanza: {distances[idx]:.2f}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        img_match = cv2.imread(os.path.join(base_folder, lbls_part1[idx], flname_part1[idx]))\n",
    "        axs[i+1].imshow(cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB))\n",
    "        axs[i+1].set_title(f\"Rank {i+1}\\nD={distances[idx]:.2f}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d41c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Part1\"\n",
    "query_img = \"Part1/brain_glioma/brain_glioma_0005.jpg\"\n",
    "find_k_similar(base_folder, query_img, k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e4ee3d",
   "metadata": {},
   "source": [
    "Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0c338e",
   "metadata": {},
   "source": [
    "Comparazione tra le due tecniche:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f6b9a700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_label_ranking_strategies(query_img_path, k=2):\n",
    "    \"\"\"\n",
    "    Confronta le etichette predette da due strategie:\n",
    "    - distanza media per classe\n",
    "    - distanza al rappresentante (prototipo) della classe\n",
    "    Visualizza solo le top-k etichette con un grafico comparativo.\n",
    "    \"\"\"\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "\n",
    "    query_feature = extract_hog_features_from_image(query_img_path)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Feature non estratte.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "\n",
    "    # ===== Strategia 1: distanza media per classe =====\n",
    "    distances_all = cosine_similarity(feat_matrix_part1, query_feature).flatten()\n",
    "    df_all = pd.DataFrame({\n",
    "        'label': lbls_part1,\n",
    "        'distance': distances_all\n",
    "    })\n",
    "    mean_dists = df_all.groupby('label')['distance'].mean().sort_values()\n",
    "\n",
    "    # ===== Strategia 2: distanza dal prototipo (centroide) =====\n",
    "    df_features = pd.DataFrame(feat_matrix_part1)\n",
    "    df_features['label'] = lbls_part1\n",
    "    class_prototypes = df_features.groupby('label').mean().drop(columns=['label'], errors='ignore')\n",
    "    proto_vectors = class_prototypes.values\n",
    "    proto_labels = class_prototypes.index\n",
    "    proto_dists = cosine_similarity(proto_vectors, query_feature).flatten()\n",
    "    proto_dists_series = pd.Series(proto_dists, index=proto_labels).sort_values()\n",
    "\n",
    "    # ===== Prendi le top-k etichette comuni =====\n",
    "    top_k_mean = mean_dists.head(k)\n",
    "    top_k_proto = proto_dists_series.head(k)\n",
    "\n",
    "    union_labels = sorted(set(top_k_mean.index).union(set(top_k_proto.index)))\n",
    "\n",
    "    # ===== Plot solo per le top-k etichette =====\n",
    "    x = np.arange(len(union_labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.bar(x - width/2, [mean_dists[label] for label in union_labels], width, label='Distanza Media')\n",
    "    ax.bar(x + width/2, [proto_dists_series[label] for label in union_labels], width, label='Distanza Prototipo')\n",
    "\n",
    "    ax.set_ylabel('Distanza')\n",
    "    ax.set_title(f\"Top-{k} Strategie - Query: {os.path.basename(query_img_path)}\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(union_labels)\n",
    "    ax.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ===== Stampa i top-k risultati =====\n",
    "    print(\"\\n Top-k etichette per ciascuna strategia:\\n\")\n",
    "    print(\"Strategia: Distanza Media\")\n",
    "    print(top_k_mean)\n",
    "\n",
    "    print(\"\\n Strategia: Prototipo di Classe\")\n",
    "    print(top_k_proto)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59797171",
   "metadata": {},
   "source": [
    "Esecuzione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9a38ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_glioma/brain_glioma_1142.jpg\"\n",
    "compare_label_ranking_strategies(query_img, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6f5b1b",
   "metadata": {},
   "source": [
    "Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "84ea53cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def task5_latent_semantics_hog(feature_model_path, technique, k):\n",
    "    \"\"\"\n",
    "    Estrae i top-k concetti latenti da feature HOG tramite SVD, LDA o KMeans.\n",
    "    Visualizza lo spazio latente ed esporta un file .txt con i pesi delle immagini.\n",
    "    \"\"\"\n",
    "    # Caricamento feature, nomi file ed etichette\n",
    "    data = np.load(feature_model_path)\n",
    "    feature_matrix = data['features']\n",
    "    filenames = data['filenames']\n",
    "    labels = data['labels']\n",
    "\n",
    "    technique = technique.lower()\n",
    "\n",
    "    if technique == \"svd\":\n",
    "        model = TruncatedSVD(n_components=k)\n",
    "        X_transformed = model.fit_transform(feature_matrix)\n",
    "        components = model.components_\n",
    "        method = \"svd\"\n",
    "\n",
    "    elif technique == \"lda\":\n",
    "        unique_labels = np.unique(labels)\n",
    "        max_k = min(k, len(unique_labels) - 1)\n",
    "        if k > max_k:\n",
    "            print(f\"[ATTENZIONE] LDA supporta al massimo {max_k} componenti con {len(unique_labels)} classi.\")\n",
    "            k = max_k\n",
    "        model = LDA(n_components=k)\n",
    "        X_transformed = model.fit_transform(feature_matrix, labels)\n",
    "        components = model.scalings_.T[:k]\n",
    "        method = \"lda\"\n",
    "\n",
    "    elif technique == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "        model.fit(feature_matrix)\n",
    "        components = model.cluster_centers_\n",
    "        X_transformed = model.transform(feature_matrix)\n",
    "        method = \"kmeans\"\n",
    "\n",
    "    else:\n",
    "        print(\"[ERRORE] Tecnica non supportata. Usa: 'svd', 'lda', 'kmeans'\")\n",
    "        return\n",
    "\n",
    "    # Visualizzazione\n",
    "    if technique in [\"svd\", \"lda\"]:\n",
    "        plot_latent_space_2d(X_transformed, labels, technique, k)\n",
    "    elif technique == \"kmeans\":\n",
    "        plot_kmeans_clusters_2d(feature_matrix, labels, k)\n",
    "\n",
    "    # Scrittura output\n",
    "    base_name = os.path.splitext(os.path.basename(feature_model_path))[0]\n",
    "    out_file = f\"latent_semantics_{method}_{base_name}_k{k}.txt\"\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for i in range(k):\n",
    "            f.write(f\"\\n--- Latent Semantic {i+1} ---\\n\")\n",
    "            if technique in [\"svd\", \"lda\"]:\n",
    "                weights = feature_matrix @ components[i].T\n",
    "            else:  # KMeans: distanza inversa\n",
    "                weights = -X_transformed[:, i]\n",
    "\n",
    "            sorted_idx = np.argsort(-np.abs(weights))\n",
    "            for idx in sorted_idx:\n",
    "                f.write(f\"{filenames[idx]} | Peso: {weights[idx]:.4f} | Classe: {labels[idx]}\\n\")\n",
    "\n",
    "    print(f\"[SALVATO] Latent semantics salvati in: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37c6277",
   "metadata": {},
   "source": [
    "Visualizzazione "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7521103a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space_2d(X_transformed, labels, technique, k):\n",
    "    \"\"\"Visualizza la proiezione 2D delle immagini nello spazio latente (solo per SVD/LDA).\"\"\"\n",
    "    if X_transformed.shape[1] < 2:\n",
    "        print(\"[INFO] Meno di 2 componenti: impossibile visualizzare in 2D.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_transformed[:, 0], y=X_transformed[:, 1], hue=labels, palette=\"Set2\", s=80)\n",
    "    plt.title(f\"{technique.upper()} - Proiezione sulle prime 2 componenti latenti (k={k})\")\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_kmeans_clusters_2d(feature_matrix, labels, n_clusters):\n",
    "    \"\"\"Visualizza le immagini raggruppate da KMeans su uno spazio 2D ridotto con SVD.\"\"\"\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(feature_matrix)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=cluster_labels, palette='tab10', s=80, style=labels)\n",
    "    plt.title(f\"KMeans Clustering (k={n_clusters}) con proiezione SVD 2D\")\n",
    "    plt.xlabel(\"Componente Latente 1 (da SVD)\")\n",
    "    plt.ylabel(\"Componente Latente 2 (da SVD)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c9976",
   "metadata": {},
   "source": [
    "Esecuzione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ba2b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "task5_latent_semantics_hog(\"hog_features_all.npz\", \"svd\", 5)\n",
    "task5_latent_semantics_hog(\"hog_features_all.npz\", \"lda\", 2)\n",
    "task5_latent_semantics_hog(\"hog_features_all.npz\", \"kmeans\", 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a6111e",
   "metadata": {},
   "source": [
    "Task7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b696bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latent_semantics_per_class(X, y, k=10):\n",
    "    class_models = {}\n",
    "    class_means = {}\n",
    "\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        X_class = X[y == label]  # Prende solo le istanze della classe corrente\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_class)  # Normalizza i dati della classe\n",
    "\n",
    "        svd = TruncatedSVD(n_components=k)\n",
    "        latent = svd.fit_transform(X_scaled)  # Riduzione dimensionale con SVD\n",
    "\n",
    "        # Salva modello SVD e scaler per la classe\n",
    "        class_models[label] = {\n",
    "            'svd': svd,\n",
    "            'scaler': scaler,\n",
    "            'latent_vectors': latent\n",
    "        }\n",
    "        # Calcola la media dei vettori latenti della classe\n",
    "        class_means[label] = np.mean(latent, axis=0)\n",
    "    return class_models, class_means\n",
    "\n",
    "def predict_label(X_test, class_models, class_means):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        best_label = None\n",
    "        min_dist = float('inf')\n",
    "        for label, model in class_models.items():\n",
    "            x_scaled = model['scaler'].transform(x.reshape(1, -1))  # Normalizza x\n",
    "            x_latent = model['svd'].transform(x_scaled)  # Trasforma in spazio latente\n",
    "            dist = np.linalg.norm(x_latent - class_means[label])  # Distanza dal centroide\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_label = label\n",
    "        y_pred.append(best_label)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    labels = np.unique(y_true)\n",
    "    print(\"Per-class metrics:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        print(\n",
    "            f\"Class {label}: P={precision[i]:.2f}, R={recall[i]:.2f}, F1={f1[i]:.2f}\")\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "def evaluate_predictions(true_labels, predicted_labels):\n",
    "    print(\"[VALUTAZIONE] Report di classificazione:\")\n",
    "    print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8611765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento sui dati di Part1\n",
    "class_models, class_means = compute_latent_semantics_per_class(\n",
    "    feat_matrix_part1, lbls_part1, k=10)\n",
    "\n",
    "# Predizione su Part2\n",
    "predicted_labels = predict_label(feat_matrix_part2, class_models, class_means)\n",
    "\n",
    "# Valutazione\n",
    "evaluate(lbls_part2, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
