{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088b8fc2",
   "metadata": {},
   "source": [
    "Color Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36d2ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eaae8",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "567059dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(\"color_moments.npz\", allow_pickle=True) = data[\"features\"]\n",
    "feature_matrix = data[\"features\"]\n",
    "filenames = data[\"filenames\"]\n",
    "labels = data[\"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58732e0",
   "metadata": {},
   "source": [
    "Crop automatico per isolare il cervello - Task1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00999225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_brain(img):\n",
    "    \"\"\"Ritaglia l'area informativa (cervello) da un'immagine.\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        return img[y:y+h, x:x+w]\n",
    "    return img  # fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6714dba",
   "metadata": {},
   "source": [
    "Estrazione Color Moments su griglia - Task 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8196bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_moments(img_path):\n",
    "    \"\"\"Estrae Color Moments su una griglia 10x10 da un'immagine.\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRORE] Immagine non trovata: {img_path}\")\n",
    "        return None\n",
    "\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    img = crop_to_brain(img)\n",
    "    img = cv2.resize(img, (300, 100))  # Griglia uniforme\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    grid_h, grid_w = h // 10, w // 10\n",
    "    features = []\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            cell = img[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]\n",
    "            for channel in range(3):\n",
    "                pixels = cell[:, :, channel].flatten()\n",
    "                if np.std(pixels) > 0:\n",
    "                    mean = np.mean(pixels)\n",
    "                    std = np.std(pixels)\n",
    "                    sk = skew(pixels)\n",
    "                    if np.isnan(sk): sk = 0\n",
    "                else:\n",
    "                    mean, std, sk = 0, 0, 0\n",
    "                features.extend([mean, std, sk])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0122b",
   "metadata": {},
   "source": [
    " Estrazione feature da più cartelle e salvataggio in .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8957034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    \"\"\"Estrae le feature da immagini organizzate in sottocartelle e le salva in un file .npz.\"\"\"\n",
    "    all_features, all_filenames, all_labels = [], [], []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_color_moments(img_path)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd46fed",
   "metadata": {},
   "source": [
    "Ricerca immagini simili (Euclidea) - Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a0add08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar(base_folder,img_path, k):\n",
    "    \"\"\"Trova le k immagini più simili in base alla distanza euclidea.\"\"\"\n",
    "    query_feature = extract_color_moments(img_path)\n",
    "    if query_feature is None:\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    distances = euclidean_distances(feature_matrix, query_feature).flatten()\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "\n",
    "    print(f\"\\nTop {k} immagini simili a: {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {filenames[idx]} | Classe: {labels[idx]} | Distanza: {distances[idx]:.2f}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        img_match = cv2.imread(os.path.join(base_folder, labels[idx], filenames[idx]))\n",
    "        axs[i+1].imshow(cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB))\n",
    "        axs[i+1].set_title(f\"Rank {i+1}\\nD={distances[idx]:.2f}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab512b0",
   "metadata": {},
   "source": [
    "Ricerca immagini simili (Mahalanobis) - Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a2fd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_mahalanobis(base_folder, img_path, k):\n",
    "    \"\"\"Trova le k immagini più simili usando distanza di Mahalanobis, escludendo la query.\"\"\"\n",
    "    # Estrai le feature dalla query\n",
    "    query_feature = extract_color_moments(img_path)\n",
    "    if query_feature is None:\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature)\n",
    "\n",
    "    # Calcola matrice di covarianza delle feature\n",
    "    cov = np.cov(feature_matrix.T)\n",
    "\n",
    "    # Inversione con fallback alla pseudoinversa\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"[ERRORE] Uso pseudoinversa per matrice non invertibile.\")\n",
    "        cov_inv = np.linalg.pinv(cov)\n",
    "\n",
    "    # Calcola distanza di Mahalanobis tra la query e tutte le immagini\n",
    "    distances = np.array([\n",
    "        mahalanobis(query_feature, f, cov_inv) for f in feature_matrix\n",
    "    ])\n",
    "\n",
    "    # Opzionale: escludi la query stessa (distanza 0)\n",
    "    # === Escludi la query basandoti sul path ===\n",
    "    query_filename = os.path.basename(img_path)\n",
    "    query_label = os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "    for i in range(len(filenames)):\n",
    "        if filenames[i] == query_filename and labels[i] == query_label:\n",
    "            distances[i] = np.inf\n",
    "            break\n",
    "\n",
    "    # Seleziona i top-k indici a distanza minima\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "    top_k_scores = distances[top_k_idx]\n",
    "\n",
    "    # Output testuale\n",
    "    print(f\"\\nTop {k} immagini simili (Mahalanobis): {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {filenames[idx]} | Classe: {labels[idx]} | Distanza: {top_k_scores[rank]:.2f}\")\n",
    "\n",
    "    # Visualizza le immagini\n",
    "    fig, axs = plt.subplots(1, k + 1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        img_match_path = os.path.join(base_folder, labels[idx], filenames[idx])\n",
    "        img_match = cv2.imread(img_match_path)\n",
    "        axs[i + 1].imshow(cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB))\n",
    "        axs[i + 1].set_title(f\"Rank {i + 1}\\nD={top_k_scores[i]:.2f}\")\n",
    "        axs[i + 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a2b6e",
   "metadata": {},
   "source": [
    "Esecuzione: Estrazione e salvataggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri\n",
    "base_folder = \"Part1\"\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "output_file = \"color_moments.npz\"\n",
    "\n",
    "# Estrazione e salvataggio\n",
    "process_and_save_features(base_folder, subfolders, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dbd1e1",
   "metadata": {},
   "source": [
    "Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27746597",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part1/brain_glioma/brain_glioma_0005.jpg\"\n",
    "find_k_similar(base_folder,query_img, k=5)\n",
    "find_k_similar_mahalanobis(base_folder,query_img, k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3292ca",
   "metadata": {},
   "source": [
    "Task 4:\n",
    "\n",
    "\t1.\tAccetti come input:\n",
    "\t    •\tun’immagine di query (da “Part2”)\n",
    "\t    •\tuna scelta dell’utente sul tipo di feature space\n",
    "\t    •\tun valore intero k <= 2.\n",
    "\t2.\tCalcoli le features dell’immagine di query secondo il feature space selezionato.\n",
    "\t3.\tCalcoli la distanza tra la query e tutte le immagini del dataset (es. Euclidea o Mahalanobis).\n",
    "\t4.\tRaggruppi le distanze per label e selezioni le k classi (etichette) più simili in media.\n",
    "\t5.\tStampi/ritorni una classifica delle k etichette più probabili con il rispettivo punteggio (es. distanza  media o somma inversa delle distanze)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67210468",
   "metadata": {},
   "source": [
    "Un feature space è lo spazio vettoriale dove ogni immagine è rappresentata come un vettore di caratteristiche (feature vector).\n",
    "\n",
    "Il selected feature space indica quale tipo di caratteristiche estrai per rappresentare l’immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "08f42b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_k_labels(query_img_path,k):\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "\n",
    "    query_feature = extract_color_moments(query_img_path)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Feature non estratte.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    distances = euclidean_distances(feature_matrix, query_feature).flatten()\n",
    "\n",
    "    # Crea un DataFrame per semplificare il raggruppamento\n",
    "    df = pd.DataFrame({\n",
    "        'filename': filenames,\n",
    "        'label': labels,\n",
    "        'distance': distances\n",
    "    })\n",
    "\n",
    "    # Calcola la distanza media per classe\n",
    "    avg_dist_per_label = df.groupby('label')['distance'].mean().sort_values()\n",
    "\n",
    "    # Prendi le k classi più simili\n",
    "    top_k_labels = avg_dist_per_label.head(k)\n",
    "\n",
    "    print(f\"\\nClassifica delle {k} etichette più probabili per la query:\")\n",
    "    for i, (label, score) in enumerate(top_k_labels.items(), 1):\n",
    "        print(f\"{i}. {label} | Score (distanza media): {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_glioma/brain_glioma_1112.jpg\"\n",
    "predict_top_k_labels(query_img,k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa6891",
   "metadata": {},
   "source": [
    "Task 5\n",
    "\n",
    "feature model è il file dei dati delle feature che già estratto. Una rappresentazione di tutte le immagini del dataset in un certo feature space, salvata come matrice (feature_matrix), dove ogni riga è un’immagine (matrice n x d, dove n è il numero di immagini, e d il numero di feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd02c5",
   "metadata": {},
   "source": [
    "Dato:\n",
    "\n",
    "\t•\tun feature model (es. color_moments.npz)\n",
    "\t•\tun valore k\n",
    "\t•\tuna tecnica di riduzione dimensionale (SVD, LDA, k-means)\n",
    "\n",
    "Esegui:\n",
    "\n",
    "\t•\tRiduzione delle dimensioni nel feature space selezionato\n",
    "\t•\tEstrai le top-k componenti latenti\n",
    "\t•\tPer ogni componente, produci e salva: (immagine, peso) ordinati per importanza\n",
    "\t•\tSalva tutto in un file con nome chiaro (es. latent_semantics_svd_color_moments_k3.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398219e6",
   "metadata": {},
   "source": [
    "Cosa rappresenta K ? numero di componenti latenti che vuoi estrarre.\n",
    "\n",
    "SVD --> K è ilnumero di componenti principali - Riduce le dimensioni mantenendo variazione.\n",
    "\n",
    "LDA --> k è il numero di direzioni discriminanti - Riduce le dimensioni separando meglio le classi.\n",
    "\n",
    "k-means --> k è il numero di cluster - Divide le immagini in k gruppi simili (senza usare etichette)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "465b813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def task5_latent_semantics(feature_model_path, technique, k):\n",
    "    \"\"\"\n",
    "    Estrae i top-k concetti latenti da uno spazio di feature usando SVD, LDA o KMeans.\n",
    "    Visualizza lo spazio latente ed esporta un file .txt con i pesi associati alle immagini.\n",
    "\n",
    "    NOTE SU k:\n",
    "    ------------------\n",
    "    • SVD: \n",
    "        - k <= numero di feature (es. 300)\n",
    "        - Tipici: da 2 a 20\n",
    "\n",
    "    • LDA:\n",
    "        - k <= (numero classi - 1)\n",
    "        - Es: 3 classi → k max = 2\n",
    "\n",
    "    • KMeans:\n",
    "        - Qualsiasi k ≥ 1\n",
    "        - Tipico: 2 ≤ k ≤ 10\n",
    "        - Rappresenta il numero di gruppi nascosti (cluster)\n",
    "    \"\"\"\n",
    "    #print(f\"[INFO] Caricati {feature_matrix.shape[0]} vettori da: {feature_model_path}\")\n",
    "\n",
    "    technique = technique.lower()\n",
    "\n",
    "    if technique == \"svd\":\n",
    "        model = TruncatedSVD(n_components=k)\n",
    "        X_transformed = model.fit_transform(feature_matrix)\n",
    "        components = model.components_\n",
    "        method = \"svd\"\n",
    "\n",
    "    elif technique == \"lda\":\n",
    "        unique_labels = np.unique(labels)\n",
    "        max_k = min(k, len(unique_labels) - 1)\n",
    "        if k > max_k:\n",
    "            print(f\"[ATTENZIONE] LDA supporta al massimo {max_k} componenti con {len(unique_labels)} classi.\")\n",
    "            k = max_k\n",
    "        model = LDA(n_components=k)\n",
    "        X_transformed = model.fit_transform(feature_matrix, labels)\n",
    "        components = model.scalings_.T[:k]\n",
    "        method = \"lda\"\n",
    "\n",
    "    elif technique == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "        model.fit(feature_matrix)\n",
    "        components = model.cluster_centers_\n",
    "        X_transformed = model.transform(feature_matrix)\n",
    "        method = \"kmeans\"\n",
    "    else:\n",
    "        print(\"[ERRORE] Tecnica non supportata. Usa: 'svd', 'lda', 'kmeans'\")\n",
    "        return\n",
    "\n",
    "    # Visualizzazione\n",
    "    if technique in [\"svd\", \"lda\"]:\n",
    "        plot_latent_space_2d(X_transformed, labels, technique, k)\n",
    "    elif technique == \"kmeans\":\n",
    "        plot_kmeans_clusters_2d(feature_matrix, labels, k)\n",
    "\n",
    "    # Output file\n",
    "    base_name = os.path.splitext(os.path.basename(feature_model_path))[0]\n",
    "    out_file = f\"latent_semantics_{method}_{base_name}_k{k}.txt\"\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for i in range(k):\n",
    "            f.write(f\"\\n--- Latent Semantic {i+1} ---\\n\")\n",
    "            if technique in [\"svd\", \"lda\"]:\n",
    "                weights = feature_matrix @ components[i].T\n",
    "            else:  # KMeans: distanza inversa dal centroide\n",
    "                weights = -X_transformed[:, i]\n",
    "\n",
    "            sorted_idx = np.argsort(-np.abs(weights))\n",
    "            for idx in sorted_idx:\n",
    "                f.write(f\"{filenames[idx]} | Peso: {weights[idx]:.4f} | Classe: {labels[idx]}\\n\")\n",
    "\n",
    "    print(f\"[SALVATO] Latent semantics salvati in: {out_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2e4021",
   "metadata": {},
   "source": [
    "\tMetodi per la visualizzazione dei dati:\n",
    "\n",
    "    1)Visualizzazione dei dati latenti con SVD o LDA.\n",
    "\n",
    "\t2)Visualizzazione alternativa e dedicata per KMeans usando la proiezione in 2D tramite SVD e la colorazione dei clust."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b8242ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent_space_2d(X_transformed, labels, technique, k):\n",
    "    \"\"\"Visualizza la proiezione 2D delle immagini nello spazio latente (solo per SVD/LDA).\"\"\"\n",
    "    if X_transformed.shape[1] < 2:\n",
    "        print(\"[INFO] Meno di 2 componenti: impossibile visualizzare in 2D.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_transformed[:, 0], y=X_transformed[:, 1], hue=labels, palette=\"Set2\", s=80)\n",
    "    plt.title(f\"{technique.upper()} - Proiezione sulle prime 2 componenti latenti (k={k})\")\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_kmeans_clusters_2d(feature_matrix, labels, n_clusters):\n",
    "    \"\"\"Visualizza le immagini raggruppate da KMeans su uno spazio 2D ridotto con SVD.\"\"\"\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(feature_matrix)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=cluster_labels, palette='tab10', s=80, style=labels)\n",
    "    plt.title(f\"KMeans Clustering (k={n_clusters}) con proiezione SVD 2D\")\n",
    "    plt.xlabel(\"Componente Latente 1 (da SVD)\")\n",
    "    plt.ylabel(\"Componente Latente 2 (da SVD)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "task5_latent_semantics(\"color_moments.npz\", technique=\"svd\", k=5)\n",
    "task5_latent_semantics(\"color_moments.npz\", technique=\"lda\", k=2)\n",
    "task5_latent_semantics(\"color_moments.npz\", technique=\"kmeans\", k=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
