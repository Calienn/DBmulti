{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088b8fc2",
   "metadata": {},
   "source": [
    "Color Moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d2ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import skew\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33eaae8",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58732e0",
   "metadata": {},
   "source": [
    "Crop automatico per isolare il cervello - Task1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00999225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_brain(img):\n",
    "    \"\"\"Ritaglia l'area informativa (cervello) da un'immagine.\"\"\"\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    coords = cv2.findNonZero(thresh)\n",
    "    if coords is not None:\n",
    "        x, y, w, h = cv2.boundingRect(coords)\n",
    "        return img[y:y+h, x:x+w]\n",
    "    return img  # fallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f3fc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_features(npz_path):\n",
    "    data = np.load(npz_path, allow_pickle=True)\n",
    "    return data['features'], data['labels'], data.get('filenames', [f\"img_{i}\" for i in range(len(data['features']))])\n",
    "\n",
    "\n",
    "feat_matrix_part1, lbls_part1, flname_part1 = load_features(\n",
    "    \"color_moments_part1.npz\")\n",
    "feat_matrix_part2, lbls_part2, flname_part2 = load_features(\n",
    "    \"color_moments_part2.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80adff1e",
   "metadata": {},
   "source": [
    "### Task 1-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6714dba",
   "metadata": {},
   "source": [
    "Estrazione Color Moments su griglia - Task 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc8196bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_color_moments(img_path):\n",
    "    \"\"\"Estrae Color Moments su una griglia 10x10 da un'immagine.\"\"\"\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        print(f\"[ERRORE] Immagine non trovata: {img_path}\")\n",
    "        return None\n",
    "\n",
    "    if len(img.shape) == 2 or img.shape[2] == 1:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    img = crop_to_brain(img)\n",
    "    img = cv2.resize(img, (300, 100))  # Griglia uniforme\n",
    "\n",
    "    h, w, _ = img.shape\n",
    "    grid_h, grid_w = h // 10, w // 10\n",
    "    features = []\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            cell = img[i*grid_h:(i+1)*grid_h, j*grid_w:(j+1)*grid_w]\n",
    "            for channel in range(3):\n",
    "                pixels = cell[:, :, channel].flatten()\n",
    "                if np.std(pixels) > 0:\n",
    "                    mean = np.mean(pixels)\n",
    "                    std = np.std(pixels)\n",
    "                    sk = skew(pixels)\n",
    "                    if np.isnan(sk): sk = 0\n",
    "                else:\n",
    "                    mean, std, sk = 0, 0, 0\n",
    "                features.extend([mean, std, sk])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf0122b",
   "metadata": {},
   "source": [
    " Estrazione feature da più cartelle e salvataggio in .npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8957034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_save_features(base_folder, subfolders, output_file):\n",
    "    \"\"\"Estrae le feature da immagini organizzate in sottocartelle e le salva in un file .npz.\"\"\"\n",
    "    all_features, all_filenames, all_labels = [], [], []\n",
    "\n",
    "    for label in subfolders:\n",
    "        folder_path = os.path.join(base_folder, label)\n",
    "        print(f\"[INFO] Elaboro cartella: {label}\")\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.lower().endswith(('.jpg', '.png', '.jpeg', '.bmp', '.tif')):\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                features = extract_color_moments(img_path)\n",
    "                if features is not None:\n",
    "                    all_features.append(features)\n",
    "                    all_filenames.append(filename)\n",
    "                    all_labels.append(label)\n",
    "\n",
    "    np.savez(output_file,\n",
    "             features=np.array(all_features),\n",
    "             filenames=np.array(all_filenames),\n",
    "             labels=np.array(all_labels))\n",
    "    print(f\"[SALVATO] Features salvate in {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf78dfcc",
   "metadata": {},
   "source": [
    "### Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd46fed",
   "metadata": {},
   "source": [
    "Ricerca immagini simili (Euclidea) - Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0add08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar(base_folder, img_path, k):\n",
    "    \"\"\"Trova le k immagini più simili in base alla distanza euclidea.\"\"\"\n",
    "    query_feature = extract_color_moments(img_path)\n",
    "    if query_feature is None:\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    distances = euclidean_distances(feat_matrix_part1, query_feature).flatten()\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "\n",
    "    print(f\"\\nTop {k} immagini simili a: {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(f\"{rank+1}. {flname_part1[idx]} | Classe: {lbls_part1[idx]} | Distanza: {distances[idx]:.2f}\")\n",
    "\n",
    "    # Visualizzazione\n",
    "    fig, axs = plt.subplots(1, k+1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        img_match = cv2.imread(os.path.join(base_folder, lbls_part1[idx], flname_part1[idx]))\n",
    "        axs[i+1].imshow(cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB))\n",
    "        axs[i+1].set_title(f\"Rank {i+1}\\nD={distances[idx]:.2f}\")\n",
    "        axs[i+1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab512b0",
   "metadata": {},
   "source": [
    "Ricerca immagini simili (Mahalanobis) - Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a2fd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k_similar_mahalanobis(base_folder, img_path, k):\n",
    "    \"\"\"Trova le k immagini più simili usando distanza di Mahalanobis, escludendo la query.\"\"\"\n",
    "    # Estrai le feature dalla query\n",
    "    query_feature = extract_color_moments(img_path)\n",
    "    if query_feature is None:\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature)\n",
    "\n",
    "    # Calcola matrice di covarianza delle feature\n",
    "    cov = np.cov(feat_matrix_part1.T)\n",
    "\n",
    "    # Inversione con fallback alla pseudoinversa\n",
    "    try:\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "    except np.linalg.LinAlgError:\n",
    "        print(\"[ERRORE] Uso pseudoinversa per matrice non invertibile.\")\n",
    "        cov_inv = np.linalg.pinv(cov)\n",
    "\n",
    "    # Calcola distanza di Mahalanobis tra la query e tutte le immagini\n",
    "    distances = np.array([\n",
    "        mahalanobis(query_feature, f, cov_inv) for f in feat_matrix_part1\n",
    "    ])\n",
    "\n",
    "    # Opzionale: escludi la query stessa (distanza 0)\n",
    "    # === Escludi la query basandoti sul path ===\n",
    "    query_filename = os.path.basename(img_path)\n",
    "    query_label = os.path.basename(os.path.dirname(img_path))\n",
    "\n",
    "    for i in range(len(flname_part1)):\n",
    "        if flname_part1[i] == query_filename and lbls_part1[i] == query_label:\n",
    "            distances[i] = np.inf\n",
    "            break\n",
    "\n",
    "    # Seleziona i top-k indici a distanza minima\n",
    "    top_k_idx = np.argsort(distances)[:k]\n",
    "    top_k_scores = distances[top_k_idx]\n",
    "\n",
    "    # Output testuale\n",
    "    print(f\"\\nTop {k} immagini simili (Mahalanobis): {img_path}\")\n",
    "    for rank, idx in enumerate(top_k_idx):\n",
    "        print(\n",
    "            f\"{rank+1}. {flname_part1[idx]} | Classe: {lbls_part1[idx]} | Distanza: {top_k_scores[rank]:.2f}\")\n",
    "\n",
    "    # Visualizza le immagini\n",
    "    fig, axs = plt.subplots(1, k + 1, figsize=(15, 5))\n",
    "    axs[0].imshow(cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB))\n",
    "    axs[0].set_title(\"Query\")\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    for i, idx in enumerate(top_k_idx):\n",
    "        img_match_path = os.path.join(\n",
    "            base_folder, lbls_part1[idx], flname_part1[idx])\n",
    "        img_match = cv2.imread(img_match_path)\n",
    "        axs[i + 1].imshow(cv2.cvtColor(img_match, cv2.COLOR_BGR2RGB))\n",
    "        axs[i + 1].set_title(f\"Rank {i + 1}\\nD={top_k_scores[i]:.2f}\")\n",
    "        axs[i + 1].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a2b6e",
   "metadata": {},
   "source": [
    "Esecuzione: Estrazione e salvataggio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8dc415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametri\n",
    "subfolders = [\"brain_glioma\", \"brain_menin\", \"brain_tumor\"]\n",
    "\n",
    "# Estrazione e salvataggio\n",
    "process_and_save_features(\"Part1\", subfolders, \"color_moments_part1.npz\")\n",
    "process_and_save_features(\"Part2\", subfolders, \"color_moments_part2.npz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dbd1e1",
   "metadata": {},
   "source": [
    "Esecuzione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27746597",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"Part1\"\n",
    "query_img = \"Part1/brain_glioma/brain_glioma_0005.jpg\"\n",
    "find_k_similar(base_folder, query_img, k=5)\n",
    "find_k_similar_mahalanobis(base_folder, query_img, k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0889fab2",
   "metadata": {},
   "source": [
    "### Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3292ca",
   "metadata": {},
   "source": [
    "Task 4:\n",
    "\n",
    "\t1.\tAccetti come input:\n",
    "\t    •\tun’immagine di query (da “Part2”)\n",
    "\t    •\tuna scelta dell’utente sul tipo di feature space\n",
    "\t    •\tun valore intero k <= 2.\n",
    "\t2.\tCalcoli le features dell’immagine di query secondo il feature space selezionato.\n",
    "\t3.\tCalcoli la distanza tra la query e tutte le immagini del dataset (es. Euclidea o Mahalanobis).\n",
    "\t4.\tRaggruppi le distanze per label e selezioni le k classi (etichette) più simili in media.\n",
    "\t5.\tStampi/ritorni una classifica delle k etichette più probabili con il rispettivo punteggio (es. distanza  media o somma inversa delle distanze)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67210468",
   "metadata": {},
   "source": [
    "Un feature space è lo spazio vettoriale dove ogni immagine è rappresentata come un vettore di caratteristiche (feature vector).\n",
    "\n",
    "Il selected feature space indica quale tipo di caratteristiche estrai per rappresentare l’immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f42b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_top_k_labels(query_img_path,k):\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "\n",
    "    # Estrazione delle feature dalla query (basata su Color Moments)\n",
    "    query_feature = extract_color_moments(query_img_path)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Feature non estratte.\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "    # Calcolo della distanza euclidea tra la query e tutte le immagini nel dataset\n",
    "    distances = euclidean_distances(feat_matrix_part1, query_feature).flatten()\n",
    "\n",
    "    # Creazione di un DataFrame per semplificare le operazioni successive\n",
    "    df = pd.DataFrame({\n",
    "        'filename': flname_part1,  # nome immagine\n",
    "        'label': lbls_part1,        # etichetta (classe)\n",
    "        'distance': distances   # distanza dalla query\n",
    "    })\n",
    "\n",
    "    # Calcola la distanza media per classe\n",
    "    avg_dist_per_label = df.groupby('label')['distance'].mean().sort_values()\n",
    "\n",
    "    # Prendi le k classi più simili (minore distanza = maggiore similarità)\n",
    "    top_k_labels = avg_dist_per_label.head(k)\n",
    "\n",
    "    print(f\"\\nClassifica delle {k} etichette più probabili per la query:\")\n",
    "    for i, (label, score) in enumerate(top_k_labels.items(), 1):\n",
    "        print(f\"{i}. {label} | Score (distanza media): {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "777c9192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top_k_labels_by_prototypes(query_img_path, k=2):\n",
    "    \"\"\"\n",
    "    Predice le k etichette più probabili per una query image confrontandola\n",
    "    con i prototipi (centroidi) di ciascuna classe nello spazio delle feature.\n",
    "\n",
    "    Parametri:\n",
    "    - query_img_path: percorso dell'immagine di query (parte 2)\n",
    "    - k: numero massimo di etichette da restituire (k <= 2)\n",
    "\n",
    "    Strategia:\n",
    "    - Calcola la media (prototipo) delle feature per ciascuna classe\n",
    "    - Confronta la query con ogni prototipo usando distanza euclidea\n",
    "    - Restituisce le k etichette con distanza minore (cioè più simili)\n",
    "    \"\"\"\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "\n",
    "    query_feature = extract_color_moments(query_img_path)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Feature non estratte.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "\n",
    "    # Costruzione DataFrame per calcolo dei prototipi per classe\n",
    "    df_features = pd.DataFrame(feat_matrix_part1)\n",
    "    df_features['label'] = lbls_part1\n",
    "\n",
    "    # Calcolo dei centroidi (prototipi) per ciascuna classe\n",
    "    class_prototypes = df_features.groupby('label').mean()\n",
    "\n",
    "    # Rimozione della colonna \"label\" dal prototipo (è diventato indice)\n",
    "    prototype_vectors = class_prototypes.values\n",
    "    prototype_labels = class_prototypes.index\n",
    "\n",
    "    # Calcolo della distanza della query da ciascun prototipo\n",
    "    distances = euclidean_distances(prototype_vectors, query_feature).flatten()\n",
    "\n",
    "    # Ordinamento per distanza crescente\n",
    "    sorted_indices = np.argsort(distances)\n",
    "    top_k = [(prototype_labels[i], distances[i]) for i in sorted_indices[:k]]\n",
    "\n",
    "    # Output\n",
    "    print(f\"\\n Classifica delle {k} etichette più vicine ai prototipi:\")\n",
    "    for i, (label, dist) in enumerate(top_k, 1):\n",
    "        print(f\"{i}. {label} | Distanza dal prototipo: {dist:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522fe5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_glioma/brain_glioma_1112.jpg\"\n",
    "predict_top_k_labels_by_prototypes(query_img, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6752a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_glioma/brain_glioma_1112.jpg\"\n",
    "predict_top_k_labels(query_img,k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c262152",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_label_ranking_strategies(query_img_path, k=2):\n",
    "    \"\"\"\n",
    "    Confronta le etichette predette da due strategie:\n",
    "    - distanza media per classe\n",
    "    - distanza al rappresentante (prototipo) della classe\n",
    "    Visualizza solo le top-k etichette con un grafico comparativo.\n",
    "    \"\"\"\n",
    "    assert k <= 2, \"k deve essere <= 2\"\n",
    "\n",
    "    query_feature = extract_color_moments(query_img_path)\n",
    "    if query_feature is None:\n",
    "        print(\"[ERRORE] Feature non estratte.\")\n",
    "        return\n",
    "\n",
    "    query_feature = np.array(query_feature).reshape(1, -1)\n",
    "\n",
    "    # ===== Strategia 1: distanza media per classe =====\n",
    "    distances_all = euclidean_distances(feat_matrix_part1, query_feature).flatten()\n",
    "    df_all = pd.DataFrame({\n",
    "        'label': lbls_part1,\n",
    "        'distance': distances_all\n",
    "    })\n",
    "    mean_dists = df_all.groupby('label')['distance'].mean().sort_values()\n",
    "\n",
    "    # ===== Strategia 2: distanza dal prototipo (centroide) =====\n",
    "    df_features = pd.DataFrame(feat_matrix_part1)\n",
    "    df_features['label'] = lbls_part1\n",
    "    class_prototypes = df_features.groupby('label').mean().drop(columns=['label'], errors='ignore')\n",
    "    proto_vectors = class_prototypes.values\n",
    "    proto_labels = class_prototypes.index\n",
    "    proto_dists = euclidean_distances(proto_vectors, query_feature).flatten()\n",
    "    proto_dists_series = pd.Series(proto_dists, index=proto_labels).sort_values()\n",
    "\n",
    "    # ===== Prendi le top-k etichette comuni =====\n",
    "    top_k_mean = mean_dists.head(k)\n",
    "    top_k_proto = proto_dists_series.head(k)\n",
    "\n",
    "    union_labels = sorted(set(top_k_mean.index).union(set(top_k_proto.index)))\n",
    "\n",
    "    # ===== Plot solo per le top-k etichette =====\n",
    "    x = np.arange(len(union_labels))\n",
    "    width = 0.35\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.bar(x - width/2, [mean_dists[label] for label in union_labels], width, label='Distanza Media')\n",
    "    ax.bar(x + width/2, [proto_dists_series[label] for label in union_labels], width, label='Distanza Prototipo')\n",
    "\n",
    "    ax.set_ylabel('Distanza')\n",
    "    ax.set_title(f\"Top-{k} Strategie - Query: {os.path.basename(query_img_path)}\")\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(union_labels)\n",
    "    ax.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # ===== Stampa i top-k risultati =====\n",
    "    print(\"\\n Top-k etichette per ciascuna strategia:\\n\")\n",
    "    print(\"Strategia: Distanza Media\")\n",
    "    print(top_k_mean)\n",
    "\n",
    "    print(\"\\n Strategia: Prototipo di Classe\")\n",
    "    print(top_k_proto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d881e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_img = \"Part2/brain_glioma/brain_glioma_1142.jpg\"\n",
    "compare_label_ranking_strategies(query_img, k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11ef5c7",
   "metadata": {},
   "source": [
    "### Task 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4fa6891",
   "metadata": {},
   "source": [
    "Task 5\n",
    "\n",
    "feature model è il file dei dati delle feature che già estratto. Una rappresentazione di tutte le immagini del dataset in un certo feature space, salvata come matrice (feature_matrix), dove ogni riga è un’immagine (matrice n x d, dove n è il numero di immagini, e d il numero di feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd02c5",
   "metadata": {},
   "source": [
    "Dato:\n",
    "\n",
    "\t•\tun feature model (es. color_moments.npz)\n",
    "\t•\tun valore k\n",
    "\t•\tuna tecnica di riduzione dimensionale (SVD, LDA, k-means)\n",
    "\n",
    "Esegui:\n",
    "\n",
    "\t•\tRiduzione delle dimensioni nel feature space selezionato\n",
    "\t•\tEstrai le top-k componenti latenti\n",
    "\t•\tPer ogni componente, produci e salva: (immagine, peso) ordinati per importanza\n",
    "\t•\tSalva tutto in un file con nome chiaro (es. latent_semantics_svd_color_moments_k3.txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398219e6",
   "metadata": {},
   "source": [
    "Cosa rappresenta K ? numero di componenti latenti che vuoi estrarre.\n",
    "\n",
    "SVD --> K è ilnumero di componenti principali - Riduce le dimensioni mantenendo variazione.\n",
    "\n",
    "LDA --> k è il numero di direzioni discriminanti - Riduce le dimensioni separando meglio le classi.\n",
    "\n",
    "k-means --> k è il numero di cluster - Divide le immagini in k gruppi simili (senza usare etichette)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4fe0ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_latent_space_2d(X_transformed, labels, technique, k):\n",
    "    \"\"\"Visualizza la proiezione 2D delle immagini nello spazio latente (solo per SVD/LDA).\"\"\"\n",
    "    print(f\"[DEBUG] Shape X_svd (dati trasformati): {X_transformed.shape}\")\n",
    "    if X_transformed.shape[1] < 2:\n",
    "        print(\"[INFO] Meno di 2 componenti: impossibile visualizzare in 2D.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_transformed[:, 0], y=X_transformed[:, 1], hue=labels, palette=\"Set2\", s=80)\n",
    "    plt.title(f\"{technique.upper()} - Proiezione sulle prime 2 componenti latenti (k={k})\")\n",
    "    plt.xlabel(\"Componente 1\")\n",
    "    plt.ylabel(\"Componente 2\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_kmeans_clusters_2d(feature_matrix, labels, n_clusters):\n",
    "    \"\"\"Visualizza le immagini raggruppate da KMeans su uno spazio 2D ridotto con SVD.\"\"\"\n",
    "    svd = TruncatedSVD(n_components=2, random_state=42)\n",
    "    X_2d = svd.fit_transform(feature_matrix)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(feature_matrix)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.scatterplot(x=X_2d[:, 0], y=X_2d[:, 1], hue=cluster_labels, palette='tab10', s=80, style=labels)\n",
    "    plt.title(f\"KMeans Clustering (k={n_clusters}) con proiezione SVD 2D\")\n",
    "    plt.xlabel(\"Componente Latente 1 (da SVD)\")\n",
    "    plt.ylabel(\"Componente Latente 2 (da SVD)\")\n",
    "    plt.grid(True)\n",
    "    plt.legend(title=\"Cluster\")\n",
    "    plt.show()\n",
    "\n",
    "def task5_latent_semantics(feature_model_path, technique, k):\n",
    "    \"\"\"\n",
    "    Estrae i top-k concetti latenti da uno spazio di feature usando SVD, LDA o KMeans.\n",
    "    Visualizza lo spazio latente ed esporta un file .txt con i pesi associati alle immagini.\n",
    "    \"\"\"\n",
    "\n",
    "    technique = technique.lower()\n",
    "    method = \"\"\n",
    "    X_transformed = None\n",
    "    components = None\n",
    "\n",
    "    if technique == \"svd\":\n",
    "        model = TruncatedSVD(n_components=k)\n",
    "        X_transformed = model.fit_transform(feat_matrix_part1)\n",
    "        components = model.components_\n",
    "        method = \"svd\"\n",
    "\n",
    "    elif technique == \"lda\":\n",
    "        unique_labels = np.unique(lbls_part1)\n",
    "        max_k = len(unique_labels) - 1\n",
    "        if k > max_k:\n",
    "            print(f\"[ATTENZIONE] LDA supporta al massimo {max_k} componenti con {len(unique_labels)} classi.\")\n",
    "            k = max_k\n",
    "        model = LDA(n_components=k)\n",
    "        X_transformed = model.fit_transform(feat_matrix_part1, lbls_part1)\n",
    "        components = model.scalings_.T[:k]\n",
    "        method = \"lda\"\n",
    "\n",
    "    elif technique == \"kmeans\":\n",
    "        model = KMeans(n_clusters=k, random_state=42)\n",
    "        model.fit(feat_matrix_part1)\n",
    "        components = model.cluster_centers_\n",
    "        X_transformed = model.transform(feat_matrix_part1)\n",
    "        method = \"kmeans\"\n",
    "    else:\n",
    "        print(\"[ERRORE] Tecnica non supportata. Usa: 'svd', 'lda', 'kmeans'\")\n",
    "        return\n",
    "\n",
    "    # Visualizzazione\n",
    "    if technique in [\"svd\", \"lda\"]:\n",
    "        plot_latent_space_2d(X_transformed, lbls_part1, technique, k)\n",
    "    elif technique == \"kmeans\":\n",
    "        plot_kmeans_clusters_2d(feat_matrix_part1, lbls_part1, k)\n",
    "\n",
    "    # Creazione output\n",
    "    os.makedirs(\"task5_output\", exist_ok=True)\n",
    "    base_name = os.path.splitext(os.path.basename(feature_model_path))[0]\n",
    "    out_file = os.path.join(\"task5_output\", f\"latent_semantics_{method}_{base_name}_k{k}.txt\")\n",
    "\n",
    "    with open(out_file, \"w\") as f:\n",
    "        for i in range(k):\n",
    "            f.write(f\"\\n--- Latent Semantic {i+1} ---\\n\")\n",
    "            if technique in [\"svd\", \"lda\"]:\n",
    "                weights = feat_matrix_part1 @ components[i].T\n",
    "                sorted_idx = np.argsort(-np.abs(weights))\n",
    "            else:  # KMeans: distanza dal centroide, più piccola = più vicino\n",
    "                weights = -X_transformed[:, i]\n",
    "                sorted_idx = np.argsort(weights)\n",
    "\n",
    "            for idx in sorted_idx:\n",
    "                image_id = flname_part1[idx]\n",
    "                f.write(f\"{image_id} | Peso: {weights[idx]:.4f} | Classe: {lbls_part1[idx]}\\n\")\n",
    "\n",
    "    print(f\"[SALVATO] Latent semantics salvati in: {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a26da",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components=min(feat_matrix_part1.shape)\n",
    "\n",
    "task5_latent_semantics(\"color_moments.npz\", technique=\"svd\", k=5)\n",
    "task5_latent_semantics(\"color_moments.npz\", technique=\"svd\", k=n_components)\n",
    "task5_latent_semantics(\"color_moments.npz\", technique=\"lda\", k=2)\n",
    "task5_latent_semantics(\"color_moments.npz\", technique=\"kmeans\", k=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f0428",
   "metadata": {},
   "source": [
    "### Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4a5bf8",
   "metadata": {},
   "source": [
    "Obiettivo del Task 6\n",
    "\n",
    "Trasformazione in uno spazio latente ortonormale: Utilizzando una tecnica di riduzione dimensionale, trasformiamo l’insieme delle feature originali in un nuovo spazio le cui componenti sono ortonormali.\n",
    "\n",
    "Concentrazione del potere discriminante: Le componenti vengono ordinate in base alla varianza spiegata (cioè, la potenza discriminante). In questo modo, le prime componenti (quelle con varianza più elevata) contengono la maggior parte dell’informazione utile, mentre le componenti successive sono meno significative.\n",
    "\n",
    "Dimensionalità intrinseca: Se il numero di componenti latenti (m) ottenute è uguale al numero di feature di partenza, la trasformazione preserva esattamente tutte le distanze ed angoli (cioè, la trasformazione è invertibile e non viene persa informazione). Se invece la dimensionalità intrinseca è minore di m, allora potrai scegliere di mantenere solo quelle componenti più significative. In questo caso, le distanze e gli angoli nel database trasformato saranno approssimati, introducendo un errore proporzionale alla quantità di informazione “persa” trascurando le componenti meno significative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa844a",
   "metadata": {},
   "source": [
    "explained = pca.explained_variance_ratio_\n",
    "\n",
    "Questa riga:\n",
    "\tOttiene un array di float dove ciascun valore rappresenta la percentuale di varianza spiegata da ciascuna componente principale della PCA.\n",
    "\n",
    "\tÈ ordinato dalla componente più importante a quella meno importante.\n",
    "\n",
    "esempio: explained = [0.40, 0.30, 0.20, 0.07, 0.03]\n",
    "\n",
    "Significa:\n",
    "    La prima componente spiega il 40% della varianza\n",
    "\n",
    "\tLa seconda il 30%, ecc.\n",
    "\n",
    "\n",
    "\n",
    "cumulative = np.cumsum(explained)\n",
    "\n",
    "Calcola la somma cumulativa dell’array explained, cioè la varianza totale spiegata fino a ciascuna componente.\n",
    "\n",
    "es:cumulative = [0.40, 0.70, 0.90, 0.97, 1.00]\n",
    "\n",
    "Significa:\n",
    "\t•\tLe prime 2 componenti spiegano il 70%\n",
    "\t•\tLe prime 3 il 90%\n",
    "\t•\tLe prime 4 il 97%, ecc.\n",
    "\n",
    "\n",
    "intrinsic_dim = np.argmax(cumulative >= threshold) + 1\n",
    "\n",
    "Questa riga:\n",
    "\t•\tTrova il primo indice in cui la varianza cumulativa raggiunge o supera una soglia (threshold), ad esempio 0.95 (95%).\n",
    "\t•\tnp.argmax(...) restituisce il primo True nella condizione cumulative >= threshold.\n",
    "\t•\tSi aggiunge +1 perché gli indici Python partono da 0, ma il numero di componenti parte da 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12aee35",
   "metadata": {},
   "source": [
    "studio del k migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "674d1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def estimate_intrinsic_dimensionality(feature_matrix, threshold, plot=True):\n",
    "    max_components = min(feature_matrix.shape)\n",
    "    pca = PCA(n_components=max_components)\n",
    "    pca.fit(feature_matrix)\n",
    "\n",
    "    explained = pca.explained_variance_ratio_\n",
    "    cumulative = np.cumsum(explained)\n",
    "    intrinsic_dim = np.argmax(cumulative >= threshold) + 1\n",
    "\n",
    "    #print(f\"[INFO] Spiegazione varianza per ogni componente PCA:\\n{explained}\")\n",
    "    #print(f\"[INFO] Varianza cumulativa:\\n{cumulative}\")\n",
    "    #print(f\"[INFO] Soglia impostata: {threshold}\")\n",
    "    #print(f\"[INFO] Dimensione intrinseca stimata: {intrinsic_dim}\")\n",
    "\n",
    "    if plot:\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        plt.plot(cumulative, marker='o', label=\"Varianza cumulativa\")\n",
    "        plt.axhline(y=threshold, color='r', linestyle='--', label=f\"Soglia {threshold*100:.0f}%\")\n",
    "        plt.axvline(x=intrinsic_dim, color='g', linestyle='--', label=f\"k suggerito: {intrinsic_dim}\")\n",
    "        plt.xlabel(\"Numero componenti\")\n",
    "        plt.ylabel(\"Varianza cumulativa\")\n",
    "        plt.title(\"Scelta ottimale di k (PCA/SVD)\")\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    print(f\"[INFO] k ottimale suggerito (soglia {threshold*100:.0f}%): {intrinsic_dim}\")\n",
    "    return intrinsic_dim, cumulative\n",
    "\n",
    "def suggest_k(feature_matrix, threshold_list=[0.90, 0.95, 0.99]):\n",
    "    print(f\"[INFO] Feature matrix shape: {feature_matrix.shape}\")\n",
    "    k_values = {}\n",
    "    for t in threshold_list:\n",
    "        k, _ = estimate_intrinsic_dimensionality(feature_matrix, threshold=t, plot=False)\n",
    "        k_values[t] = k\n",
    "        print(f\"Soglia {int(t*100)}% : k = {k}\")\n",
    "    return k_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c7fb149e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_dimensionality_per_label(feature_matrix, labels, threshold):\n",
    "    label_dim_map = {}\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    print(f\"[INFO] Etichette uniche trovate: {len(unique_labels)}\")\n",
    "\n",
    "    for label in unique_labels:\n",
    "        indices = np.where(labels == label)[0]\n",
    "        label_features = feature_matrix[indices]\n",
    "\n",
    "        if len(indices) < 2:\n",
    "            print(f\"[AVVISO] Label '{label}' ha meno di 2 campioni — ignorata.\")\n",
    "            continue\n",
    "\n",
    "        k, _ = estimate_intrinsic_dimensionality(label_features, threshold=threshold, plot=False)\n",
    "        label_dim_map[label] = k\n",
    "        print(f\" Label '{label}' : k = {k}\")\n",
    "\n",
    "    return label_dim_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f13f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola k per varie soglie\n",
    "print(\"\\Stima automatica di k in base alla varianza spiegata:\\n\")\n",
    "k_suggeriti = suggest_k(feat_matrix_part1)\n",
    "# Plot dettagliato per la soglia 95%\n",
    "estimate_intrinsic_dimensionality(feat_matrix_part1, threshold=0.95, plot=True)\n",
    "\n",
    "\n",
    "print(\"\\n Task 6b – Dimensionalità per etichetta:\\n\")\n",
    "label_dimensionalities = estimate_dimensionality_per_label(feat_matrix_part1, lbls_part1, threshold=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69c6970",
   "metadata": {},
   "source": [
    "### Task 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ba93a0",
   "metadata": {},
   "source": [
    "Implementare un programma che:\n",
    "\n",
    "1) per ogni etichetta unica l, calcoli la corrispondente k semantica latente (a scelta)\n",
    "associata alle immagini della parte 1 \n",
    "\n",
    "2) per le immagini della parte 2, preveda le etichette più probabili utilizzando le distanze/similitudini calcolate\n",
    "in base alla semantica latente specifica dell'etichetta.\n",
    "Il sistema deve inoltre fornire i valori di precisione, richiamo e punteggio F1 per etichetta, nonché\n",
    "un valore di accuratezza complessiva.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60aaa7d5",
   "metadata": {},
   "source": [
    "1. Estrazione della semantica latente per ogni classe\n",
    "Funzione: compute_latent_semantics_per_class(X, y, k)\n",
    "\n",
    "Input:\n",
    "- X: Matrice delle caratteristiche delle immagini della Parte 1.\n",
    "- y: Vettore delle etichette corrispondenti.\n",
    "- k: Numero di componenti latenti da estrarre tramite SVD.\n",
    "\n",
    "Output:\n",
    "- class_models: Contiene scaler, modello SVD e vettori latenti per ciascuna classe.\n",
    "- class_means: Contiene il vettore medio (centroide latente) per ciascuna classe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5f2964",
   "metadata": {},
   "source": [
    "2 Funzione: predict_label(X_test, class_models, class_means)\n",
    "\n",
    "Input:\n",
    "- X_test: Matrice delle immagini da classificare.\n",
    "- class_models: Modelli latenti per ciascuna classe.\n",
    "- class_means: Centroidi dei vettori latenti per ciascuna classe.\n",
    "\n",
    "Output:\n",
    "- y_pred: Lista delle etichette previste per ciascuna immagine.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0158e54c",
   "metadata": {},
   "source": [
    "Funzioni: evaluate(y_true, y_pred), evaluate_predictions(true_labels, predicted_labels)\n",
    "\n",
    "Metriche calcolate:\n",
    "- Precisione per classe\n",
    "- Recall per classe\n",
    "- F1 score per classe\n",
    "- Accuratezza complessiva\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1eca69",
   "metadata": {},
   "source": [
    "Ogni classe ha uno spazio semantico proprio, dove le immagini sono rappresentate in modo compatto.\n",
    "L'immagine da classificare è proiettata in ogni spazio latente e assegnata alla classe più simile in base alla distanza dal centroide.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ddfdf516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_latent_semantics_per_class(X, y, k=10):\n",
    "    class_models = {}\n",
    "    class_means = {}\n",
    "\n",
    "    labels = np.unique(y)\n",
    "    for label in labels:\n",
    "        X_class = X[y == label]  # Prende solo le istanze della classe corrente\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_class)  # Normalizza i dati della classe\n",
    "\n",
    "        svd = TruncatedSVD(n_components=k)\n",
    "        latent = svd.fit_transform(X_scaled)  # Riduzione dimensionale con SVD\n",
    "\n",
    "        # Salva modello SVD e scaler per la classe\n",
    "        class_models[label] = {\n",
    "            'svd': svd,\n",
    "            'scaler': scaler,\n",
    "            'latent_vectors': latent\n",
    "        }\n",
    "        # Calcola la media dei vettori latenti della classe\n",
    "        class_means[label] = np.mean(latent, axis=0)\n",
    "    return class_models, class_means\n",
    "\n",
    "def predict_label(X_test, class_models, class_means):\n",
    "    y_pred = []\n",
    "    for x in X_test:\n",
    "        best_label = None\n",
    "        min_dist = float('inf')\n",
    "        for label, model in class_models.items():\n",
    "            x_scaled = model['scaler'].transform(x.reshape(1, -1))  # Normalizza x\n",
    "            x_latent = model['svd'].transform(x_scaled)  # Trasforma in spazio latente\n",
    "            dist = np.linalg.norm(x_latent - class_means[label])  # Distanza dal centroide\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                best_label = label\n",
    "        y_pred.append(best_label)\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "def evaluate(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        y_true, y_pred, average=None, zero_division=0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    labels = np.unique(y_true)\n",
    "    print(\"Per-class metrics:\")\n",
    "    for i, label in enumerate(labels):\n",
    "        print(\n",
    "            f\"Class {label}: P={precision[i]:.2f}, R={recall[i]:.2f}, F1={f1[i]:.2f}\")\n",
    "    print(f\"\\nOverall Accuracy: {accuracy:.2f}\\n\")\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "def evaluate_predictions(true_labels, predicted_labels):\n",
    "    print(\"[VALUTAZIONE] Report di classificazione:\")\n",
    "    print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4646513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Addestramento sui dati di Part1\n",
    "class_models, class_means = compute_latent_semantics_per_class(\n",
    "    feat_matrix_part1, lbls_part1, k=10)\n",
    "\n",
    "# Predizione su Part2\n",
    "predicted_labels = predict_label(feat_matrix_part2, class_models, class_means)\n",
    "\n",
    "# Valutazione\n",
    "evaluate(lbls_part2, predicted_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
